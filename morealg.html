<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>More Algorithms for Arbitrary-Precision Sampling</title><meta name="citation_title" content="More Algorithms for Arbitrary-Precision Sampling"><meta name="citation_pdf_url" content="https://peteroupc.github.io/morealg.pdf"><meta name="citation_url" content="https://peteroupc.github.io/morealg.html"><meta name="citation_date" content="2023/03/09"><meta name="citation_online_date" content="2023/03/09"><meta name="og:title" content="More Algorithms for Arbitrary-Precision Sampling"><meta name="og:description" content="This page contains additional algorithms for arbitrary-precision sampling of distributions, Bernoulli factory algorithms (biased-coin to biased-coin algorithms), and algorithms to produce heads with an irrational probability.  They supplement my pages on Bernoulli factory algorithms and partially-sampled random numbers."><meta name="description" content="This page contains additional algorithms for arbitrary-precision sampling of distributions, Bernoulli factory algorithms (biased-coin to biased-coin algorithms), and algorithms to produce heads with an irrational probability.  They supplement my pages on Bernoulli factory algorithms and partially-sampled random numbers."><meta name="twitter:description" content="This page contains additional algorithms for arbitrary-precision sampling of distributions, Bernoulli factory algorithms (biased-coin to biased-coin algorithms), and algorithms to produce heads with an irrational probability.  They supplement my pages on Bernoulli factory algo..."><meta name="og:type" content="article"><meta name="og:url" content="https://peteroupc.github.io/morealg.html"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="More Algorithms for Arbitrary-Precision Sampling"><meta name="author" content="Peter Occil"/><meta name="citation_author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css">
            <script type="text/x-mathjax-config"> MathJax.Hub.Config({"HTML-CSS": { availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, preferredFont: "TeX" },
                    tex2jax: { displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ], processEscapes: true } });
            </script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"></script></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>More Algorithms for Arbitrary-Precision Sampling</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><strong>Abstract:</strong> This page contains additional algorithms for arbitrary-precision sampling of distributions, Bernoulli factory algorithms (biased-coin to biased-coin algorithms), and algorithms to produce heads with an irrational probability.  They supplement my pages on Bernoulli factory algorithms and partially-sampled random numbers.</p>

<p><strong>2020 Mathematics Subject Classification:</strong> 68W20, 60-08, 60-04.</p>

<p><a id=Introduction></a></p>

<h2>Introduction</h2>

<p>This page contains additional algorithms for arbitrary-precision sampling of distributions, Bernoulli factory algorithms (biased-coin to biased-coin algorithms), and algorithms to produce heads with an irrational probability.  These samplers are designed to not rely on floating-point arithmetic.</p>

<p>The samplers on this page may depend on algorithms given in the following pages:</p>

<ul>
<li><a href="https://peteroupc.github.io/exporand.html"><strong>Partially-Sampled Random Numbers for Accurate Sampling of Continuous Distributions</strong></a></li>
<li><a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a></li>
</ul>

<p>Additional Bernoulli factory algorithms and irrational probability samplers are included here rather than in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot; because that article is quite long as it is.</p>

<p><a id=About_This_Document></a></p>

<h3>About This Document</h3>

<p><strong>This is an open-source document; for an updated version, see the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/raw/master/morealg.md"><strong>source code</strong></a> <strong>or its</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/morealg.md"><strong>rendering on GitHub</strong></a><strong>.  You can send comments on this document on the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/issues"><strong>GitHub issues page</strong></a><strong>.</strong></p>

<p>My audience for this article is <strong>computer programmers with mathematics knowledge, but little or no familiarity with calculus</strong>.</p>

<p>I encourage readers to implement any of the algorithms given in this page, and report their implementation experiences.  In particular, <a href="https://github.com/peteroupc/peteroupc.github.io/issues/18"><strong>I seek comments on the following aspects</strong></a>:</p>

<ul>
<li>Are the algorithms in this article easy to implement? Is each algorithm written so that someone could write code for that algorithm after reading the article?</li>
<li>Does this article have errors that should be corrected?</li>
<li>Are there ways to make this article more useful to the target audience?</li>
</ul>

<p>Comments on other aspects of this document are welcome.</p>

<p><a id=Contents></a></p>

<h2>Contents</h2>

<ul>
<li><a href="#Introduction"><strong>Introduction</strong></a>

<ul>
<li><a href="#About_This_Document"><strong>About This Document</strong></a></li>
</ul></li>
<li><a href="#Contents"><strong>Contents</strong></a></li>
<li><a href="#Bernoulli_Factories"><strong>Bernoulli Factories</strong></a>

<ul>
<li><a href="#Certain_Power_Series"><strong>Certain Power Series</strong></a>

<ul>
<li><a href="#Certain_Alternating_Series"><strong>Certain Alternating Series</strong></a></li>
<li><a href="#General_Power_Series"><strong>General Power Series</strong></a></li>
<li><a href="#Series_with_Non_Negative_Coefficients_Summing_to_1_or_Less"><strong>Series with Non-Negative Coefficients Summing to 1 or Less</strong></a></li>
<li><a href="#Series_with_General_Non_Negative_Coefficients"><strong>Series with General Non-Negative Coefficients</strong></a></li>
<li><a href="#Power_Series_Examples"><strong>Power Series Examples</strong></a></li>
</ul></li>
<li><a href="#Certain_Piecewise_Linear_Functions"><strong>Certain Piecewise Linear Functions</strong></a></li>
<li><a href="#Pushdown_Automata_for_Square_Root_Like_Functions"><strong>Pushdown Automata for Square-Root-Like Functions</strong></a></li>
</ul></li>
<li><a href="#Irrational_Probabilities"><strong>Irrational Probabilities</strong></a>

<ul>
<li><a href="#Ratio_of_Lower_Gamma_Functions_gamma__m___x__gamma__m__1"><strong>Ratio of Lower Gamma Functions (&gamma;(<em>m</em>, <em>x</em>)/&gamma;(<em>m</em>, 1)).</strong></a></li>
<li><a href="#4_3___pi"><strong>4/(3*<em>&pi;</em>)</strong></a></li>
<li><a href="#1_exp__k__1_exp__k__1"><strong>(1 + exp(<em>k</em>)) / (1 + exp(<em>k</em> + 1))</strong></a></li>
</ul></li>
<li><a href="#Sampling_Distributions_Using_Incomplete_Information"><strong>Sampling Distributions Using Incomplete Information</strong></a></li>
<li><a href="#Acknowledgments"><strong>Acknowledgments</strong></a></li>
<li><a href="#Notes"><strong>Notes</strong></a></li>
<li><a href="#Appendix"><strong>Appendix</strong></a>

<ul>
<li><a href="#Ratio_of_Uniforms"><strong>Ratio of Uniforms</strong></a></li>
<li><a href="#Probability_Transformations"><strong>Probability Transformations</strong></a></li>
<li><a href="#Proof_of_the_General_Martingale_Algorithm"><strong>Proof of the General Martingale Algorithm</strong></a></li>
<li><a href="#SymPy_Code_for_Piecewise_Linear_Factory_Functions"><strong>SymPy Code for Piecewise Linear Factory Functions</strong></a></li>
<li><a href="#Algorithm_for_sin___lambda_____pi___2"><strong>Algorithm for sin(<em>&lambda;</em>*<em>&pi;</em>/2)</strong></a></li>
<li><a href="#Sampling_Distributions_Using_Incomplete_Information_Omitted_Algorithms"><strong>Sampling Distributions Using Incomplete Information: Omitted Algorithms</strong></a></li>
<li><a href="#Pushdown_Automata_and_Algebraic_Functions"><strong>Pushdown Automata and Algebraic Functions</strong></a>

<ul>
<li><a href="#Finite_State_and_Pushdown_Generators"><strong>Finite-State and Pushdown Generators</strong></a></li>
</ul></li>
</ul></li>
<li><a href="#License"><strong>License</strong></a></li>
</ul>

<p><a id=Bernoulli_Factories></a></p>

<h2>Bernoulli Factories</h2>

<p>&nbsp;</p>

<p>As a reminder, the <em>Bernoulli factory problem</em> is: We&#39;re given a coin that shows heads with an unknown probability, <em>&lambda;</em>, and the goal is to use that coin (and possibly also a fair coin) to build a &quot;new&quot; coin that shows heads with a probability that depends on <em>&lambda;</em>, call it <em>f</em>(<em>&lambda;</em>).  <em>f</em> is a Bernoulli factory function (or factory function) if this problem can be solved for that function.</p>

<p>This section contains additional algorithms to solve the Bernoulli factory problem for certain kinds of functions.  Such algorithms could be placed in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, but, since that article is quite long as it is, they are included here instead.</p>

<p>In the methods below, <em>&lambda;</em> is the unknown probability of heads of the coin involved in the Bernoulli factory problem.</p>

<p><a id=Certain_Power_Series></a></p>

<h3>Certain Power Series</h3>

<p>A <em>power series</em> is a function written as&mdash; $$f(\lambda) = a_0 (g(\lambda))^0 + a_1 (g(\lambda))^1 + ... + a_i (g(\lambda))^i + ...,\tag{1}$$ where $a_i$ are <em>coefficients</em> and $g(\lambda)$ is a function in the variable $\lambda$.  Not all power series sum to a definite value, but all power series that matter in this section do, and they must be Bernoulli factory functions.  (In particular, $g(\lambda)$ must be a Bernoulli factory function, too.)</p>

<p>Depending on the coefficients, different algorithms can be built to simulate a power series function:</p>

<ul>
<li>The coefficients are arbitrary, but can be split into two parts.</li>
<li>The coefficients alternate in sign, and their absolute values form a decreasing sequence.</li>
<li>The coefficients are nonnegative and sum to 1 or less.</li>
<li>The coefficients are nonnegative and may sum to 1 or greater.</li>
</ul>

<blockquote>
<p><strong>Note:</strong> In theory, the power series can contain coefficients that are irrational numbers or sum to an irrational number, but the algorithms to simulate such series can be inexact in practice.  Also, not all power series that admit a Bernoulli factory are covered by the algorithms in this section.  They include:</p>

<ul>
<li>Series with coefficients that alternate in sign, but do not satisfy the <strong>general martingale algorithm</strong> or <strong>Algorithm 1</strong> below.  This includes nearly all such series that equal 0 at 0 and 1 at 1, or equal 0 at 1 and 1 at 0. (An example is $\sin(\lambda\pi/2)$.)</li>
<li>Series with negative and positive coefficients that do not eventually alternate in sign (ignoring zeros).</li>
</ul>
</blockquote>

<p><a id=Certain_Alternating_Series></a></p>

<h4>Certain Alternating Series</h4>

<p>Suppose the following holds true for a power series function $f(\lambda)$:</p>

<ul>
<li>$f$ is written as in equation $(1)$.</li>
<li>Suppose $(a_i)$ is the sequence formed from the coefficients of the series.</li>
<li>Let $(d_j)$ be the sequence formed from $(a_i)$ by deleting the zero coefficients.  Then suppose that:

<ul>
<li>$d_0$ is greater than 0, and the elements in $(d_j)$ alternate in sign (example: 1/2, -1/3, 1/4, -1/5, ...).</li>
<li>The absolute values of $(d_j)$&#39;s elements are 1 or less and form a nowhere increasing sequence that is finite or converges to 0.</li>
</ul></li>
</ul>

<p>In addition, the coefficients should be rational numbers.</p>

<blockquote>
<p><strong>Example:</strong> Let $f(\lambda) = (1/2)\lambda^0 - (1/4)\lambda^2 + (1/8)\lambda^4 - ...$.  Then $(a_i) = (1/2, 0, -1/4, 0, 1/8, ...)$ (for example, $a_0 = 1/2$) and deleting the zeros leads to $(d_i) = (1/2, -1/4, 1/8, ...)$  (for example, $d_0 = 1/2$), which meets the requirements above.</p>
</blockquote>

<p>Then the algorithm below, based on an algorithm by Łatuszyński et al. (2009/2011, especially section 3.1)[^1], simulates $f(\lambda)$ given a coin that shows heads (returns 1) with probability $g(\lambda)$.</p>

<p><strong>General martingale algorithm:</strong></p>

<ol>
<li>Set <em>u</em> to abs($d_0$) ($d_0$ is the value of the first nonzero coefficient in the sequence $(a_i)$), set <em>w</em> to 1, set <em>&#x2113;</em> to 0, and set <em>n</em> to 1.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>If <em>w</em> is not 0, run a Bernoulli factory algorithm for $g(\lambda)$ (if $g(\lambda) = \lambda$, this is done by flipping the input coin), then multiply <em>w</em> by the result of the run.</li>
<li>If $a_n$ is greater than 0: Set <em>u</em> to <em>&#x2113;</em> + <em>w</em> * $a_n$, then, if no further nonzero coefficients follow $a_n$, set <em>&#x2113;</em> to <em>u</em>.</li>
<li>If $a_n$ is less than 0: Set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em> * abs($a_n$), then, if no further nonzero coefficients follow $a_n$, set <em>u</em> to <em>&#x2113;</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  Otherwise, if <em>ret</em> is less than <em>u</em>, add 1 to <em>n</em>.  Otherwise, return 0.  (If <em>ret</em> is a uniform partially-sampled random number [PSRN], these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
</ol></li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>The <strong>general martingale algorithm</strong>, as it&#39;s called in this article, supports more functions than in section 3.1 of Łatuszyński et al. (2019/2011), which supports only power series whose coefficients alternate in sign and decrease in absolute value, with no zeros in between nonzero coefficients.  However, the general martingale algorithm uses that paper&#39;s framework.  A proof of its correctness is given in the appendix.</li>
<li>The <strong>general martingale algorithm</strong> allows the sequence $(a_i)$ to sum to 1, but this appears to be possible only if the sequence&#39;s nonzero values have the form $(1, -z_0, z_0, -z_1, z_1, ..., -z_i, z_i, ...)$, where the $z_i$ are positive, are no greater than 1, and form a nowhere increasing sequence that is finite or converges to 0.  Moreover, it appears that every power series with this sequence of coefficients is less than or equal to $\lambda$.</li>
</ol>
</blockquote>

<p><a id=General_Power_Series></a></p>

<h4>General Power Series</h4>

<p>The algorithm that follows can be used to simulate a more general class of power series functions.  Suppose the following for a power series function $f(\lambda)$:</p>

<ul>
<li>$f$ is written as in equation $(1)$.</li>
<li>There is a rational number $Z$ defined as follows. For every $\lambda$ that satisfies $0 \le \lambda \le 1$, it is true that $0 \le f(\lambda) \le Z \lt 1$.</li>
<li>There is an even integer $m$ defined as follows. The series in equation $(1)$ can be split into two parts: the first part ($A$) is the sum of the first $m$ terms, and the second part ($C$) is the sum of the remaining terms.  Moreover, both parts admit a Bernoulli factory algorithm (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#About_Bernoulli_Factories"><strong>About Bernoulli Factories</strong></a>&quot; in the &quot;Bernoulli Factory Algorithms&quot; article).  Specifically: $$C(\lambda) = \sum_{i\ge m} a_i (g(\lambda))^i, A(\lambda) = f(\lambda) - C(\lambda).$$  As an example, if $C$ is a power series function described in the section &quot;Certain Alternating Series&quot;, above, then $C$ admits a Bernoulli factory algorithm, namely the <strong>general martingale algorithm</strong>.</li>
</ul>

<p>In addition, the algorithm will be simpler if each coefficient $a_i$ is a rational number.</p>

<p>Then rewrite the function as&mdash; $$f(\lambda) = A(\lambda) + (g(\lambda))^{m} B(\lambda),$$ where&mdash;</p>

<ul>
<li>$A(\lambda) = f(\lambda) - C(\lambda) = \sum_{i=0}^{m-1} a_i (g(\lambda))^i$ is a polynomial in $g(\lambda)$ of degree $m-1$, and</li>
<li>$B(\lambda) = C(\lambda) / (g(\lambda))^{m} = \sum_{i\ge m} a_{m+i} (g(\lambda))^i$.</li>
</ul>

<p>Rewrite $A$ as a polynomial in Bernstein form, in the variable $g(\lambda)$. (One way to transform a polynomial to Bernstein form, given the &quot;power&quot; coefficients $a_0, ..., a_{m-1}$, is the so-called &quot;matrix method&quot; from Ray and Nataraj (2012)[^2].)  Let $b_0, ..., b_{m-1}$ be the Bernstein-form polynomial&#39;s coefficients.  Then if those coefficients all lie in $[0, 1]$, then the following algorithm simulates $f(\lambda)$.</p>

<p><strong>Algorithm 1:</strong> Run a <a href="https://peteroupc.github.io/bernoulli.html#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a>, with parameters $x=2$, $y=1$, and $\epsilon=1-Z$.  Whenever the linear Bernoulli factory &quot;flips the input coin&quot;, it runs the sub-algorithm below.</p>

<ul>
<li><p><strong>Sub-algorithm:</strong> Generate an unbiased random bit.  If that bit is 1, sample the polynomial $A$ as follows (Goyal and Sigman 2012)[^9]:</p>

<ol>
<li>Run a Bernoulli factory algorithm for $g(\lambda)$, $m-1$ times.  Let $j$ be the number of runs that return 1.</li>
<li>With probability $b_j$, return 1.  Otherwise, return 0.</li>
</ol>

<p>If the bit is 0, do the following:</p>

<ol>
<li>Run a Bernoulli factory algorithm for $g(\lambda)$, $m$ times.  Return 0 if any of the runs returns 0.</li>
<li>Run a Bernoulli factory algorithm for $B(\lambda)$, and return the result.</li>
</ol></li>
</ul>

<p><a id=Series_with_Non_Negative_Coefficients_Summing_to_1_or_Less></a></p>

<h4>Series with Non-Negative Coefficients Summing to 1 or Less</h4>

<p>Now, suppose $f(\lambda)$ can be written as a power series in equation $(1)$, but this time, the <em>coefficients</em> $a_i$ are 0 or greater and their sum is 1 or less.</p>

<p>If $g(\lambda) = \lambda$, this kind of function&mdash;</p>

<ul>
<li>satisfies $0\le f(\lambda)\le 1$ whenever 0 &le; <em>&lambda;</em> &le; 1,</li>
<li>is either constant or strictly increasing, and</li>
<li>is <em>convex</em> (its &quot;slope&quot; or &quot;velocity&quot; doesn&#39;t decrease as <em>&lambda;</em> increases)[^3].</li>
</ul>

<p>Suppose $f$ can be written as $f(\lambda)= f_0(g(\lambda))$, where&mdash; $$f_0(\lambda) = \sum_{n} a_n \lambda^n = \sum_{n} w(n) \frac{a_n}{w(n)}\lambda^n,$$ where each sum is taken over all nonnegative values of $n$ where $a_n &gt; 0$.[^4]</p>

<p>Then the key to simulating $f(\lambda)$ is to &quot;tuck&quot; the values $a_n$ under a function $w(n)$ such that&mdash;</p>

<ul>
<li>$1 \ge w(n)\ge a_n\ge 0$ for every allowed <em>n</em>, and</li>
<li>$w(0)+w(1)+...=1$ (required for a valid distribution of integers 0 or greater).</li>
</ul>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>Assuming $f_0(1)$ does not equal 0, an appropriate $w(n)$ is trivial to find &mdash; $w(n)=a_n/f_0(1)$ (because $a_n \le f_0(1)$ for every allowed $n$).  But in general, this can make $w(n)$ an irrational number and thus harder to handle with arbitrary precision.</li>
<li>If the coefficients $a_n$ sum to 1, then $w(n)$ can equal $a_n$.  In this case, $f_0(\lambda)$ is what&#39;s called the <em>probability generating function</em> for getting $X$ with probability $a_X$ (or $w(X)$), and the expected value (&quot;long-run average&quot;) of $X$ equals the &quot;slope&quot; of $f_0(\lambda)$ at 1.  See also (Dughmi et al. 2021)[^5].</li>
<li>Assuming $f_0(1)$ is an irrational number, $w(n)$ can equal $a_n + c_n/2^n$, where $c_n$ is the $n$-th base-2 digit after the point in the binary expansion of $1 - f_0(1)$ (or 0 if $n=0$).  Here, a number&#39;s <em>binary expansion</em> is written as <code>0.bbbbb...</code> in base 2, where each <code>b</code> is a base-2 digit (either 0 or 1).  See my <a href="https://math.stackexchange.com/questions/4495216"><strong>Stack Exchange question</strong></a>.</li>
</ol>
</blockquote>

<p>Once $a_n$ and $w(n)$ are found, the function $f(\lambda)$ can be simulated using the following algorithm, which takes advantage of the <a href="https://peteroupc.github.io/bernoulli.html#Convex_Combinations"><strong>convex combination method</strong></a>.</p>

<p><strong>Algorithm 2:</strong></p>

<ol>
<li>Choose at random an integer <em>n</em> that equals <em>i</em> with probability $w(i)$.</li>
<li>(The next two steps succeed with probability $\frac{a_n}{w(n)} (g(\lambda))^n$.) Let <em>P</em> be $a_n/w(n)$.  With probability <em>P</em>, go to the next step.  Otherwise, return 0.</li>
<li>(At this point, <em>n</em> equals <em>i</em> with probability $a_i$.) Run a Bernoulli factory algorithm for $g(\lambda)$, <em>n</em> times or until a run returns 0, whichever happens first. (For example, if $g(\lambda)=\lambda$, flip the input coin each time.)  Return 1 if all the runs, including the last, returned 1 (or if <em>n</em> is 0).  Otherwise, return 0.</li>
</ol>

<p>Step 1 is rather general, and doesn&#39;t fully describe how to generate the value $n$ at random.  That depends on the function $w(n)$.  See &quot;<a href="#Power_Series_Examples"><strong>Power Series Examples</strong></a>&quot;, later, for examples of power series functions $f(\lambda)$ that can be simulated using Algorithm 2.</p>

<blockquote>
<p><strong>Note:</strong> Part of <strong>Algorithm 2</strong> involves choosing $X$ at random with probability $w(X)$, then doing $X$ coin flips.  Thus, the algorithm uses, on average, at least the number of unbiased random bits needed to generate $X$ on average (Knuth and Yao 1976)[^6].</p>
</blockquote>

<p><strong>Algorithm 2</strong> covers an algorithm that was given by Luis Mendo (2019)[^7] for simulating certain power series, but that works only if the coefficients sum to 1 or less and only if coefficient 0 ($a_0$) is 0.</p>

<p>To get to an algorithm equivalent to Mendo&#39;s, first <strong>Algorithm 2</strong> is modified to simulate $f_0(\lambda)$/<em>CS</em> as follows, where <em>CS</em> is the sum of all coefficients $a_i$, starting with $i=1$.  This shows Mendo&#39;s algorithm, like <strong>Algorithm 2</strong>, is actually a special case of the <a href="https://peteroupc.github.io/bernoulli.html#Convex_Combinations"><strong>convex combination algorithm</strong></a>.</p>

<ul>
<li>Step 1 of <strong>Algorithm 2</strong> becomes: &quot;(1a.) Set <em>dsum</em> to 0 and $n$ to 1; (1b.) With probability $a_n$/(<em>CS</em> &minus; <em>dsum</em>), go to step 2. Otherwise, add $a_n$ to <em>dsum</em>; (1c.) Add 1 to <em>i</em> and go to step 1b.&quot; (Choose at random $n$ with probability $w(n)=a_n$/<em>CS</em>.)</li>
<li>Step 2 becomes &quot;Go to step 3&quot;. (The <em>P</em> in <strong>Algorithm 2</strong> is not used; it&#39;s effectively $w(n)/\frac{a_n}{CS}=\frac{a_n}{CS}/\frac{a_n}{CS} = 1$.)</li>
<li>In step 3, $g(\lambda)$ is either $\lambda$ (flip the input coin) or $1-\lambda$ (flip the input coin and take 1 minus the flip).</li>
</ul>

<p>Mendo&#39;s algorithm and extensions of it mentioned by him cover several variations of power series as follows:</p>

<table><thead>
<tr>
<th>Type</th>
<th>Power Series</th>
<th>Algorithm</th>
</tr>
</thead><tbody>
<tr>
<td>1</td>
<td>$f(\lambda)=1-f_0(1-\lambda)$</td>
<td>With probability <em>CS</em>, run the modified algorithm with $g(\lambda)=1-\lambda$ and return 1 minus the result.  Otherwise, return 1.</td>
</tr>
<tr>
<td>2</td>
<td>$f(\lambda)=f_0(1-\lambda)$</td>
<td>With probability <em>CS</em>, run the modified algorithm with $g(\lambda)=1-\lambda$ and return the result.  Otherwise, return 0.</td>
</tr>
<tr>
<td>3</td>
<td>$f(\lambda)=f_0(\lambda)$</td>
<td>With probability <em>CS</em>, run the modified algorithm with $g(\lambda)=\lambda$ and return the result.  Otherwise, return 0.</td>
</tr>
<tr>
<td>4</td>
<td>$f(\lambda)=1-f_0(\lambda)$</td>
<td>With probability <em>CS</em>, run the modified algorithm with $g(\lambda)=\lambda$ and return 1 minus the result.  Otherwise, return 1.</td>
</tr>
</tbody></table>

<p>The conditions on $f$ given above mean that&mdash;</p>

<ul>
<li>for series of type 1, <em>f</em>(0) = 1&minus;<em>CS</em> and <em>f</em>(1) = 1 (series of type 1 with <em>CS</em>=1 is the main form in Mendo&#39;s paper),</li>
<li>for series of type 2, <em>f</em>(0) = <em>CS</em> and <em>f</em>(1) = 0,</li>
<li>for series of type 3, <em>f</em>(0) = 0 and <em>f</em>(1) = <em>CS</em>, and</li>
<li>for series of type 4, <em>f</em>(0) = 1 and <em>f</em>(1) = 1&minus;<em>CS</em>.</li>
</ul>

<p><a id=Series_with_General_Non_Negative_Coefficients></a></p>

<h4>Series with General Non-Negative Coefficients</h4>

<p>If $f$ is a power series written as equation (1), but&mdash;</p>

<ul>
<li>each of the coefficients is positive or zero, and</li>
<li>the coefficients sum to greater than 1,</li>
</ul>

<p>then Nacu and Peres (2005, proposition 16)[^1] gave an algorithm which takes the following parameters:</p>

<ul>
<li><em>t</em> is a rational number such that <em>B</em> &lt; <em>t</em> &le; 1 and  <em>f</em>(<em>t</em>) &lt; 1.</li>
<li><em>&#x03F5;</em> is a rational number such that 0 &lt; <em>&#x03F5;</em> &le; (<em>t</em> &minus; <em>B</em>)/2.</li>
</ul>

<p><em>B</em> is not a parameter, but is the maximum allowed value for $g(\lambda)$ (probability of heads), and is greater than 0 and less than 1.  The following algorithm is based on that algorithm, but runs a Bernoulli factory for $g(\lambda)$ instead of flipping the input coin with probability of heads $\lambda$.</p>

<ol>
<li>Create a <em>&nu;</em> input coin that does the following: &quot;(1) Set <em>n</em> to 0. (2) With probability <em>&#x03F5;</em>/<em>t</em>, go to the next substep.  Otherwise, add 1 to <em>n</em> and repeat this substep. (3) With probability 1 &minus; $a_n\cdot t^n$, return 0. (4) Run a <a href="https://peteroupc.github.io/bernoulli.html#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> <em>n</em> times, <em>x</em>/<em>y</em> = 1/(<em>t</em> &minus; <em>&#x03F5;</em>), and <em>&#x03F5;</em> = <em>&#x03F5;</em>.  If the linear Bernoulli factory would flip the input coin, the coin is &#39;flipped&#39; by running a Bernoulli factory for $g(\lambda)$.  If any run of the linear Bernoulli factory returns 0, return 0.  Otherwise, return 1.&quot;</li>
<li>Run a <a href="https://peteroupc.github.io/bernoulli.html#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> once, using the <em>&nu;</em> input coin described earlier, <em>x</em>/<em>y</em> = <em>t</em>/<em>&#x03F5;</em>, and <em>&#x03F5;</em> = <em>&#x03F5;</em>, and return the result.</li>
</ol>

<p><a id=Power_Series_Examples></a></p>

<h4>Power Series Examples</h4>

<p>Examples 1 to 4 show how <strong>Algorithm 1</strong> leads to algorithms for simulating certain factory functions.</p>

<blockquote>
<p><strong>Note:</strong> In the SymPy computer algebra library, the <code>series(func, x, n=20)</code> method computes the terms of a function&#39;s power series up to the term with $x^{19}$.  An example is: <code>series(sin(x), x, n=20)</code>.</p>
</blockquote>

<p><strong>Example 1:</strong> Take $f(\lambda) = \sin(3\lambda)/2$, which is a power series.</p>

<ul>
<li>$f$ is less than or equal to $Z=1/2 \lt 1$.</li>
<li>$f$ satisfies $m=8$ since splitting the series at 8 leads to two functions that admit Bernoulli factories.</li>
<li>Thus, $f$ can be written as&mdash; $$f(\lambda) = A(\lambda) + \lambda^8 \left(\sum_{i\ge 0} a_{8+i} \lambda^i\right),$$ where $a_i = \frac{3^i}{i! \times 2}(-1)^{(i-1)/2}$ if $i$ is odd and 0 otherwise.</li>
<li>$A$ is rewritten from &quot;power&quot; form (with coefficients $a_0, ..., a_{m-1}$) to Bernstein form, with the following coefficients, in order: [0, 3/14, 3/7, 81/140, 3/5, 267/560, 81/280, 51/1120].</li>
<li>Now, <strong>Algorithm 1</strong> can be used to simulate $f$ given a coin that shows heads (returns 1) with probability $\lambda$, where:

<ul>
<li>$g(\lambda) = \lambda$, so the Bernoulli factory algorithm for $g(\lambda)$ is simply to flip the coin for $\lambda$.</li>
<li>The coefficients $b_0, ..., b_{m-1}$, in order, are the Bernstein-form coefficients found for $A$.</li>
<li>The Bernoulli factory algorithm for $B(\lambda)$ is as follows: Let $h_i = a_i$.  Then run the <strong>general martingale algorithm</strong> with $g(\lambda) = \lambda$ and $a_i = h_{m+i}$.</li>
</ul></li>
</ul>

<p><strong>Example 2:</strong> Take $f(\lambda) = 1/2 + \sin(6\lambda)/4$, rewritable as another power series.</p>

<ul>
<li>$f$ is less than or equal to $Z=3/4 \lt 1$.</li>
<li>$f$ satisfies $m=16$ since splitting the series at 16 leads to two functions that admit Bernoulli factories.</li>
<li>Thus, $f$ can be written as&mdash; $$f(\lambda) = A(\lambda) + \lambda^{m} \left(\sum_{i\ge 0} a_{m+i} \lambda^i\right),$$ where $m=16$, and where $a_i$ is $1/2$ if $i = 0$; $\frac{6^i}{i! \times 4}(-1)^{(i-1)/2}$ if $i$ is odd; and 0 otherwise.</li>
<li>$A$ is rewritten from &quot;power&quot; form (with coefficients $a_0, ..., a_{m-1}$) to Bernstein form, with the following coefficients, in order: [1/2, 3/5, 7/10, 71/91, 747/910, 4042/5005, 1475/2002, 15486/25025, 167/350, 11978/35035, 16869/70070, 167392/875875, 345223/1751750, 43767/175175, 83939/250250, 367343/875875].</li>
<li>Now, <strong>Algorithm 1</strong> can be used to simulate $f$ in the same manner as for Example 1.</li>
</ul>

<p><strong>Example 3:</strong> Take $f(\lambda) = 1/2 + \sin(\pi\lambda)/4$.  To simulate this probability:</p>

<ol>
<li>Create a <em>&mu;</em> coin that does the following: &quot;With probability 1/3, return 0.  Otherwise, run the algorithm for <strong><em>&pi;</em>/4</strong> (in &#39;Bernoulli Factory Algorithms&#39;) and return the result.&quot; (Simulates <em>&pi;</em>/6.)</li>
<li>Run the algorithm for $1/2 + \sin(6\lambda)/4$ in Example 2, using the <em>&mu;</em> coin.</li>
</ol>

<p><strong>Example 4:</strong> Take $f(\lambda) = 1/2 + \cos(6\lambda)/4$.  This is as in Example 2, except&mdash;</p>

<ul>
<li>$Z=3/4$ and $m=16$;</li>
<li>$a_i$ is $3/4$ if $i = 0$; $\frac{6^i}{i! \times 4}(-1)^{i/2}$ if $i$ is even and greater than 0; and 0 otherwise; and</li>
<li>the Bernstein-form coefficients for $A$, in order, are [3/4, 3/4, 255/364, 219/364, 267/572, 1293/4004, 4107/20020, 417/2860, 22683/140140, 6927/28028, 263409/700700, 2523/4900, 442797/700700, 38481/53900, 497463/700700].</li>
</ul>

<p><strong>Example 5:</strong> Take $f(\lambda) = 1/2 + \cos(\pi\lambda)/4$.  This is as in Example 3, except step 2 runs the algorithm for $1/2 + \cos(6\lambda)/4$ in Example 4.</p>

<p><strong>Examples 6:</strong> The following functions can be written as power series that satisfy the <strong>general martingale algorithm</strong>.  In the table, $B(i)$ is the $i$<sup>th</sup> <em>Bernoulli number</em> (see the note after the table), and ${n \choose m}$ = choose($n$, $m$) is a binomial coefficient.</p>

<table><thead>
<tr>
<th>Function $f(\lambda)$</th>
<th>Coefficients</th>
<th>Value of $d_0$</th>
</tr>
</thead><tbody>
<tr>
<td>$\lambda/(\exp(\lambda)-1)$</td>
<td>$a_i = -1/2$ if $i=1$, or $B(i)/(i!)$ otherwise.</td>
<td>1.</td>
</tr>
<tr>
<td>Hyperbolic tangent: $\tanh(\lambda)$</td>
<td>$a_i = \frac{B(i+1) 2^{i+1} (2^{i+1}-1)}{(i+1)!}$ if $i$ is odd[^8], or 0 otherwise.</td>
<td>1.</td>
</tr>
<tr>
<td>$\cos(\sqrt \lambda)$</td>
<td>$a_i = \frac{(-1)^i}{(2i)!}$.</td>
<td>1.</td>
</tr>
<tr>
<td>$\sum_{i\ge 0} a_i x^i$ (<a href="https://math.stackexchange.com/questions/855517"><strong>source</strong></a>)</td>
<td>$a_i = \frac{(-1)^i 4^i}{(2i+1)^2 {2i \choose i}}$.</td>
<td>1.</td>
</tr>
</tbody></table>

<p>To simulate a function in the table, run the <strong>general martingale algorithm</strong> with $g(\lambda) = \lambda$ and with the given coefficients and value of $d_0$ ($d_0$ is the first nonzero coefficient).</p>

<blockquote>
<p><strong>Note:</strong> Bernoulli numbers can be computed with the following algorithm, namely <strong>Get the <em>m</em><sup>th</sup> Bernoulli number</strong>:</p>

<ol>
<li>If <em>m</em> is 0, 1, 2, 3, or 4, return 1, 1/2, 1/6, 0, or &minus;1/30, respectively.  Otherwise, if <em>m</em> is odd[^8], return 0.</li>
<li>Set <em>i</em> to 2 and <em>v</em> to 1 &minus; (<em>m</em>+1)/2.</li>
<li>While <em>i</em> is less than <em>m</em>:

<ol>
<li><strong>Get the <em>i</em><sup>th</sup> Bernoulli number</strong>, call it <em>b</em>.  Add <em>b</em>*choose(<em>m</em>+1, <em>i</em>) to <em>v</em>.[^9]</li>
<li>Add 2 to <em>i</em>.</li>
</ol></li>
<li>Return &minus;<em>v</em>/(<em>m</em>+1).</li>
</ol>
</blockquote>

<p>Examples 7 to 9 use <strong>Algorithm 2</strong> to simulate power series functions where the coefficients $a_0$ are nonnegative.</p>

<p><strong>Example 7:</strong> The hyperbolic cosine minus 1, denoted as cosh(<em>&lambda;</em>)&minus;1, can be written as follows: $$f(\lambda)=\cosh(\lambda)-1 = \sum_{n} a_n \lambda^n = \sum_{n} w(n) \frac{a_n \lambda^n}{w(n)},$$ where:</p>

<ul>
<li>Each sum given above is taken over all values of <em>n</em> that can occur after step 1 is complete (in this case, all values of <em>n</em> that are even and greater than 0).</li>
<li>$a_n$ is $1/(n!)$.[^10]</li>
<li>The coefficients $a_n$ are tucked under a function $w(n)$, which in this case is $\frac{1}{2^{n-2}}$ if <em>n</em>&gt;0 and <em>n</em> is even[^11], or 0 otherwise.</li>
</ul>

<p>For this particular function:</p>

<ul>
<li>Step 1 of <strong>Algorithm 2</strong> can read: &quot;(1a.) Generate unbiased random bits (each bit is 0 or 1 with equal probability) until a zero is generated this way, then set <em>n</em> to the number of ones generated this way; (1b.) Set <em>n</em> to 2*<em>n</em> + 2.&quot;</li>
<li>In step 2, <em>P</em> is $a_n/w(n) = \frac{1}{n!} / \frac{1}{2^{n-2}} = \frac{2^{n/2}}{n!}$ for each allowed $n$.</li>
<li>In step 3, $g(\lambda)$ is simply $\lambda$.</li>
</ul>

<p><strong>Examples 8:</strong> cosh(<em>&lambda;</em>)&minus;1 and additional target functions are shown in the following table.  (In the table below, $w(n)=1/(2^{w^{-1}(n)+1})$ where $w^{-1}(n)$ is the inverse of the &quot;Step 1b&quot; column, and the $g(\lambda)$ in step 3 is simply $\lambda$.)</p>

<table><thead>
<tr>
<th>Target function <em>f</em>(<em>&lambda;</em>)</th>
<th>Step 1b in <strong>Example 7</strong> reads &quot;Set <em>n</em> to ...&quot;</th>
<th>$a_n$</th>
<th>$w(n)$</th>
<th>Value of <em>P</em></th>
</tr>
</thead><tbody>
<tr>
<td>cosh(<em>&lambda;</em>)&minus;1.</td>
<td>2*<em>n</em> + 2.</td>
<td>1/(<em>n</em>!).</td>
<td>1/(2<sup>(n&minus;2)/2+1</sup>).</td>
<td>2<sup><em>n</em>/2</sup>/(<em>n</em>!).</td>
</tr>
<tr>
<td>exp(<em>&lambda;</em>/4)/2.</td>
<td><em>n</em>.</td>
<td>1/(<em>n</em>!*2*4<sup><em>n</em></sup>)</td>
<td>1/(2<sup><em>n</em>+1</sup>).</td>
<td>1/(2<sup><em>n</em></sup>*(<em>n</em>!)).</td>
</tr>
<tr>
<td>exp(<em>&lambda;</em>)/4.</td>
<td><em>n</em>.</td>
<td>1/(<em>n</em>!*4).</td>
<td>1/(2<sup><em>n</em>+1</sup>).</td>
<td>2<sup><em>n</em>&minus;1</sup>/(<em>n</em>!).</td>
</tr>
<tr>
<td>exp(<em>&lambda;</em>)/6.</td>
<td><em>n</em>.</td>
<td>1/(<em>n</em>!*6).</td>
<td>1/(2<sup><em>n</em>+1</sup>).</td>
<td>2<sup><em>n</em></sup>/(3*(<em>n</em>!)).</td>
</tr>
<tr>
<td>exp(<em>&lambda;</em>/2)/2.</td>
<td><em>n</em>.</td>
<td>1/(<em>n</em>!*2*2<sup><em>n</em></sup>)</td>
<td>1/(2<sup><em>n</em>+1</sup>).</td>
<td>1/(<em>n</em>!).</td>
</tr>
<tr>
<td>(exp(<em>&lambda;</em>)&minus;1)/2.</td>
<td><em>n</em> + 1.</td>
<td>1/((<em>n</em>+1)!*4).</td>
<td>1/(2<sup><em>n</em></sup>).</td>
<td>2<sup><em>n</em>&minus;1</sup>/(<em>n</em>!).</td>
</tr>
<tr>
<td>sinh(<em>&lambda;</em>)/2</td>
<td>2*<em>n</em> + 1.</td>
<td>1/(<em>n</em>!*2).</td>
<td>1/(2<sup>(<em>n</em>&minus;1)/2+1</sup>).</td>
<td>2<sup>(<em>n</em>&minus;1)/2</sup>/(<em>n</em>!).</td>
</tr>
<tr>
<td>cosh(<em>&lambda;</em>)/2</td>
<td>2*<em>n</em>.</td>
<td>1/(<em>n</em>!*2).</td>
<td>1/(2<sup><em>n</em>/2+1</sup>).</td>
<td>2<sup><em>n</em>/2</sup>/(<em>n</em>!).</td>
</tr>
</tbody></table>

<p><strong>Examples 9:</strong> The table below shows power series functions shifted downward and shows the algorithm changes needed to simulate the modified function.  In the table, <em>D</em> is a rational number such that 0 &le; <em>D</em> &le; <em>&phi;</em>(0), where <em>&phi;</em>(.) is the original function.</p>

<table><thead>
<tr>
<th>Original function (<em>&phi;</em>(<em>&lambda;</em>))</th>
<th>Target function <em>f</em>(<em>&lambda;</em>)</th>
<th>Step 1b in <strong>Example 7</strong> reads &quot;Set <em>n</em> to ...&quot;</th>
<th>Value of <em>P</em></th>
</tr>
</thead><tbody>
<tr>
<td>exp(<em>&lambda;</em>)/4.</td>
<td><em>&phi;</em>(<em>&lambda;</em>) &minus; <em>D</em>.</td>
<td><em>n</em>.</td>
<td>(1/4&minus;<em>D</em>)*2 or (<em>&phi;</em>(0)&minus;<em>D</em>)*2 if <em>n</em> = 0;<br>2<sup><em>n</em>&minus;1</sup>/(<em>n</em>!) otherwise.</td>
</tr>
<tr>
<td>exp(<em>&lambda;</em>)/6.</td>
<td><em>&phi;</em>(<em>&lambda;</em>) &minus; <em>D</em>.</td>
<td><em>n</em>.</td>
<td>(1/6&minus;<em>D</em>)*2 if <em>n</em> = 0;<br>2<sup><em>n</em></sup>/(3*(<em>n</em>!)) otherwise.</td>
</tr>
<tr>
<td>exp(<em>&lambda;</em>/2)/2.</td>
<td><em>&phi;</em>(<em>&lambda;</em>) &minus; <em>D</em>.</td>
<td><em>n</em>.</td>
<td>(1/2&minus;<em>D</em>)*2 if <em>n</em> = 0;<br>1/(<em>n</em>!) otherwise.</td>
</tr>
<tr>
<td>cosh(<em>&lambda;</em>)/4.</td>
<td><em>&phi;</em>(<em>&lambda;</em>) &minus; <em>D</em>.</td>
<td>2*<em>n</em>.</td>
<td>(1/4&minus;<em>D</em>)*2 if <em>n</em> = 0;<br>2<sup><em>n</em>/2</sup>/(2*(<em>n</em>!)) otherwise.</td>
</tr>
</tbody></table>

<p><strong>Example 10:</strong> Let $f(\lambda)=exp(\lambda)\cdot (1-\lambda)$.  Run Mendo&#39;s algorithm for series of type 1, with $a_i = \frac{i-1}{i!}$ and $CS = 1$.</p>

<p><a id=Certain_Piecewise_Linear_Functions></a></p>

<h3>Certain Piecewise Linear Functions</h3>

<p>Let <em>f</em>(<em>&lambda;</em>) be a function of the form min(<em>&lambda;</em>*<em>mult</em>, 1&minus;<em>&epsilon;</em>). This is a <em>piecewise linear function</em>, a function made up of two linear pieces (in this case, the pieces are a rising linear part and a constant part).</p>

<p>This section describes how to calculate the Bernstein coefficients for polynomials that converge from above and below to <em>f</em>, based on Thomas and Blanchet (2012)[^12].  These polynomials can then be used to show heads with probability <em>f</em>(<em>&lambda;</em>) using the algorithms given in &quot;<a href="https://peteroupc.github.io/bernoulli.html#General_Factory_Functions"><strong>General Factory Functions</strong></a>&quot;.</p>

<p>In this section, <strong>fbelow(<em>n</em>, <em>k</em>)</strong> and <strong>fabove(<em>n</em>, <em>k</em>)</strong> are the <em>k</em><sup>th</sup> coefficients (with <em>k</em> starting at 0) of the lower and upper polynomials, respectively, in Bernstein form of degree <em>n</em>.</p>

<p>The code in the <a href="#Appendix"><strong>appendix</strong></a> uses the computer algebra library SymPy to calculate a list of parameters for a sequence of polynomials converging from above.  The method to do so is called <code>calc_linear_func(eps, mult, count)</code>, where <code>eps</code> is <em>&epsilon;</em>, <code>mult</code> = <em>mult</em>, and <code>count</code> is the number of polynomials to generate.  Each item returned by <code>calc_linear_func</code> is a list of two items: the degree of the polynomial, and a <em>Y parameter</em>.  The procedure to calculate the required polynomials is then logically as follows (as written, it runs very slowly, though):</p>

<ol>
<li>Set <em>i</em> to 1.</li>
<li>Run <code>calc_linear_func(eps, mult, i)</code> and get the degree and <em>Y parameter</em> for the last listed item, call them <em>n</em> and <em>y</em>, respectively.</li>
<li>Set <em>x</em> to &minus;((<em>y</em>&minus;(1&minus;<em>&epsilon;</em>))/<em>&epsilon;</em>)<sup>5</sup>/<em>mult</em> + <em>y</em>/<em>mult</em>.  (This exact formula doesn&#39;t appear in the Thomas and Blanchet paper; rather it comes from the <a href="https://github.com/acthomasca/rberfac/blob/main/rberfac-public-2.R"><strong>supplemental source code</strong></a> uploaded by A. C. Thomas at my request.)</li>
<li>For degree <em>n</em>, <strong>fbelow(<em>n</em>, <em>k</em>)</strong> is min((<em>k</em>/<em>n</em>)*<em>mult</em>, 1&minus;<em>&epsilon;</em>), and <strong>fabove(<em>n</em>, <em>k</em>)</strong> is min((<em>k</em>/<em>n</em>)*<em>y</em>/<em>x</em>,<em>y</em>).  (<strong>fbelow</strong> matches <em>f</em> because <em>f</em> is <em>concave</em> on the interval [0, 1], which roughly means that its rate of growth there never goes up.)</li>
<li>Add 1 to <em>i</em> and go to step 2.</li>
</ol>

<p>It would be interesting to find general formulas to find the appropriate polynomials (degrees and <em>Y parameters</em>) given only the values for <em>mult</em> and <em>&epsilon;</em>, rather than find them &quot;the hard way&quot; via <code>calc_linear_func</code>.  For this procedure, the degrees and <em>Y parameters</em> can be upper bounds, as long as the sequence of degrees is strictly increasing and the sequence of Y parameters is nowhere increasing.</p>

<blockquote>
<p><strong>Note:</strong> In Nacu and Peres (2005)[^13], the following polynomial sequences were suggested to simulate $\min(2\lambda, 1-2\varepsilon)$, provided $\varepsilon \lt 1/8$, where <em>n</em> is a power of 2.  However, with these sequences, an extraordinary number of input coin flips is required to simulate this function each time.</p>

<ul>
<li><strong>fbelow(<em>n</em>, <em>k</em>)</strong> = $\min(2(k/n), 1-2\varepsilon)$.</li>
<li><strong>fabove(<em>n</em>, <em>k</em>)</strong> = $\min(2(k/n), 1-2\varepsilon)+$<br> $
\frac{2\times\max(0, k/n+3\varepsilon - 1/2)}{\varepsilon(2-\sqrt{2})} \sqrt{2/n}+$<br> $\frac{72\times\max(0,k/n-1/9)}{1-\exp(-2\times\varepsilon^2)} \exp(-2n\times\varepsilon^2)$.</li>
</ul>
</blockquote>

<p><a id=Pushdown_Automata_for_Square_Root_Like_Functions></a></p>

<h3>Pushdown Automata for Square-Root-Like Functions</h3>

<p>In this section, ${n \choose m}$ = choose($n$, $m$) is a binomial coefficient.</p>

<p>The following algorithm extends the square-root construction of Flajolet et al. (2010)[^14], takes an input coin with probability of heads <em>&lambda;</em> (where 0 &le; <em>&lambda;</em> &lt; 1), and returns 1 with probability&mdash;</p>

<p>$$f(\lambda)=\frac{1-\lambda}{\sqrt{1+4\lambda\mathtt{Coin}(\lambda)(\mathtt{Coin}(\lambda)-1)}} = (1-\lambda)\sum_{n\ge 0} \lambda^n (\mathtt{Coin}(\lambda))^n (1-\mathtt{Coin}(\lambda))^n {2n \choose n}$$  $$= (1-\lambda)\sum_{n\ge 0} (\lambda \mathtt{Coin}(\lambda) (1-\mathtt{Coin}(\lambda)))^n {2n \choose n}$$ $$= \sum_{n\ge 0} (1-\lambda) \lambda^n h_n(\lambda) = \sum_{n\ge 0} g(n, \lambda) h_n(\lambda),$$</p>

<p>and 0 otherwise, where:</p>

<ul>
<li><code>Coin</code>(<em>&lambda;</em>) is a Bernoulli factory function. If <code>Coin</code> is a rational function (a ratio of two polynomials) whose coefficients are rational numbers, then <em>f</em> is an <em>algebraic function</em> (a function that can be a solution of a nonzero polynomial equation) and can be simulated by a <em>pushdown automaton</em>, or a state machine with a stack (see the algorithm below and the note that follows it). But this algorithm will still work even if <code>Coin</code> is not a rational function.  In the original square-root construction,  <code>Coin</code>(<em>&lambda;</em>) = 1/2.</li>
<li>$g(n, \lambda) = (1-\lambda) \lambda^n$; this is the probability of running the <code>Coin</code> Bernoulli factory $2 \times n$ times.</li>
<li>$h_n(\lambda) = (\mathtt{Coin}(\lambda))^n (1-\mathtt{Coin}(\lambda))^n {2n \choose n}$; this is the probability of getting as many ones as zeros from the <code>Coin</code> Bernoulli factory.</li>
</ul>

<p>Equivalently&mdash; $$f(\lambda)=(1-\lambda) OGF(\lambda \mathtt{Coin}(\lambda) (1-\mathtt{Coin}(\lambda))),$$ where $OGF(x) = \sum_{n\ge 0} x^n {2n \choose n}$ is the algorithm&#39;s ordinary generating function (also known as counting generating function).</p>

<p>The algorithm follows.</p>

<ol>
<li>Set <em>d</em> to 0.</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>Flip the input coin.  If it returns 1, go to the next substep.  Otherwise, return either 1 if <em>d</em> is 0, or 0 otherwise.</li>
<li>Run a Bernoulli factory algorithm for <code>Coin</code>(<em>&lambda;</em>).  If the run returns 1, add 1 to <em>d</em>.  Otherwise, subtract 1 from <em>d</em>.</li>
<li>Repeat the previous substep.</li>
</ol></li>
</ol>

<blockquote>
<p><strong>Note:</strong> A <em>pushdown automaton</em> is a state machine that keeps a stack of symbols.  In this document, the input for this automaton is a stream of flips of a coin that shows heads with probability <em>&lambda;</em>, and the output is 0 or 1 depending on which state the automaton ends up in when it empties the stack (Mossel and Peres 2005)[^15].  That paper shows that a pushdown automaton, as defined here, can simulate only <em>algebraic functions</em>, that is, functions that can be a solution of a nonzero polynomial equation.  The <a href="#Pushdown_Automata_and_Algebraic_Functions"><strong>appendix</strong></a> defines these machines in more detail and has proofs on which algebraic functions are possible with pushdown automata.</p>

<p>As a pushdown automaton, this algorithm (except the &quot;Repeat the previous substep&quot; part) can be expressed as follows. Let the stack have the single symbol EMPTY, and start at the state POS-S1.  Based on the current state, the last coin flip (HEADS or TAILS), and the symbol on the top of the stack, set the new state and replace the top stack symbol with zero, one, or two symbols.  These <em>transition rules</em> can be written as follows:</p>

<ul>
<li>(POS-S1, HEADS, <em>topsymbol</em>) &rarr; (POS-S2, {<em>topsymbol</em>}) (set state to POS-S2, keep <em>topsymbol</em> on the stack).</li>
<li>(NEG-S1, HEADS, <em>topsymbol</em>) &rarr; (NEG-S2, {<em>topsymbol</em>}).</li>
<li>(POS-S1, TAILS, EMPTY) &rarr; (ONE, {}) (set state to ONE, pop the top symbol from the stack).</li>
<li>(NEG-S1, TAILS, EMPTY) &rarr; (ONE, {}).</li>
<li>(POS-S1, TAILS, X) &rarr; (ZERO, {}).</li>
<li>(NEG-S1, TAILS, X) &rarr; (ZERO, {}).</li>
<li>(ZERO, <em>flip</em>, <em>topsymbol</em>) &rarr; (ZERO, {}).</li>
<li>(POS-S2, <em>flip</em>, <em>topsymbol</em>) &rarr; Add enough transition rules to the automaton to simulate <em>g</em>(<em>&lambda;</em>) by a finite-state machine (only possible if <em>g</em> is rational with rational coefficients (Mossel and Peres 2005)[^15]).  Transition to POS-S2-ZERO if the machine outputs 0, or POS-S2-ONE if the machine outputs 1.</li>
<li>(NEG-S2, <em>flip</em>, <em>topsymbol</em>) &rarr; Same as before, but the transitioning states are NEG-S2-ZERO and NEG-S2-ONE, respectively.</li>
<li>(POS-S2-ONE, <em>flip</em>, <em>topsymbol</em>) &rarr; (POS-S1, {<em>topsymbol</em>, X}) (replace top stack symbol with <em>topsymbol</em>, then push X to the stack).</li>
<li>(POS-S2-ZERO, <em>flip</em>, EMPTY) &rarr; (NEG-S1, {EMPTY, X}).</li>
<li>(POS-S2-ZERO, <em>flip</em>, X) &rarr; (POS-S1, {}).</li>
<li>(NEG-S2-ZERO, <em>flip</em>, <em>topsymbol</em>) &rarr; (NEG-S1, {<em>topsymbol</em>, X}).</li>
<li>(NEG-S2-ONE, <em>flip</em>, EMPTY) &rarr; (POS-S1, {EMPTY, X}).</li>
<li>(NEG-S2-ONE, <em>flip</em>, X) &rarr; (NEG-S1, {}).</li>
</ul>

<p>The machine stops when it removes EMPTY from the stack, and the result is either ZERO (0) or ONE (1).</p>
</blockquote>

<p>For the following algorithm, which extends the end of Note 1 of the Flajolet paper, the probability is&mdash; $$f(\lambda)=(1-\lambda) \sum_{n\ge 0} \lambda^{Hn} \mathtt{Coin}(\lambda)^n (1-\mathtt{Coin}(\lambda))^{Hn-n} {Hn \choose n},$$ where <em>H</em> &ge; 2 is an integer; and <code>Coin</code> has the same meaning as earlier.</p>

<ol>
<li>Set <em>d</em> to 0.</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>Flip the input coin.  If it returns 1, go to the next substep.  Otherwise, return either 1 if <em>d</em> is 0, or 0 otherwise.</li>
<li>Run a Bernoulli factory algorithm for <code>Coin</code>(<em>&lambda;</em>).  If the run returns 1, add (<em>H</em>&minus;1) to <em>d</em>.  Otherwise, subtract 1 from <em>d</em>.</li>
</ol></li>
</ol>

<p>The following algorithm simulates the probability&mdash; $$
f(\lambda) = (1-\lambda) \sum_{n\ge 0} \lambda^n \left( \sum_{m\ge 0} W(n,m) \mathtt{Coin}(\lambda)^m (1-\mathtt{Coin}(\lambda))^{n-m} {n \choose m}\right)$$ $$= (1-\lambda) \sum_{n\ge 0} \lambda^n \left( \sum_{m\ge 0} V(n,m) \mathtt{Coin}(\lambda)^m (1-\mathtt{Coin}(\lambda))^{n-m}\right),$$ where <code>Coin</code> has the same meaning as earlier; <em>W</em>(<em>n</em>, <em>m</em>) is 1 if <em>m</em>*<em>H</em> equals (<em>n</em>&minus;<em>m</em>)*<em>T</em>, or 0 otherwise; and <em>H</em>&ge;1 and <em>T</em>&ge;1 are integers. (In the first formula, the sum in parentheses is a polynomial in Bernstein form, in the variable <code>Coin</code>(<em>&lambda;</em>) and with only zeros and ones as coefficients.  Because of the <em>&lambda;</em><sup><em>n</em></sup>, the polynomial gets smaller as <em>n</em> gets larger.  <em>V</em>(<em>n</em>, <em>m</em>) is the number of <em>n</em>-letter words that have <em>m</em> heads <em>and</em> describe a walk that ends at the beginning.)</p>

<ol>
<li>Set <em>d</em> to 0.</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>Flip the input coin.  If it returns 1, go to the next substep.  Otherwise, return either 1 if <em>d</em> is 0, or 0 otherwise.</li>
<li>Run a Bernoulli factory algorithm for <code>Coin</code>(<em>&lambda;</em>).  If the run returns 1 (&quot;heads&quot;), add <em>H</em> to <em>d</em>.  Otherwise (&quot;tails&quot;), subtract <em>T</em> from <em>d</em>.</li>
</ol></li>
</ol>

<p><a id=Irrational_Probabilities></a></p>

<h2>Irrational Probabilities</h2>

<p><a id=Ratio_of_Lower_Gamma_Functions_gamma__m___x__gamma__m__1></a></p>

<h3>Ratio of Lower Gamma Functions (&gamma;(<em>m</em>, <em>x</em>)/&gamma;(<em>m</em>, 1)).</h3>

<ol>
<li>Set <em>ret</em> to the result of <strong>kthsmallest</strong> with the two parameters <em>m</em> and <em>m</em>.  (Thus, <em>ret</em> is distributed as <em>u</em><sup>1/<em>m</em></sup> where <em>u</em> is a uniform random variate greater than 0 and less than 1; although <strong>kthsmallest</strong> accepts only integers, this formula works for every <em>m</em> greater than 0.)</li>
<li>Set <em>k</em> to 1, then set <em>u</em> to point to the same value as <em>ret</em>.</li>
<li>Generate a uniform(0, 1) random variate <em>v</em>.</li>
<li>If <em>v</em> is less than <em>u</em>: Set <em>u</em> to <em>v</em>, then add 1 to <em>k</em>, then go to step 3.</li>
<li>If <em>k</em> is odd[^8], return a number that is 1 if <em>ret</em> is less than <em>x</em> and 0 otherwise. (If <em>ret</em> is implemented as a uniform partially-sampled random number (PSRN), this comparison should be done via <strong>URandLessThanReal</strong>.)  If <em>k</em> is even[^11], go to step 1.</li>
</ol>

<p>Derivation:  See Formula 1 in the section &quot;<a href="https://peteroupc.github.io/bernoulli.html#Probabilities_Arising_from_Certain_Permutations"><strong>Probabilities Arising from Certain Permutations</strong></a>&quot;, where:</p>

<ul>
<li><code>ECDF(x)</code>  is the probability that a uniform random variate greater than 0 and less than 1 is <em>x</em> or less, namely <em>x</em> if <em>x</em> is in [0, 1], 0 if <em>x</em> is less than 0, and 1 otherwise.</li>
<li><code>DPDF(x)</code> is the probability density function for the maximum of <em>m</em> uniform random variates in [0, 1], namely <em>m</em>*<em>x</em><sup><em>m</em>&minus;1</sup> if <em>x</em> is in [0, 1], and 0 otherwise.</li>
</ul>

<p><a id=4_3___pi></a></p>

<h3>4/(3*<em>&pi;</em>)</h3>

<p>Given that the point (<em>x</em>, <em>y</em>) has positive coordinates and lies inside a disk of radius 1 centered at (0, 0), the mean value of <em>x</em> is 4/(3*<em>&pi;</em>). This leads to the following algorithm to sample that probability:</p>

<ol>
<li>Generate two PSRNs in the form of a uniformly chosen point inside a 2-dimensional quarter hypersphere (that is, a quarter of a &quot;filled circle&quot;; see &quot;<a href="https://peteroupc.github.io/morealg.html#Uniform_Distribution_Inside_N_Dimensional_Shapes"><strong>Uniform Distribution Inside N-Dimensional Shapes</strong></a>&quot; in the article &quot;More Algorithms for Arbitrary-Precision Sampling&quot;, as well as the examples there).</li>
<li>Let <em>x</em> be one of those PSRNs.  Run <strong>SampleGeometricBag</strong> on that PSRN and return the result (which will be either 0 or 1).</li>
</ol>

<blockquote>
<p><strong>Note:</strong> The mean value 4/(3*<em>&pi;</em>) can be derived as follows.  The relative probability that <em>x</em> is &quot;close&quot; to <em>z</em>, where $0\le <em>z</em> \le 1$, is <em>p</em>(<em>z</em>) = sqrt(1 &minus; <em>z</em>*<em>z</em>).  Now find the integral (&quot;area under the graph&quot;) of <em>z</em>*<em>p</em>(<em>z</em>)/<em>c</em> (where <em>c</em>=<em>&pi;</em>/4 is the integral of <em>p</em>(<em>z</em>) on the interval [0, 1]).  The result is the mean value 4/(3*<em>&pi;</em>).  The following Python code prints this mean value using the SymPy computer algebra library: <code>p=sqrt(1-z*z); c=integrate(p,(z,0,1)); print(integrate(z*p/c,(z,0,1)));</code>.</p>
</blockquote>

<p><a id=1_exp__k__1_exp__k__1></a></p>

<h3>(1 + exp(<em>k</em>)) / (1 + exp(<em>k</em> + 1))</h3>

<p>This algorithm simulates this probability by computing lower and upper bounds of exp(1), which improve as more and more digits are calculated.  These bounds are calculated through an algorithm by Citterio and Pavani (2016)[^16].  Note the use of the methodology in Łatuszyński et al. (2009/2011, algorithm 2)[^17] in this algorithm.  In this algorithm, <em>k</em> must be an integer 0 or greater.</p>

<ol>
<li>If <em>k</em> is 0, run the <strong>algorithm for 2 / (1 + exp(2))</strong> and return the result.  If <em>k</em> is 1, run the <strong>algorithm for (1 + exp(1)) / (1 + exp(2))</strong> and return the result.</li>
<li>Generate a uniform(0, 1) random variate, call it <em>ret</em>.</li>
<li>If <em>k</em> is 3 or greater, return 0 if <em>ret</em> is greater than 38/100, or 1 if <em>ret</em> is less than 36/100.  (This is an early return step.  If <em>ret</em> is implemented as a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Set <em>d</em> to 2.</li>
<li>Calculate a lower and upper bound of exp(1) (<em>LB</em> and <em>UB</em>, respectively) in the form of rational numbers whose numerator has at most <em>d</em> digits, using the Citterio and Pavani algorithm.  For details, see later.</li>
<li>Set <em>rl</em> to (1+<em>LB</em><sup><em>k</em></sup>) / (1+<em>UB</em><sup><em>k</em> + 1</sup>), and set <em>ru</em> to (1+<em>UB</em><sup><em>k</em></sup>) / (1+<em>LB</em><sup><em>k</em> + 1</sup>); both these numbers should be calculated using rational arithmetic.</li>
<li>If <em>ret</em> is greater than <em>ru</em>, return 0.  If <em>ret</em> is less than <em>rl</em>, return 1.  (If <em>ret</em> is implemented as a uniform PSRN, these comparisons should be done via <strong>URandLessThanReal</strong>.)</li>
<li>Add 1 to <em>d</em> and go to step 5.</li>
</ol>

<p>The following implements the parts of Citterio and Pavani&#39;s algorithm needed to calculate lower and upper bounds for exp(1) in the form of rational numbers.</p>

<p>Define the following operations:</p>

<ul>
<li><strong>Setup:</strong> Set <em>p</em> to the list <code>[0, 1]</code>, set <em>q</em> to the list <code>[1, 0]</code>, set <em>a</em> to the list <code>[0, 0, 2]</code> (two zeros, followed by the integer part for exp(1)), set <em>v</em> to 0, and set <em>av</em> to 0.</li>
<li><strong>Ensure <em>n</em>:</strong> While <em>v</em> is less than or equal to <em>n</em>:

<ol>
<li>(Ensure partial denominator <em>v</em>, starting from 0, is available.) If <em>v</em> + 2 is greater than or equal to the size of <em>a</em>, append 1, <em>av</em>, and 1, in that order, to the list <em>a</em>, then add 2 to <em>av</em>.</li>
<li>(Calculate convergent <em>v</em>, starting from 0.) Append <em>a</em>[<em>n</em>+2] * <em>p</em>[<em>n</em>+1]+<em>p</em>[<em>n</em>] to the list <em>p</em>, and append <em>a</em>[<em>n</em>+2] * <em>q</em>[<em>n</em>+1]+<em>q</em>[<em>n</em>] to the list <em>q</em>. (Positions in lists start at 0.  For example, <em>p</em>[0] means the first item in <em>p</em>; <em>p</em>[1] means the second; and so on.)</li>
<li>Add 1 to <em>v</em>.</li>
</ol></li>
<li><strong>Get the numerator for convergent <em>n</em>:</strong> Ensure <em>n</em>, then return <em>p</em>[<em>n</em>+2].</li>
<li><strong>Get convergent <em>n</em>:</strong> Ensure <em>n</em>, then return <em>p</em>[<em>n</em>+2]/<em>q</em>[<em>n</em>+2].</li>
<li><strong>Get semiconvergent <em>n</em> given <em>d</em>:</strong>

<ol>
<li>Ensure <em>n</em>, then set <em>m</em> to floor(((10<sup><em>d</em></sup>)&minus;1&minus;<em>p</em>[<em>n</em>+1])/<em>p</em>[<em>n</em>+2]).</li>
<li>Return (<em>p</em>[<em>n</em>+2] * <em>m</em> +<em>p</em>[<em>n</em>+1]) / (<em>q</em>[<em>n</em>+2] * <em>m</em> +<em>q</em>[<em>n</em>+1]).</li>
</ol></li>
</ul>

<p>Then the algorithm to calculate lower and upper bounds for exp(1), given <em>d</em>, is as follows:</p>

<ol>
<li>Set <em>i</em> to 0, then run the <strong>setup</strong>.</li>
<li><strong>Get the numerator for convergent <em>i</em></strong>, call it <em>c</em>. If <em>c</em> is less than 10<sup><em>d</em></sup>, add 1 to <em>i</em> and repeat this step.  Otherwise, go to the next step.</li>
<li><strong>Get convergent <em>i</em> &minus; 1</strong> and <strong>get semiconvergent <em>i</em> &minus; 1 given <em>d</em></strong>, call them <em>conv</em> and <em>semi</em>, respectively.</li>
<li>If (<em>i</em> &minus; 1) is odd[^8], return <em>semi</em> as the lower bound and <em>conv</em> as the upper bound.  Otherwise, return <em>conv</em> as the lower bound and <em>semi</em> as the upper bound.</li>
</ol>

<p><a id=Sampling_Distributions_Using_Incomplete_Information></a></p>

<h2>Sampling Distributions Using Incomplete Information</h2>

<p>The Bernoulli factory is a special case of the problem of <strong>sampling a probability distribution with unknown parameters</strong>.  This problem can be described as sampling from a new distribution using an <em>oracle</em> (black box) that produces numbers of an incompletely known distribution. In the Bernoulli factory problem, this oracle is a <em>coin that shows heads or tails where the probability of heads is unknown</em>.  The rest of this section deals with oracles that go beyond coins.</p>

<p><strong>Algorithm 1.</strong> Suppose there is an oracle that produces independent random variates on a closed interval [<em>a</em>, <em>b</em>], and these numbers have an unknown mean of <em>&mu;</em>. The goal is now to produce nonnegative random variates whose expected value (&quot;long-run average&quot;) is <em>f</em>(<em>&mu;</em>).  Unless <em>f</em> is constant, this is possible if and only if&mdash;</p>

<ul>
<li><em>f</em> is continuous on the closed interval, and</li>
<li><em>f</em>(<em>&mu;</em>) is greater than or equal to <em>&epsilon;</em>*min((<em>&mu;</em> &minus; <em>a</em>)<sup><em>n</em></sup>, (<em>b</em> &minus; <em>&mu;</em>)<sup><em>n</em></sup>) for some integer <em>n</em> and some <em>&epsilon;</em> greater than 0 (loosely speaking, <em>f</em> is nonnegative and neither touches 0 in the interior of the interval nor moves away from 0 more slowly than a polynomial)</li>
</ul>

<p>(Jacob and Thiery 2015)[^18]. (Here, <em>a</em> and <em>b</em> are both rational numbers and may be less than 0.)</p>

<p>In the algorithm below, let <em>K</em> be a rational number greater than the maximum value of <em>f</em> on the closed interval [<em>a</em>, <em>b</em>], and let <em>g</em>(<em>&lambda;</em>) = <em>f</em>(<em>a</em> + (<em>b</em>&minus;<em>a</em>)*<em>&lambda;</em>)/<em>K</em>.</p>

<ol>
<li>Create a <em>&lambda;</em> input coin that does the following: &quot;Take a number from the oracle, call it <em>x</em>.  With probability (<em>x</em>&minus;<em>a</em>)/(<em>b</em>&minus;<em>a</em>) (see note below), return 1.  Otherwise, return 0.&quot;</li>
<li>Run a Bernoulli factory algorithm for <em>g</em>(<em>&lambda;</em>), using the <em>&lambda;</em> input coin.  Then return <em>K</em> times the result.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> The check &quot;With probability (<em>x</em>&minus;<em>a</em>)/(<em>b</em>&minus;<em>a</em>)&quot; is exact if the oracle produces only rational numbers.  If the oracle can produce irrational numbers (such as numbers that follow a beta distribution or another non-discrete distribution), then the code for the oracle should use uniform <a href="https://peteroupc.github.io/exporand.html"><strong>partially-sampled random numbers (PSRNs)</strong></a>.  In that case, the check can be implemented as follows.  Let <em>x</em> be a uniform PSRN representing a number generated by the oracle.  Set <em>y</em> to <strong>RandUniformFromReal</strong>(<em>b</em>&minus;<em>a</em>), then the check succeeds if <strong>URandLess</strong>(<em>y</em>, <strong>UniformAddRational</strong>(<em>x</em>, &minus;<em>a</em>)) returns 1, and fails otherwise.</p>

<p><strong>Example:</strong> Suppose an oracle produces random variates in the interval [3, 13] with unknown mean <em>&mu;</em>, and the goal is to use the oracle to produce nonnegative random variates with mean <em>f</em>(<em>&mu;</em>) = &minus;319/100 + <em>&mu;</em>*103/50 &minus; <em>&mu;</em><sup>2</sup>*11/100, which is a polynomial with Bernstein coefficients [2, 9, 5] in the given interval.  Then since 8 is greater than the maximum of <em>f</em> in that interval, <em>g</em>(<em>&lambda;</em>) is a degree-2 polynomial in the interval [0, 1] that has Bernstein coefficients [2/8, 9/8, 5/8].  <em>g</em> can&#39;t be simulated as is, though, but increasing <em>g</em>&#39;s degree to 3 leads to the Bernstein coefficients [1/4, 5/6, 23/24, 5/8], which are all less than 1 so that the following algorithm can be used (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Polynomials"><strong>Certain Polynomials</strong></a>&quot;):</p>

<ol>
<li>Set <em>heads</em> to 0.</li>
<li>Generate three random variates from the oracle (which must produce random variates in the interval [3, 13]).  For each number <em>x</em>: With probability (<em>x</em>&minus;3)/(10&minus;3), add 1 to <em>heads</em>.</li>
<li>Depending on <em>heads</em>, return 8 (that is, 1 times the upper bound) with the given probability, or 0 otherwise: <em>heads</em>=0 &rarr; probability 1/4; 1 &rarr; 5/6; 2 &rarr; 23/24; 3 &rarr; 5/8.</li>
</ol>
</blockquote>

<p><strong>Algorithm 2.</strong> This algorithm takes an oracle and produces nonnegative random variates whose expected value (&quot;long-run average&quot;) is the mean of <em>f</em>(<em>X</em>), where <em>X</em> is a number produced by the oracle.  The algorithm appears in the appendix, however, because it requires applying an arbitrary function (here, <em>f</em>) to a potentially irrational number.</p>

<p><strong>Algorithm 3.</strong> For this algorithm, see the appendix.</p>

<p><strong>Algorithm 4.</strong> Say there is an oracle in the form of a fair die.  The number of faces of the die, <em>n</em>, is at least 2 but otherwise unknown. Each face shows a different integer 0 or greater and less than <em>n</em>.  The question arises: Which probability distributions based on the number of faces can be sampled with this oracle?  This question was studied in the French-language dissertation of R. Duvignau (2015, section 5.2)[^19], and the following are four of these distributions.</p>

<p><strong><em>Bernoulli 1/n.</em></strong> It&#39;s trivial to generate a Bernoulli variate that is 1 with probability 1/<em>n</em> and 0 otherwise: just take a number from the oracle and return either 1 if that number is 0, or 0 otherwise.  Alternatively, take two numbers from the oracle and return either 1 if both are the same, or 0 otherwise (Duvignau 2015, p. 153)[^19].</p>

<p><strong><em>Random variate with mean n.</em></strong> Likewise, it&#39;s trivial to generate variates with a mean of <em>n</em>: Do &quot;Bernoulli 1/n&quot; trials as described above until a trial returns 0, then return the number of trials done this way.  (This is related to the ambiguously defined &quot;geometric&quot; random variates.)</p>

<p><strong><em>Binomial with parameters n and 1/n.</em></strong> Using the oracle, the following algorithm generates a binomial variate of this kind (Duvignau 2015, Algorithm 20)[^19]:</p>

<ol>
<li>Take items from the oracle until the same item is taken twice.</li>
<li>Create a list consisting of the items taken in step 1, except for the last item taken, then shuffle that list.</li>
<li>In the shuffled list, count the number of items that didn&#39;t change position after being shuffled, then return that number.</li>
</ol>

<p><strong><em>Binomial with parameters n and k/n.</em></strong> Duvignau 2015 also includes an algorithm (Algorithm 25) to generate a binomial variate of this kind using the oracle (where <em>k</em> is a known integer such that 0 &lt; <em>k</em> and <em>k</em> &le; <em>n</em>):</p>

<ol>
<li>Take items from the oracle until <em>k</em> different items were taken this way.  Let <em>U</em> be a list of these <em>k</em> items, in the order in which they were first taken.</li>
<li>Create an empty list <em>L</em>.</li>
<li>For each integer <em>i</em> in [0, <em>k</em>):

<ol>
<li>Create an empty list <em>M</em>.</li>
<li>Take an item from the oracle.  If the item is in <em>U</em> at a position <strong>less than <em>i</em></strong> (positions start at 0), repeat this substep.  Otherwise, if the item is not in <em>M</em>, add it to <em>M</em> and repeat this substep.  Otherwise, go to the next substep.</li>
<li>Shuffle the list <em>M</em>, then add to <em>L</em> each item that didn&#39;t change position after being shuffled (if not already present in <em>L</em>).</li>
</ol></li>
<li>For each integer <em>i</em> in [0, <em>k</em>):

<ol>
<li>Let <em>P</em> be the item at position <em>i</em> in <em>U</em>.</li>
<li>Take an item from the oracle.  If the item is in <em>U</em> at position <strong><em>i</em> or less</strong> (positions start at 0), repeat this substep.</li>
<li>If the last item taken in the previous substep is in <em>U</em> at a position <strong>greater than <em>i</em></strong>, add <em>P</em> to <em>L</em> (if not already present).</li>
</ol></li>
<li>Return the number of items in <em>L</em>.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> Duvignau proved a result (Theorem 5.2) that answers the question: Which probability distributions based on the unknown <em>n</em> can be sampled with the oracle?[^20] The result applies to a family of (discrete) distributions with the same unknown parameter <em>n</em>, starting with either 1 or a greater integer.  Let Supp(<em>m</em>) be the set of values taken on by the distribution with parameter equal to <em>m</em>.  Then that family can be sampled using the oracle if and only if:</p>

<ul>
<li>There is a computable function <em>f</em>(<em>k</em>) that outputs a positive number.</li>
<li>For each <em>n</em>, Supp(<em>n</em>) is included in Supp(<em>n</em>+1).</li>
<li>For every <em>k</em> and for every <em>n</em> &ge; 2 starting with the first <em>n</em> for which <em>k</em> is in Supp(<em>n</em>), the probability of seeing <em>k</em> given parameter <em>n</em> is at least (1/<em>n</em>)<sup><em>f</em>(<em>k</em>)</sup> (roughly speaking, the probability doesn&#39;t decay at a faster than polynomial rate as <em>n</em> increases).</li>
</ul>
</blockquote>

<p><a id=Acknowledgments></a></p>

<h2>Acknowledgments</h2>

<p>Michael Shoemate gave comments on this article.</p>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<p>[^1]: Łatuszyński, K., Kosmidis, I.,  Papaspiliopoulos, O., Roberts, G.O., &quot;<a href="https://arxiv.org/abs/0907.4018v2"><strong>Simulating events of unknown probabilities via reverse time martingales</strong></a>&quot;, arXiv:0907.4018v2 [stat.CO], 2009/2011.</p>

<p>[^2]: S. Ray, P.S.V. Nataraj, &quot;A Matrix Method for Efficient Computation of Bernstein Coefficients&quot;, <em>Reliable Computing</em> 17(1), 2012.</p>

<p>[^3]: To show the target function $f(\lambda)$ is convex, find the &quot;slope-of-slope&quot; function of <em>f</em> and show it&#39;s 0 or greater for every <em>&lambda;</em> in the domain.  To do so, first find the &quot;slope&quot;: omit the first term and for each remaining term (with $i\ge 1$), replace $a_i \lambda^i$ with $a_i i \lambda^{i-1}$.  The resulting &quot;slope&quot; function is still an infinite series with coefficients 0 or greater.  Hence, so will the &quot;slope&quot; of this &quot;slope&quot; function, so the result follows by induction.</p>

<p>[^4]: <em>Summation notation</em>, involving the Greek capital sigma (&Sigma;), is a way to write the sum of one or more terms of similar form. For example, $\sum_{k=0}^n g(k)$ means $g(0)+g(1)+...+g(n)$, and $\sum_{k\ge 0} g(k)$ means $g(0)+g(1)+...$.</p>

<p>[^5]: Dughmi, Shaddin, Jason Hartline, Robert D. Kleinberg, and Rad Niazadeh. &quot;Bernoulli Factories and Black-box Reductions in Mechanism Design.&quot; Journal of the ACM (JACM) 68, no. 2 (2021): 1-30.</p>

<p>[^6]: Knuth, Donald E. and Andrew Chi-Chih Yao. &quot;The complexity of nonuniform random number generation&quot;, in <em>Algorithms and Complexity: New Directions and Recent Results</em>, 1976.</p>

<p>[^7]: Mendo, Luis. &quot;An asymptotically optimal Bernoulli factory for certain functions that can be expressed as power series.&quot; Stochastic Processes and their Applications 129, no. 11 (2019): 4366-4384.</p>

<p>[^8]: &quot;<em>x</em> is odd&quot; means that <em>x</em> is an integer and not divisible by 2.  This is true if <em>x</em> &minus; 2*floor(<em>x</em>/2) equals 1, or if <em>x</em> is an integer and the least significant bit of abs(<em>x</em>) is 1.</p>

<p>[^9]: choose(<em>n</em>, <em>k</em>) = (1*2*3*...*<em>n</em>)/((1*...*<em>k</em>)*(1*...*(<em>n</em>&minus;<em>k</em>))) =  <em>n</em>!/(<em>k</em>! * (<em>n</em> &minus; <em>k</em>)!) is a <em>binomial coefficient</em>, or the number of ways to choose <em>k</em> out of <em>n</em> labeled items.  It can be calculated, for example, by calculating <em>i</em>/(<em>n</em>&minus;<em>i</em>+1) for each integer <em>i</em> in the interval [<em>n</em>&minus;<em>k</em>+1, <em>n</em>], then multiplying the results (Yannis Manolopoulos. 2002. &quot;<a href="https://doi.org/10.1145/820127.820168"><strong>Binomial coefficient computation: recursion or iteration?</strong></a>&quot;, SIGCSE Bull. 34, 4 (December 2002), 65–67).  For every <em>m</em>&gt;0, choose(<em>m</em>, 0) = choose(<em>m</em>, <em>m</em>) = 1 and choose(<em>m</em>, 1) = choose(<em>m</em>, <em>m</em>&minus;1) = <em>m</em>; also, in this document, choose(<em>n</em>, <em>k</em>) is 0 when <em>k</em> is less than 0 or greater than <em>n</em>.</p>

<p>[^10]: <em>n</em>! = 1*2*3*...*<em>n</em> is also known as <em>n</em> factorial; in this document, (0!) = 1.</p>

<p>[^11]: &quot;<em>x</em> is even&quot; means that <em>x</em> is an integer and divisible by 2.  This is true if <em>x</em> &minus; 2*floor(<em>x</em>/2) equals 0, or if <em>x</em> is an integer and the least significant bit of abs(<em>x</em>) is 0.</p>

<p>[^12]: Thomas, A.C., Blanchet, J., &quot;<a href="https://arxiv.org/abs/1106.2508v3"><strong>A Practical Implementation of the Bernoulli Factory</strong></a>&quot;, arXiv:1106.2508v3  [stat.AP], 2012.</p>

<p>[^13]: Nacu, Şerban, and Yuval Peres. &quot;<a href="https://projecteuclid.org/euclid.aoap/1106922322"><strong>Fast simulation of new coins from old</strong></a>&quot;, The Annals of Applied Probability 15, no. 1A (2005): 93-115.</p>

<p>[^14]: Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560"><strong>On Buffon machines and numbers</strong></a>&quot;, arXiv:0906.5560  [math.PR], 2010</p>

<p>[^15]: Mossel, Elchanan, and Yuval Peres. New coins from old: computing with unknown bias. Combinatorica, 25(6), pp.707-724, 2005.</p>

<p>[^16]: Citterio, M., Pavani, R., &quot;A Fast Computation of the Best k-Digit Rational Approximation to a Real Number&quot;, Mediterranean Journal of Mathematics 13 (2016).</p>

<p>[^17]: Łatuszyński, K., Kosmidis, I., Papaspiliopoulos, O., Roberts, G.O., &quot;<a href="https://arxiv.org/abs/0907.4018v2"><strong>Simulating events of unknown probabilities via reverse time martingales</strong></a>&quot;, arXiv:0907.4018v2 [stat.CO], 2009/2011.</p>

<p>[^18]: Jacob, P.E., Thiery, A.H., &quot;On nonnegative unbiased estimators&quot;, Ann. Statist., Volume 43, Number 2 (2015), 769-784.</p>

<p>[^19]: Duvignau, R., 2015. Maintenance et simulation de graphes aléatoires dynamiques (Doctoral dissertation, Université de Bordeaux).</p>

<p>[^20]: There are many distributions that can be sampled using the oracle, by first generating unbiased random bits via randomness extraction methods, but then these distributions won&#39;t use the unknown number of faces in general.  Duvignau proved Theorem 5.2 for an oracle that outputs <em>arbitrary</em> but still distinct items, as opposed to integers, but this case can be reduced to the integer case (see section 4.1.3).</p>

<p>[^21]: Kinderman, A.J., Monahan, J.F., &quot;Computer generation of random variables using the ratio of uniform deviates&quot;, <em>ACM Transactions on Mathematical Software</em> 3(3), pp. 257-260, 1977.</p>

<p>[^22]: Daumas, M., Lester, D., Muñoz, C., &quot;<a href="https://arxiv.org/abs/0708.3721"><strong>Verified Real Number Calculations: A Library for Interval Arithmetic</strong></a>&quot;, arXiv:0708.3721 [cs.MS], 2007.</p>

<p>[^23]: Karney, C.F.F., 2016. Sampling exactly from the normal distribution. ACM Transactions on Mathematical Software (TOMS), 42(1), pp.1-14. Also: &quot;<a href="https://arxiv.org/abs/1303.6257v2"><strong>Sampling exactly from the normal distribution</strong></a>&quot;, arXiv:1303.6257v2  [physics.comp-ph], 2014.</p>

<p>[^24]: Leydold, J., &quot;<a href="https://dl.acm.org/doi/10.1145/347837.347863"><strong>Automatic sampling with the ratio-of-uniforms method</strong></a>&quot;, ACM Transactions on Mathematical Software 26(1), 2000.</p>

<p>[^25]: Brassard, G., Devroye, L., Gravel, C., &quot;Remote Sampling with Applications to General Entanglement Simulation&quot;, <em>Entropy</em> 2019(21)(92), <a href="https://doi.org/10.3390/e21010092"><strong>https://doi.org/10.3390/e21010092</strong></a> .</p>

<p>[^26]: Devroye, L., <a href="http://luc.devroye.org/rnbookindex.html"><strong><em>Non-Uniform Random Variate Generation</em></strong></a>, 1986.</p>

<p>[^27]: Devroye, L., Gravel, C., &quot;<a href="https://arxiv.org/abs/1502.02539v6"><strong>Random variate generation using only finitely many unbiased, independently and identically distributed random bits</strong></a>&quot;, arXiv:1502.02539v6 [cs.IT], 2020.</p>

<p>[^28]: Keane,  M.  S.,  and  O&#39;Brien,  G.  L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</p>

<p>[^29]: Lee, A., Doucet, A. and Łatuszyński, K., 2014. &quot;<a href="https://arxiv.org/abs/1407.5770v1"><strong>Perfect simulation using atomic regeneration with application to Sequential Monte Carlo</strong></a>&quot;, arXiv:1407.5770v1  [stat.CO].</p>

<p>[^30]: Banderier, C. And Drmota, M., 2015. Formulae and asymptotics for coefficients of algebraic functions. Combinatorics, Probability and Computing, 24(1), pp.1-53.</p>

<p>[^31]: Icard, Thomas F., &quot;Calibrating generative models: The probabilistic Chomsky–Schützenberger hierarchy&quot;, <em>Journal of Mathematical Psychology</em> 95 (2020): 102308.</p>

<p>[^32]: Etessami, K. and Yannakakis, M., &quot;Recursive Markov chains, stochastic grammars, and monotone systems of nonlinear equations&quot;, <em>Journal of the ACM</em> 56(1), pp.1-66, 2009.</p>

<p>[^33]: Goyal, V. and Sigman, K., 2012. On simulating a class of Bernstein polynomials. ACM Transactions on Modeling and Computer Simulation (TOMACS), 22(2), pp.1-5.</p>

<p>[^34]: Esparza, J., Kučera, A. and Mayr, R., 2004, July. Model checking probabilistic pushdown automata. In <em>Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science</em>, 2004. (pp. 12-21). IEEE.</p>

<p>[^35]: Elder, Murray, Geoffrey Lee, and Andrew Rechnitzer. &quot;Permutations generated by a depth 2 stack and an infinite stack in series are algebraic.&quot; <em>Electronic Journal of Combinatorics</em> 22(1), 2015.</p>

<p>[^36]: Vatan, F., &quot;Distribution functions of probabilistic automata&quot;, in <em>Proceedings of the thirty-third annual ACM symposium on Theory of computing (STOC &#39;01)</em>, pp. 684-693, 2001.</p>

<p>[^37]: Kindler, Guy and D. Romik, &quot;On distributions computable by random walks on graphs,&quot; <em>SIAM Journal on Discrete Mathematics</em> 17 (2004): 624-633.</p>

<p>[^38]: Vatan (2001) claims that a finite-state generator has a continuous <code>CDF</code> (unless it produces a single value with probability 1), but this is not necessarily true if the generator has a state that outputs 0 forever.</p>

<p>[^39]: Adamczewski, B., Cassaigne, J. and Le Gonidec, M., 2020. On the computational complexity of algebraic numbers: the Hartmanis–Stearns problem revisited. Transactions of the American Mathematical Society, 373(5), pp.3085-3115.</p>

<p>[^40]: Cobham, A., &quot;On the Hartmanis-Stearns problem for a class of tag machines&quot;, in <em>IEEE Conference Record of 1968 Ninth Annual Symposium on Switching and Automata Theory</em> 1968.</p>

<p>[^41]: Adamczewski, B., Bugeaud, Y., &quot;On the complexity of algebraic numbers I. Expansions in integer bases&quot;, <em>Annals of Mathematics</em> 165 (2007).</p>

<p>[^42]: Richman, F. (2012). Algebraic functions, calculus style. Communications in Algebra, 40(7), 2671-2683.</p>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p>&nbsp;</p>

<p><a id=Ratio_of_Uniforms></a></p>

<h3>Ratio of Uniforms</h3>

<p>The Cauchy sampler given earlier demonstrates the <em>ratio-of-uniforms</em> technique for sampling a distribution (Kinderman and Monahan 1977)[^21].  It involves transforming the distribution&#39;s probability density function (PDF) into a compact shape.  The ratio-of-uniforms method appears here in the appendix, particularly since it can involve calculating upper and lower bounds of transcendental functions which, while it&#39;s possible to achieve in rational arithmetic (Daumas et al., 2007)[^22], is less elegant than, say, the normal distribution sampler by Karney (2014)[^23], which doesn&#39;t require calculating logarithms or other transcendental functions.</p>

<p>This algorithm works for every univariate (one-variable) distribution as long as&mdash;</p>

<ul>
<li><em>PDF</em>(<em>x</em>) (either the distribution&#39;s PDF or a function proportional to the PDF) is continuous &quot;almost everywhere&quot; on its domain,</li>
<li>both <em>PDF</em>(<em>x</em>) and <em>x</em><sup>2</sup>*<em>PDF</em>(<em>x</em>) have a maximum on that domain, and</li>
<li>either&mdash;

<ul>
<li>the distribution&#39;s ratio-of-uniforms shape (the transformed PDF) is covered entirely by the rectangle [0, ceil(<em>d1</em>)]&times;[0, ceil(<em>d2</em>)], where <em>d1</em> is not less than the maximum of abs(<em>x</em>)*sqrt(<em>PDF</em>(<em>x</em>)) on its domain, and <em>d2</em> is not less than the maximum of sqrt(<em>PDF</em>(<em>x</em>)) on its domain, or</li>
<li>half of that shape is covered this way and the shape is symmetric about the <em>v</em>-axis.</li>
</ul></li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>Generate two empty PSRNs, with a positive sign, an integer part of 0, and an empty fractional part.  Call the PSRNs <em>p1</em> and <em>p2</em>.</li>
<li>Set <em>S</em> to <em>base</em>, where <em>base</em> is the base of digits to be stored by the PSRNs (such as 2 for binary or 10 for decimal).  Then set <em>c1</em> to an integer in the interval [0, <em>d1</em>), chosen uniformly at random, then set <em>c2</em> to an integer in [0, <em>d2</em>), chosen uniformly at random, then set <em>d</em> to 1.</li>
<li>Multiply <em>c1</em> and <em>c2</em> each by <em>base</em> and add a digit chosen uniformly at random to that coordinate.</li>
<li>Run an <strong>InShape</strong> function that determines whether the transformed PDF is covered by the current box. In principle, this is the case when <em>z</em> &le; 0 everywhere in the box, where <em>u</em> lies in [<em>c1</em>/<em>S</em>, (<em>c1</em>+1)/<em>S</em>], <em>v</em> lies in [<em>c2</em>/<em>S</em>, (<em>c2</em>+1)/<em>S</em>], and <em>z</em> is <em>v</em><sup>2</sup>&minus;<em>PDF</em>(<em>u</em>/<em>v</em>).  <strong>InShape</strong> returns <em>YES</em> if the box is fully inside the transformed PDF, <em>NO</em> if the box is fully outside it, and <em>MAYBE</em> in any other case, or if evaluating <em>z</em> fails for a given box (for example, because ln(0) would be calculated or <em>v</em> is 0).  See the next section for implementation notes.</li>
<li>If <strong>InShape</strong> as described in step 4 returns <em>YES</em>, then do the following:

<ol>
<li>Transfer <em>c1</em>&#39;s least significant digits to <em>p1</em>&#39;s fractional part, and transfer <em>c2</em>&#39;s least significant digits to <em>p2</em>&#39;s fractional part.  The variable <em>d</em> tells how many digits to transfer to each PSRN this way.  Then set <em>p1</em>&#39;s integer part to floor(<em>c1</em>/<em>base</em><sup><em>d</em></sup>) and <em>p2</em>&#39;s integer part to floor(<em>c2</em>/<em>base</em><sup><em>d</em></sup>). (For example, if <em>base</em> is 10, <em>d</em> is 3, and <em>c1</em> is 7342, set <em>p1</em>&#39;s fractional part to [3, 4, 2] and <em>p1</em>&#39;s integer part to 7.)</li>
<li>Run the <strong>UniformDivide</strong> algorithm (described in the article on PSRNs) on <em>p1</em> and <em>p2</em>, in that order.</li>
<li>If the transformed PDF is symmetric about the <em>v</em>-axis, set the resulting PSRN&#39;s sign to positive or negative with equal probability.  Otherwise, set the PSRN&#39;s sign to positive.</li>
<li>Return the PSRN.</li>
</ol></li>
<li>If <strong>InShape</strong> as described in step 4 returns <em>NO</em>, then go to step 2.</li>
<li>Multiply <em>S</em> by <em>base</em>, then add 1 to <em>d</em>, then go to step 3.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> The ratio-of-uniforms shape is convex if and only if &minus;1/sqrt(<em>PDF</em>(<em>x</em>)) is a concave function (loosely speaking, its &quot;slope&quot; never increases) (Leydold 2000)[^24].</p>

<p><strong>Examples:</strong></p>

<ol>
<li>For the normal distribution, <em>PDF</em> is proportional to exp(&minus;<em>x</em><sup>2</sup>/2), so that <em>z</em> after a logarithmic transformation (see next section) becomes 4*ln(<em>v</em>) + (<em>u</em>/<em>v</em>)<sup>2</sup>, and since the distribution&#39;s ratio-of-uniforms shape is symmetric about the <em>v</em>-axis, the return value&#39;s sign is positive or negative with equal probability.</li>
<li>For the standard lognormal distribution (<a href="https://mathworld.wolfram.com/GibratsDistribution.html"><strong>Gibrat&#39;s distribution</strong></a>), <em>PDF</em>(<em>x</em>) is proportional to exp(&minus;(ln(<em>x</em>))<sup>2</sup>/2)/<em>x</em>, so that <em>z</em> after a logarithmic transformation becomes 2*ln(<em>v</em>)&minus;(&minus;ln(<em>u</em>/<em>v</em>)<sup>2</sup>/2 &minus; ln(<em>u</em>/<em>v</em>)), and the returned PSRN has a positive sign.</li>
<li>For the gamma distribution with shape parameter <em>a</em> &gt; 1, <em>PDF</em>(<em>x</em>) is proportional to <em>x</em><sup><em>a</em>&minus;1</sup>*exp(&minus;<em>x</em>), so that <em>z</em> after a logarithmic transformation becomes 2*ln(<em>v</em>)&minus;(<em>a</em>&minus;1)*ln(<em>u</em>/<em>v</em>)&minus;(<em>u</em>/<em>v</em>), or 0 if <em>u</em> or <em>v</em> is 0, and the returned PSRN has a positive sign.</li>
</ol>
</blockquote>

<p><a id=Probability_Transformations></a></p>

<h3>Probability Transformations</h3>

<p>The following algorithm takes a uniform partially-sampled random number (PSRN) as a &quot;coin&quot; and flips that &quot;coin&quot; using <strong>SampleGeometricBag</strong> (a method described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>).  Given that &quot;coin&quot; and a function <em>f</em> as described below, the algorithm returns 1 with probability <em>f</em>(<em>U</em>), where <em>U</em> is the number built up by the uniform PSRN (see also (Brassard et al., 2019)[^25], (Devroye 1986, p. 769)[^26], (Devroye and Gravel 2020)[^27].  In the algorithm:</p>

<ul>
<li> The uniform PSRN&#39;s sign must be positive and its integer part must be 0.</li>
<li><p>For correctness, <em>f</em>(<em>U</em>) must meet the following conditions:</p>

<ul>
<li>If the algorithm will be run multiple times with the same PSRN, <em>f</em>(<em>U</em>) must be the constant 0 or 1, or be continuous and polynomially bounded on the open interval (0, 1) (polynomially bounded means that both <em>f</em>(<em>U</em>) and 1&minus;<em>f</em>(<em>U</em>) are greater than or equal to min(<em>U</em><sup><em>n</em></sup>, (1&minus;<em>U</em>)<sup><em>n</em></sup>) for some integer <em>n</em> (Keane and O&#39;Brien 1994)[^28]).</li>
<li>Otherwise, <em>f</em>(<em>U</em>) must map the interval [0, 1] to [0, 1] and be continuous everywhere or &quot;almost everywhere&quot;.</li>
</ul>

<p>The first set of conditions is the same as those for the Bernoulli factory problem (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#About_Bernoulli_Factories"><strong>About Bernoulli Factories</strong></a>) and ensure this algorithm is unbiased (see also Łatuszyński et al. 2009/2011)[^1].</p></li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>Set <em>v</em> to 0 and <em>k</em> to 1.</li>
<li>(<em>v</em> acts as a uniform random variate greater than 0 and less than 1 to compare with <em>f</em>(<em>U</em>).) Set <em>v</em> to <em>b</em> * <em>v</em> + <em>d</em>, where <em>b</em> is the base (or radix) of the uniform PSRN&#39;s digits, and <em>d</em> is a digit chosen uniformly at random.</li>
<li>Calculate an approximation of <em>f</em>(<em>U</em>) as follows:

<ol>
<li>Set <em>n</em> to the number of items (sampled and unsampled digits) in the uniform PSRN&#39;s fractional part.</li>
<li>Of the first <em>n</em> digits (sampled and unsampled) in the PSRN&#39;s fractional part, sample each of the unsampled digits uniformly at random.  Then let <em>uk</em> be the PSRN&#39;s digit expansion up to the first <em>n</em> digits after the point.</li>
<li>Calculate the lowest and highest values of <em>f</em> in the interval [<em>uk</em>, <em>uk</em> + <em>b</em><sup>&minus;<em>n</em></sup>], call them <em>fmin</em> and <em>fmax</em>. If abs(<em>fmin</em> &minus; <em>fmax</em>) &le; 2 * <em>b</em><sup>&minus;<em>k</em></sup>, calculate (<em>fmax</em> + <em>fmin</em>) / 2 as the approximation.  Otherwise, add 1 to <em>n</em> and go to the previous substep.</li>
</ol></li>
<li>Let <em>pk</em> be the approximation&#39;s digit expansion up to the <em>k</em> digits after the point.  For example, if <em>f</em>(<em>U</em>) is <em>&pi;</em>/5, <em>b</em> is 10, and <em>k</em> is 3, <em>pk</em> is 628.</li>
<li>If <em>pk</em> + 1 &le; <em>v</em>, return 0. If <em>pk</em> &minus; 2 &ge; <em>v</em>, return 1.  If neither is the case, add 1 to <em>k</em> and go to step 2.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>This algorithm is related to the Bernoulli factory problem, where the input probability is unknown.  However, the algorithm doesn&#39;t exactly solve that problem because it has access to the input probability&#39;s value to some extent.</li>
<li>This section appears in the appendix because this article is focused on algorithms that don&#39;t rely on calculations of irrational numbers.</li>
</ol>
</blockquote>

<p><a id=Proof_of_the_General_Martingale_Algorithm></a></p>

<h3>Proof of the General Martingale Algorithm</h3>

<p>This proof of the <strong>general martingale algorithm</strong> is similar to the proof for certain alternating series with only nonzero coefficients, given in Łatuszyński et al. (2019/2011)[^1], section 3.1.  Suppose we repeatedly flip a coin that shows heads with probability $g(\lambda)$ and we get the following results: $X_1, X_2, ...$, where each result is either 1 if the coin shows heads or 0 otherwise.  Then define two sequences <em>U</em> and <em>L</em> as follows:</p>

<ul>
<li>$U_0=d_0$ and $L_0=0$.</li>
<li>For each $n&gt;0$, $U_n$ is $L_{n-1} + |a_n|\times X_1\times...\times X_n$ if $a_n &gt; 0$, otherwise $U_{n-1} - |a_n|\times X_1\times...\times X_n$ if no nonzero coefficients follow $a_n$ and $a_n &lt; 0$, otherwise $U_{n-1}$.</li>
<li>For each $n&gt;0$, $L_n$ is $U_{n-1} - |a_n|\times X_1\times...\times X_n$ if $a_n &lt; 0$, otherwise $L_{n-1} + |a_n|\times X_1\times...\times X_n$ if no nonzero coefficients follow $a_n$ and $a_n &gt; 0$, otherwise $L_{n-1}$.</li>
</ul>

<p>Then it&#39;s clear that with probability 1, for every $n\ge 1$&mdash;</p>

<ul>
<li>$L_n \le U_n$,</li>
<li>$U_n$ is 0 or greater and $L_n$ is 1 or less, and</li>
<li>$L_{n-1} \le L_n$ and $U_{n-1} \ge U_n$.</li>
</ul>

<p>Moreover, if there are infinitely many nonzero coefficients, the <em>U</em> and <em>L</em> sequences have expected values (&quot;long-run averages&quot;) converging to $f(\lambda)$ with probability 1; otherwise $f(\lambda)$ is a polynomial in $g(\lambda)$, and $U_n$ and $L_n$ have expected values that approach $f(\lambda)$ as $n$ gets large.  These conditions are required for the paper&#39;s Algorithm 3 (and thus the <strong>general martingale algorithm</strong>) to be valid.</p>

<p><a id=SymPy_Code_for_Piecewise_Linear_Factory_Functions></a></p>

<h3>SymPy Code for Piecewise Linear Factory Functions</h3>

<pre>def bernstein_n(func, x, n, pt=None):
  # Bernstein operator.
  # Create a polynomial that approximates func, which in turn uses
  # the symbol x.  The polynomial&#39;s degree is n and is evaluated
  # at the point pt (or at x if not given).
  if pt==None: pt=x
  ret=0
  v=[binomial(n,j) for j in range(n//2+1)]
  for i in range(0, n+1):
    oldret=ret
    bino=v[i] if i&lt;len(v) else v[n-i]
    ret+=func.subs(x,S(i)/n)*bino*pt**i*(1-pt)**(n-i)
    if pt!=x and ret==oldret and ret&gt;0: break
  return ret

def inflec(y,eps=S(2)/10,mult=2):
  # Calculate the inflection point (x) given y, eps, and mult.
  # The formula is not found in the paper by Thomas and
  # Blanchet 2012, but in
  # the supplemental source code uploaded by
  # A.C. Thomas.
  po=5 # Degree of y-to-x polynomial curve
  eps=S(eps)
  mult=S(mult)
  x=-((y-(1-eps))/eps)**po/mult + y/mult
  return x

def xfunc(y,sym,eps=S(2)/10,mult=2):
  # Calculate Bernstein &quot;control polygon&quot; given y,
  # eps, and mult.
  return Min(sym*y/inflec(y,eps,mult),y)

def calc_linear_func(eps=S(5)/10, mult=1, count=10):
   # Calculates the degrees and Y parameters
   # of a sequence of polynomials that converge
   # from above to min(x*mult, 1-eps).
   # eps must be greater than 0 and less than 1.
   # Default is 10 polynomials.
   polys=[]
   eps=S(eps)
   mult=S(mult)
   count=S(count)
   bs=20
   ypt=1-(eps/4)
   x=symbols(&#39;x&#39;)
   tfunc=Min(x*mult,1-eps)
   tfn=tfunc.subs(x,(1-eps)/mult).n()
   xpt=xfunc(ypt,x,eps=eps,mult=mult)
   bits=5
   i=0
   lastbxn = 1
   diffs=[]
   while i&lt;count:
     bx=bernstein_n(xpt,x,bits,(1-eps)/mult)
     bxn=bx.n()
     if bxn &gt; tfn and bxn &lt; lastbxn:
       # Dominates target function
       #if oldbx!=None:
       #   diffs.append(bx)
       #   diffs.append(oldbx-bx)
       #oldbx=bx
       oldxpt=xpt
       lastbxn = bxn
       polys.append([bits,ypt])
       print(&quot;    [%d,%s],&quot; % (bits,ypt))
       # Find y2 such that y2 &lt; ypt and
       # bernstein_n(oldxpt,x,bits,inflec(y2, ...)) &gt;= y2,
       # so that next Bernstein expansion will go
       # underneath the previous one
       while True:
         ypt-=(ypt-(1-eps))/4
         xpt=inflec(ypt,eps=eps,mult=mult).n()
         bxs=bernstein_n(oldxpt,x,bits,xpt).n()
         if bxs&gt;=ypt.n():
            break
       xpt=xfunc(ypt,x,eps=eps,mult=mult)
       bits+=20
       i+=1
     else:
       bits=int(bits*200/100)
   return polys

calc_linear_func(count=8)
</pre>

<p><a id=Algorithm_for_sin___lambda_____pi___2></a></p>

<h3>Algorithm for sin(<em>&lambda;</em>*<em>&pi;</em>/2)</h3>

<p>The following algorithm returns 1 with probability sin(<em>&lambda;</em>*<em>&pi;</em>/2) and 0 otherwise, given a coin that shows heads with probability <em>&lambda;</em>.  However, this algorithm appears in the appendix since it requires manipulating irrational numbers, particularly numbers involving <em>&pi;</em>.</p>

<ol>
<li>Choose at random an integer <em>n</em> (0 or greater) with probability (<em>&pi;</em>/2)<sup>4*<em>n</em>+2</sup>/((4*<em>n</em>+2)!) &minus; (<em>&pi;</em>/2)<sup>4*<em>n</em>+4</sup>/((4*<em>n</em>+4)!).</li>
<li>Let <em>v</em> = 16*(<em>n</em>+1)*(4*<em>n</em>+3).</li>
<li>Flip the input coin 4*<em>n</em>+4 times.  Let <em>tails</em> be the number of flips that returned 0 this way. (This would be the number of heads if the probability <em>&lambda;</em> were 1 &minus; <em>&lambda;</em>.)</li>
<li>If <em>tails</em> = 4*<em>n</em>+4, return 0.</li>
<li>If <em>tails</em> = 4*<em>n</em>+3, return a number that is 0 with probability 8*(4*<em>n</em>+3)/(<em>v</em>&minus;<em>&pi;</em><sup>2</sup>) and 1 otherwise.</li>
<li>If <em>tails</em> = 4*<em>n</em>+2, return a number that is 0 with probability 8/(<em>v</em>&minus;<em>&pi;</em><sup>2</sup>) and 1 otherwise.</li>
<li>Return 1.</li>
</ol>

<p>Derivation:  Write&mdash; $$f(\lambda) = \sin(\lambda \pi/2) = 1-g(1-\lambda),$$ where&mdash; $$g(\mu) = 1-\sin((1-\mu) \pi/2)$$ $$= \sum_{n\ge 0} \frac{(\mu\pi/2)^{4n+2}}{(4n+2)!} - \frac{(\mu\pi/2)^{4n+4}}{(4n+4)!}$$ $$= \sum_{n\ge 0} w_n(\mu) = \sum_{n\ge 0} w_n(1) \frac{w_n(\mu)}{w_n(1)}.$$</p>

<p>This is a <a href="https://peteroupc.github.io/bernoulli.html#Convex_Combinations"><strong>convex combination</strong></a> of $w_n(1)$ and $\frac{w_n(\mu)}{w_n(1)}$ &mdash; to simulate $g(\mu)$, first an integer <em>n</em> is chosen with probability $w_n(1)$ and then a coin that shows heads with probability $\frac{w_n(\mu)}{w_n(1)}$ is flipped.  Finally, to simulate $f(\lambda)$, the input coin is &quot;inverted&quot; ($\mu = 1-\lambda$), $g(\mu)$ is simulated using the &quot;inverted&quot; coin, and 1 minus the simulation result is returned.</p>

<p>As given above, each term $w_n(\mu)$ is a polynomial in $\mu$, and is strictly increasing and equals 1 or less everywhere on the interval $[0, 1]$, and $w_n(1)$ is a constant so that $\frac{w_n(\mu)}{w_n(1)}$ remains a polynomial.  Each polynomial $\frac{w_n(\mu)}{w_n(1)}$ can be transformed into a polynomial in Bernstein form with the following coefficients: $$(0, 0, ..., 0, 8/(v-\pi^2), 8(4n+3)/(v-\pi^2), 1),$$ where the polynomial is of degree $4n+4$ and so has $4n+5$ coefficients, and $v = \frac{((4n+4)!)\times 2^{4n+4}}{((4n+2)!)\times 2^{4n+2}} = 16 (n+1) (4n+3)$.  These are the coefficients used in steps 4 through 7 of the algorithm above.</p>

<blockquote>
<p><strong>Note:</strong> sin(<em>&lambda;</em>*<em>&pi;</em>/2) = cos((1&minus;<em>&lambda;</em>)*<em>&pi;</em>/2).</p>
</blockquote>

<p><a id=Sampling_Distributions_Using_Incomplete_Information_Omitted_Algorithms></a></p>

<h3>Sampling Distributions Using Incomplete Information: Omitted Algorithms</h3>

<p><strong>Algorithm 2.</strong> Suppose there is an <em>oracle</em> that produces independent random real numbers whose expected value (&quot;long-run average&quot;) is a known or unknown mean. The goal is now to produce nonnegative random variates whose expected value is the mean of <em>f</em>(<em>X</em>), where <em>X</em> is a number produced by the oracle.  This is possible whenever&mdash;</p>

<ul>
<li><em>f</em> has a finite lower bound and a finite upper bound on its domain, and</li>
<li>the mean of <em>f</em>(<em>X</em>) is not less than <em>&delta;</em>, where <em>&delta;</em> is a known rational number greater than 0.</li>
</ul>

<p>The algorithm to achieve this goal follows (see Lee et al. 2014)[^29]:</p>

<ol>
<li>Let <em>m</em> be a rational number equal to or greater than the maximum value of abs(<em>f</em>(<em>&mu;</em>)) anywhere.  Create a <em>&nu;</em> input coin that does the following: &quot;Take a number from the oracle, call it <em>x</em>.  With probability abs(<em>f</em>(<em>x</em>))/<em>m</em>, return a number that is 1 if <em>f</em>(<em>x</em>) &lt; 0 and 0 otherwise.  Otherwise, repeat this process.&quot;</li>
<li>Use one of the <a href="https://peteroupc.github.io/bernoulli.html#lambda____x___y__linear_Bernoulli_factories"><strong>linear Bernoulli factories</strong></a> to simulate 2*<em>&nu;</em> (2 times the <em>&nu;</em> coin&#39;s probability of heads), using the <em>&nu;</em> input coin, with <em>&#x03F5;</em> = <em>&delta;</em>/<em>m</em>.  If the factory returns 1, return 0.  Otherwise, take a number from the oracle, call it <em>&xi;</em>, and return abs(<em>f</em>(<em>&xi;</em>)).</li>
</ol>

<blockquote>
<p><strong>Example:</strong> An example from Lee et al. (2014)[^29].  Say the oracle produces uniform random variates in [0, 3*<em>&pi;</em>], and let <em>f</em>(<em>&nu;</em>) = sin(<em>&nu;</em>).  Then the mean of <em>f</em>(<em>X</em>) is 2/(3*<em>&pi;</em>), which is greater than 0 and found in SymPy by <code>sympy.stats.E(sin(sympy.stats.Uniform(&#39;U&#39;,0,3*pi)))</code>, so the algorithm can produce nonnegative random variates whose expected value (&quot;long-run average&quot;) is that mean.</p>

<p><strong>Notes:</strong></p>

<ol>
<li>Averaging to the mean of <em>f</em>(<em>X</em>) (that is, <strong>E</strong>[<em>f</em>(<em>X</em>)] where <strong>E</strong>[.] means expected or average value) is not the same as averaging to <em>f</em>(<em>&mu;</em>) where <em>&mu;</em> is the mean of the oracle&#39;s numbers (that is, <em>f</em>(<strong>E</strong>[<em>X</em>])).  For example, if <em>X</em> is 0 or 1 with equal probability, and <em>f</em>(<em>&nu;</em>) = exp(&minus;<em>&nu;</em>), then <strong>E</strong>[<em>f</em>(<em>X</em>)] = exp(0) + (exp(&minus;1) &minus; exp(0))*(1/2), and <em>f</em>(<strong>E</strong>[<em>X</em>]) = <em>f</em>(1/2) = exp(&minus;1/2).</li>
<li><p>(Lee et al. 2014, Corollary 4)[^29]: If <em>f</em>(<em>&mu;</em>) is known to return only values in the interval [<em>a</em>, <em>c</em>], the mean of <em>f</em>(<em>X</em>) is not less than <em>&delta;</em>, <em>&delta;</em> &gt; <em>b</em>, and <em>&delta;</em> and <em>b</em> are known numbers, then Algorithm 2 can be modified as follows:</p>

<ul>
<li>Use <em>f</em>(<em>&nu;</em>) = <em>f</em>(<em>&nu;</em>) &minus; <em>b</em>, and use <em>&delta;</em> = <em>&delta;</em> &minus; <em>b</em>.</li>
<li><em>m</em> is taken as max(<em>b</em>&minus;<em>a</em>, <em>c</em>&minus;<em>b</em>).</li>
<li>When Algorithm 2 finishes, add <em>b</em> to its return value.</li>
</ul></li>
<li>The check &quot;With probability abs(<em>f</em>(<em>x</em>))/<em>m</em>&quot; is exact if the oracle produces only rational numbers <em>and</em> if <em>f</em>(<em>x</em>) outputs only rational numbers.  If the oracle or <em>f</em> can produce irrational numbers (such as numbers that follow a beta distribution or another non-discrete distribution), then this check should be implemented using uniform <a href="https://peteroupc.github.io/exporand.html"><strong>partially-sampled random numbers (PSRNs)</strong></a>.</li>
</ol>
</blockquote>

<p><strong>Algorithm 3.</strong> Suppose there is an <em>oracle</em> that produces independent random real numbers that are all greater than or equal to <em>a</em> (which is a known rational number), whose mean (<em>&mu;</em>) is unknown.  The goal is to use the oracle to produce nonnegative random variates with mean <em>f</em>(<em>&mu;</em>).  This is possible only if <em>f</em> is 0 or greater everywhere in the interval [<em>a</em>, <em>&infin;</em>) and is nowhere decreasing in that interval (Jacob and Thiery 2015)[^18].  This can be done using the algorithm below.  In the algorithm:</p>

<ul>
<li><em>f</em>(<em>&mu;</em>) must be a function that can be written as&mdash;<br><em>c</em>[0]*<em>z</em><sup>0</sup> + <em>c</em>[1]*<em>z</em><sup>1</sup> + ...,<br>which is an infinite series where <em>z</em> = <em>&mu;</em>&minus;<em>a</em> and all <em>c</em>[<em>i</em>] are 0 or greater.</li>
<li><em>&psi;</em> is a rational number close to 1, such as 95/100.  (The exact choice is arbitrary and can be less or greater for efficiency purposes, but must be greater than 0 and less than 1.)</li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>Set <em>ret</em> to 0, <em>prod</em> to 1, <em>k</em> to 0, and <em>w</em> to 1. (<em>w</em> is the probability of generating <em>k</em> or more random variates in a single run of the algorithm.)</li>
<li>If <em>k</em> is greater than 0: Take a number from the oracle, call it <em>x</em>, and multiply <em>prod</em> by <em>x</em>&minus;<em>a</em>.</li>
<li>Add <em>c</em>[<em>k</em>]*<em>prod</em>/<em>w</em> to <em>ret</em>.</li>
<li>Multiply <em>w</em> by <em>&psi;</em> and add 1 to <em>k</em>.</li>
<li>With probability <em>&psi;</em>, go to step 2.  Otherwise, return <em>ret</em>.</li>
</ol>

<p>Now, assume the oracle&#39;s numbers are all less than or equal to <em>b</em> (rather than greater than or equal to <em>a</em>), where <em>b</em> is a known rational number.  Then <em>f</em> must be 0 or greater everywhere in (&minus;<em>&infin;</em>, <em>b</em>] and be nowhere increasing there (Jacob and Thiery 2015)[^18], and the algorithm above can be used with the following modifications: (1) In the note on the infinite series, <em>z</em> = <em>b</em> &minus;<em>&mu;</em>; (2) in step 2, multiply <em>prod</em> by <em>b</em> &minus; <em>x</em> rather than <em>x</em> &minus; <em>a</em>.</p>

<blockquote>
<p><strong>Note:</strong> This algorithm is exact if the oracle produces only rational numbers <em>and</em> if all <em>c</em>[<em>i</em>] are rational numbers.  If the oracle can produce irrational numbers, then they should be implemented using uniform PSRNs.  See also note 3 on Algorithm 2.</p>
</blockquote>

<p><a id=Pushdown_Automata_and_Algebraic_Functions></a></p>

<h3>Pushdown Automata and Algebraic Functions</h3>

<p>This section has mathematical proofs showing which kinds of algebraic functions (functions that can be a solution of a nonzero polynomial equation) can be simulated with a pushdown automaton (a state machine with a stack).</p>

<p>The following summarizes what can be established about these algebraic functions:</p>

<ul>
<li>sqrt(<em>&lambda;</em>) can be simulated.</li>
<li>Every rational function with rational coefficients that maps the open interval (0, 1) to itself can be simulated.</li>
<li>If <em>f</em>(<em>&lambda;</em>) can be simulated, so can any Bernstein-form polynomial in the variable <em>f</em>(<em>&lambda;</em>) with coefficients that can be simulated.</li>
<li>If <em>f</em>(<em>&lambda;</em>) and <em>g</em>(<em>&lambda;</em>) can be simulated, so can <em>f</em>(<em>&lambda;</em>)*<em>g</em>(<em>&lambda;</em>), <em>f</em>(<em>g</em>(<em>&lambda;</em>)), and <em>g</em>(<em>f</em>(<em>&lambda;</em>)).</li>
<li>If a full-domain pushdown automaton (defined later) can generate words of a given length with a given probability (a <em>probability distribution</em> of word lengths), then the probability generating function for that distribution can be simulated, as well as for that distribution conditioned on a finite set or periodic infinite set of word lengths (for example, all odd word lengths only).</li>
<li>If a stochastic context-free grammar (defined later) can generate a probability distribution of word lengths, and terminates with probability 1, then the probability generating function for that distribution can be simulated.</li>
<li>Every quadratic irrational number between 0 and 1 can be simulated.</li>
</ul>

<p>It is not yet known whether the following functions can be simulated:</p>

<ul>
<li><em>&lambda;</em><sup>1/<em>p</em></sup> for prime numbers <em>p</em> greater than 2. The answer may be no; Banderier and Drmota (2015)[^30] proved results that show, among other things, that $\lambda^{1/p}$, where $p$ is not a power of 2, is not a possible solution to $P(\lambda) = 0$, where $P(\lambda)$ is a polynomial whose coefficients are non-negative real numbers.</li>
<li>min(<em>&lambda;</em>, 1&minus;<em>&lambda;</em>).</li>
</ul>

<hr>

<p>The following definitions are used in this section:</p>

<ol>
<li><p>A <em>pushdown automaton</em> has a finite set of <em>states</em> and a finite set of <em>stack symbols</em>, one of which is called EMPTY, and takes a coin that shows heads with an unknown probability. It starts at a given state and its stack starts with EMPTY.  On each iteration:</p>

<ul>
<li>The automaton flips the coin.</li>
<li>Based on the coin flip (HEADS or TAILS), the current state, and the top stack symbol, it moves to a new state (or keeps it unchanged) and replaces the top stack symbol with zero, one or two symbols.  Thus, there are three kinds of <em>transition rules</em>:

<ul>
<li>(<em>state</em>, <em>flip</em>, <em>symbol</em>) &rarr; (<em>state2</em>, {<em>symbol2</em>}): move to <em>state2</em>, replace top stack symbol with same or different one.</li>
<li>(<em>state</em>, <em>flip</em>, <em>symbol</em>) &rarr; (<em>state2</em>, {<em>symbol2</em>, <em>new</em>}): move to <em>state2</em>, replace top stack symbol with <em>symbol2</em>, then <em>push</em> a new symbol (<em>new</em>) onto the stack.</li>
<li>(<em>state</em>, <em>flip</em>, <em>symbol</em>) &rarr; (<em>state2</em>, {}): move to <em>state2</em>, <em>pop</em> the top symbol from the stack.</li>
</ul></li>
</ul>

<p>When the stack is empty, the machine stops, and returns either 0 or 1 depending on the state it ends up at.  (Because each left-hand side has no more than one possible transition, the automaton is <em>deterministic</em>.)</p></li>
<li><p>A <em>full-domain pushdown automaton</em> means a pushdown automaton that terminates with probability 1 given a coin with probability of heads <em>&lambda;</em>, for every <em>&lambda;</em> greater than 0 and less than 1.</p></li>
<li><strong>PDA</strong> is the class of functions that map the open interval (0, 1) to itself and can be simulated by a full-domain pushdown automaton.  <strong>PDA</strong> also includes the constant functions 0 and 1.</li>
<li><strong>ALGRAT</strong> is the class of functions that map the open interval (0, 1) to itself, are continuous, and are algebraic over the rational numbers (they satisfy a nonzero polynomial system whose coefficients are rational numbers). <strong>ALGRAT</strong> also includes the constant functions 0 and 1.</li>
<li>A <em>probability generating function</em> has the form <em>p</em><sub>0</sub>*<em>&lambda;</em><sup>0</sup> + <em>p</em><sub>1</sub>*<em>&lambda;</em><sup>1</sup> + ..., where <em>p</em><sub><em>i</em></sub> (a <em>coefficient</em>) is the probability of getting <em>i</em>.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>Mossel and Peres (2005)[^15] defined pushdown automata to start with a non-empty stack of <em>arbitrary</em> size, and to allow each rule to replace the top symbol with an <em>arbitrary</em> number of symbols.  Both cases can be reduced to the definition in this section.</li>
<li>Pushdown automata, as defined here, are very similar to so-called <em>probabilistic right-linear indexed grammars</em> (Icard 2020)[^31] and can be translated to those grammars as well as to <em>probabilistic pushdown systems</em> (Etessami and Yannakakis 2009)[^32], as long as those grammars and systems use only transition probabilities that are rational numbers.</li>
</ol>
</blockquote>

<p><strong>Proposition 0</strong> (Mossel and Peres 2005[^31], Theorem 1.2): <em>A full-domain pushdown automaton can simulate a function that maps (0, 1) to itself only if the function is in class <strong>ALGRAT</strong>.</em></p>

<p>It is not known whether <strong>ALGRAT</strong> and <strong>PDA</strong> are equal, but the following can be established about <strong>PDA</strong>:</p>

<p><strong>Lemma 1A:</strong> <em>Let g(&lambda;) be a function in the class <strong>PDA</strong>, and suppose a pushdown automaton F has two rules of the form (<code>state</code>, HEADS, <code>stacksymbol</code>) &rarr; RHS1 and (<code>state</code>, TAILS, <code>stacksymbol</code>) &rarr; RHS2, where <code>state</code> and <code>stacksymbol</code> are a specific state/symbol pair among the left-hand sides of F&#39;s rules.  Then there is a pushdown automaton that transitions to RHS1 with probability g(&lambda;) and to RHS2 with probability 1&minus;g(&lambda;) instead.</em></p>

<p><em>Proof:</em> If RHS1 and RHS2 are the same, then the conclusion holds and nothing has to be done.  Thus assume RHS1 and RHS2 are different.</p>

<p>Let <em>G</em> be the full-domain pushdown automaton for <em>g</em>. Assume that machines <em>F</em> and <em>G</em> stop when they pop EMPTY from the stack. If this is not the case, transform both machines by renaming the symbol EMPTY to EMPTY&prime;&prime;, adding a new symbol EMPTY&prime;&prime; and new starting state X0, and adding rules (X0, <em>flip</em>, EMPTY) &rarr; (<em>start</em>, {EMPTY&prime;&prime;}) and rule (<em>state</em>, <em>flip</em>, EMPTY) &rarr; (<em>state</em>, {}) for all states other than X0, where <em>start</em> is the starting state of <em>F</em> or <em>G</em>, as the case may be.</p>

<p>Now, rename each state of <em>G</em> as necessary so that the sets of states of <em>F</em> and of <em>G</em> are disjoint.  Then, add to <em>F</em> a new stack symbol EMPTY&prime; (or a name not found in the stack symbols of G, as the case may be).  Then, for the following two pairs of rules in <em>F</em>, namely&mdash;</p>

<p>(<em>state</em>, HEADS, <em>stacksymbol</em>) &rarr; (<em>state2heads</em>, <em>stackheads</em>), and<br>
(<em>state</em>, TAILS, <em>stacksymbol</em>) &rarr; (<em>state2tails</em>, <em>stacktails</em>),</p>

<p>add two new states <em>state</em><sub>0</sub> and <em>state</em><sub>1</sub> that correspond to <em>state</em> and have names different from all other states, and replace that rule with the following rules:</p>

<p>(<em>state</em>, HEADS, <em>stacksymbol</em>) &rarr; (<em>gstart</em>, {<em>stacksymbol</em>, EMPTY&prime;}),<br>
(<em>state</em>, TAILS, <em>stacksymbol</em>) &rarr; (<em>gstart</em>, {<em>stacksymbol</em>, EMPTY&prime;}),<br>
(<em>state</em><sub>0</sub>, HEADS, <em>stacksymbol</em>) &rarr; (<em>state2heads</em>, <em>stackheads</em>),<br>
(<em>state</em><sub>0</sub>, TAILS, <em>stacksymbol</em>) &rarr; (<em>state2heads</em>, <em>stackheads</em>),<br>
(<em>state</em><sub>1</sub>, HEADS, <em>stacksymbol</em>) &rarr; (<em>state2tails</em>, <em>stacktails</em>), and<br>
(<em>state</em><sub>1</sub>, TAILS, <em>stacksymbol</em>) &rarr; (<em>state2tails</em>, <em>stacktails</em>),<br></p>

<p>where <em>gstart</em> is the starting state for <em>G</em>, and copy the rules of the automaton for <em>G</em> onto <em>F</em>, but with the following modifications:</p>

<ul>
<li>Replace the symbol EMPTY in <em>G</em> with EMPTY&prime;.</li>
<li>Replace each state in <em>G</em> with a name distinct from all other states in <em>F</em>.</li>
<li>Replace each rule in <em>G</em> of the form (<em>state</em>, <em>flip</em>, EMPTY&prime;) &rarr; (<em>state2</em>, {}), where <em>state2</em> is a final state of <em>G</em> associated with output 1, with the rule (<em>state</em>, <em>flip</em>, EMPTY&prime;) &rarr; ( <em>state</em><sub>1</sub>, {}).</li>
<li>Replace each rule in <em>G</em> of the form (<em>state</em>, <em>flip</em>, EMPTY&prime;) &rarr; (<em>state2</em>, {}), where <em>state2</em> is a final state of <em>G</em> associated with output 0, with the rule (<em>state</em>, <em>flip</em>, EMPTY&prime;) &rarr; ( <em>state</em><sub>0</sub>, {}).</li>
</ul>

<p>Then, the final states of the new machine are the same as those for the original machine <em>F</em>. &#x25a1;</p>

<p><strong>Lemma 1B:</strong>  <em>There are pushdown automata that simulate the probabilities 0 and 1.</em></p>

<p><em>Proof:</em> The probability 0 automaton has the rules (START, HEADS, EMPTY) &rarr; (START, {}) and (START, TAILS, EMPTY) &rarr; (START, {}), and its only state START is associated with output 0. The probability 1 automaton is the same, except START is associated with output 1.  Both automata obviously terminate with probability 1. &#x25a1;</p>

<p>Because of Lemma 1A, it&#39;s possible to label each left-hand side of a pushdown automaton&#39;s rules with not just HEADS or TAILS, but also a rational number or another function in <strong>PDA</strong>, as long as for each state/symbol pair, the probabilities for that pair sum to 1.  For example, rules like the following are now allowed:</p>

<p>(START, 1/2, EMPTY) &rarr; ..., (START, sqrt(<em>&lambda;</em>)/2, EMPTY) &rarr; ..., (START, (1 &minus; sqrt(<em>&lambda;</em>))/2, EMPTY) &rarr; ....</p>

<p><strong>Proposition 1A:</strong> <em>If f(&lambda;) is in the class <strong>PDA</strong>, then so is every polynomial written as&mdash;</em></p>

<p>$${n\choose 0}f(\lambda)^0 (1-f(\lambda))^{n-0} a[0] + {n\choose 1}f(\lambda)^1 (1-f(\lambda))^{n-1} a[1] + ... + {n\choose n}f(\lambda)^n (1-f(\lambda))^{n-n} a[n],$$</p>

<p><em>where n is the polynomial&#39;s degree and a[0], a[1], ..., a[n] are functions in the class <strong>PDA</strong>.</em></p>

<p><em>Proof Sketch</em>: This corresponds to a two-stage pushdown automaton that follows the algorithm of Goyal and Sigman (2012)[^33]: The first stage counts the number of &quot;heads&quot; shown when flipping the f(&lambda;) coin, and the second stage flips another coin that has success probability <em>a</em>[<em>i</em>], where <em>i</em> is the number of &quot;heads&quot;. The automaton&#39;s transitions take advantage of Lemma 1A.  &#x25a1;</p>

<p><strong>Proposition 1:</strong> <em>If f(&lambda;) and g(&lambda;) are functions in the class <strong>PDA</strong>, then so is their product, namely f(&lambda;)*g(&lambda;).</em></p>

<p><em>Proof:</em> Special case of Proposition 1A with <em>n</em>=1, <em>f</em>(<em>&lambda;</em>)=<em>f</em>(<em>&lambda;</em>), <em>a</em>[0]=0 (using Lemma 1B), and <em>a</em>[1]=<em>g</em>(<em>&lambda;</em>).  &#x25a1;</p>

<p><strong>Corollary 1A:</strong> <em>If f(&lambda;), g(&lambda;), and h(&lambda;) are functions in the class <strong>PDA</strong>, then so is f(&lambda;)*g(&lambda;) + (1&minus;f(&lambda;))*h(&lambda;).</em></p>

<p><em>Proof:</em> Special case of Proposition 1A with <em>n</em>=1, <em>f</em>(<em>&lambda;</em>)=<em>f</em>(<em>&lambda;</em>), <em>a</em>[0]=<em>h</em>(<em>&lambda;</em>), and <em>a</em>[1]=<em>g</em>(<em>&lambda;</em>).  &#x25a1;</p>

<p><strong>Proposition 2:</strong> <em>If f(&lambda;) and g(&lambda;) are functions in the class <strong>PDA</strong>, then so is their composition, namely f(g(&lambda;)) or f&#x2218;g(&lambda;).</em></p>

<p><em>Proof:</em> Let <em>F</em> be the full-domain pushdown automaton for <em>f</em>. For each state/symbol pair among the left-hand sides of <em>F</em>&#39;s rules, apply Lemma 1A to the automaton <em>F</em>, using the function <em>g</em>.  Then the new machine <em>F</em> terminates with probability 1 because the original <em>F</em> and the original automaton for <em>g</em> do for every <em>&lambda;</em> greater than 0 and less than 1, and because the automaton for <em>g</em> maps to (0, 1) where <em>F</em> terminates with probability 1.  Moreover, <em>f</em> is in class <strong>PDA</strong> by Theorem 1.2 of (Mossel and Peres 2005)[^15] because the machine is a full-domain pushdown automaton.  &#x25a1;</p>

<p><strong>Proposition 3:</strong> <em>Every rational function with rational coefficients that maps (0, 1) to itself is in class <strong>PDA</strong>.</em></p>

<p><em>Proof:</em> These functions can be simulated by a finite-state machine (Mossel and Peres 2005)[^15].  This corresponds to a full-domain pushdown automaton that has no stack symbols other than EMPTY, never pushes symbols onto the stack, and pops the only symbol EMPTY from the stack whenever it transitions to a final state of the finite-state machine. &#x25a1;</p>

<blockquote>
<p><strong>Note:</strong> An unbounded stack size is necessary for a pushdown automaton to simulate functions that a finite-state machine can&#39;t.  With a bounded stack size, there is a finite-state machine where each state not only holds the pushdown automaton&#39;s original state, but also encodes the contents of the stack (which is possible because the stack&#39;s size is bounded); each operation that would push, pop, or change the top symbol transitions to a state with the appropriate encoding of the stack instead.</p>
</blockquote>

<p><strong>Proposition 4:</strong> <em>If a full-domain pushdown automaton can generate words with the same letter such that the length of each word follows a probability distribution, then that distribution&#39;s probability generating function is in class <strong>PDA</strong>.</em></p>

<p><em>Proof:</em> Let <em>F</em> be a full-domain pushdown automaton.  Add one state FAILURE, then augment <em>F</em> with a special &quot;letter-generating&quot; operation as follows.  Add the following rule that pops all symbols from the stack:</p>

<p>(FAILURE, <em>flip</em>, <em>stacksymbol</em>) &rarr; (FAILURE, {}),</p>

<p>and for each rule of the following form that transitions to a letter-generating operation (where S and T are arbitrary states):</p>

<p>(S, <em>flip</em>, <em>stacksymbol</em>) &rarr; (T, <em>newstack</em>),</p>

<p>add another state S&prime; (with a name that differs from all other states) and replace that rule with the following rules:</p>

<p>(S, <em>flip</em>, <em>stacksymbol</em>) &rarr; (S&prime;, {<em>stacksymbol</em>}),<br/>
(S&prime;, HEADS, <em>stacksymbol</em>) &rarr; (T, <em>newstack</em>), and<br/>
(S&prime;, TAILS, <em>stacksymbol</em>) &rarr; (FAILURE, {}).</p>

<p>Then if the stack is empty upon reaching the FAILURE state, the result is 0, and if the stack is empty upon reaching any other state, the result is 1.  By (Dughmi et al. 2021)[^5], the machine now simulates the distribution&#39;s probability generating function.  Moreover, the function is in class <strong>PDA</strong> by Theorem 1.2 of (Mossel and Peres 2005)[^15] because the machine is a full-domain pushdown automaton.  &#x25a1;</p>

<p>Define a <em>stochastic context-free grammar</em> as follows.  The grammar consists of a finite set of <em>nonterminals</em> and a finite set of <em>letters</em>, and rewrites one nonterminal (the starting nonterminal) into a word.  The grammar has three kinds of rules (in generalized Chomsky Normal Form (Etessami and Yannakakis 2009)[^32]):</p>

<ul>
<li><em>X</em> &rarr; <em>a</em> (rewrite <em>X</em> to the letter <em>a</em>).</li>
<li><em>X</em> &rarr;<sub><em>p</em></sub> (<em>a</em>, <em>Y</em>) (with rational probability <em>p</em>, rewrite <em>X</em> to the letter <em>a</em> followed by the nonterminal <em>Y</em>).  For the same left-hand side, all the <em>p</em> must sum to 1.</li>
<li><em>X</em> &rarr; (<em>Y</em>, <em>Z</em>) (rewrite <em>X</em> to the nonterminals <em>Y</em> and <em>Z</em> in that order).</li>
</ul>

<p>Instead of a letter (such as <em>a</em>), a rule can use <em>&epsilon;</em> (the empty string). (The grammar is <em>context-free</em> because the left-hand side has only a single nonterminal, so that no context from the word is needed to parse it.)</p>

<p><strong>Proposition 5:</strong> <em>Every stochastic context-free grammar can be transformed into a pushdown automaton.  If the automaton is a full-domain pushdown automaton and the grammar has a one-letter alphabet, the automaton can generate words such that the length of each word follows the same distribution as the grammar, and that distribution&#39;s probability generating function is in class <strong>PDA</strong>.</em></p>

<p><em>Proof Sketch:</em> In the equivalent pushdown automaton:</p>

<ul>
<li><em>X</em> &rarr; <em>a</em> becomes the two rules&mdash;<br>(START, HEADS, <em>X</em>) &rarr; (<em>letter</em>, {}), and<br>(START, TAILS, <em>X</em>) &rarr; (<em>letter</em>, {}).<br>Here, <em>letter</em> is either START or a unique state in <em>F</em> that &quot;detours&quot; to a letter-generating operation for <em>a</em> and sets the state back to START when finished (see Proposition 4).  If <em>a</em> is <em>&epsilon;</em>, <em>letter</em> is START and no letter-generating operation is done.</li>
<li><em>X</em> &rarr;<sub><em>p</em><sub><em>i</em></sub></sub> (<em>a</em><sub><em>i</em></sub>, <em>Y</em><sub><em>i</em></sub>) (all rules with the same nonterminal <em>X</em>) are rewritten to enough rules to transition to a letter-generating operation for <em>a</em><sub><em>i</em></sub>, and swap the top stack symbol with <em>Y</em><sub><em>i</em></sub>, with probability <em>p</em><sub><em>i</em></sub>, which is possible with just a finite-state machine (see Proposition 4) because all the probabilities are rational numbers (Mossel and Peres 2005)[^15].  If <em>a</em><sub><em>i</em></sub> is <em>&epsilon;</em>, no letter-generating operation is done.</li>
<li><em>X</em> &rarr; (<em>Y</em>, <em>Z</em>) becomes the two rules&mdash;<br>(START, HEADS, <em>X</em>) &rarr; (START, {<em>Z</em>, <em>Y</em>}), and<br>(START, TAILS, <em>X</em>) &rarr; (START, {<em>Z</em>, <em>Y</em>}).</li>
</ul>

<p>Here, <em>X</em> is the stack symbol EMPTY if <em>X</em> is the grammar&#39;s starting nonterminal. Now, assuming the automaton is full-domain, the rest of the result follows easily.   For a single-letter alphabet, the grammar corresponds to a system of polynomial equations, one for each rule in the grammar, as follows:</p>

<ul>
<li><em>X</em> &rarr; <em>a</em> becomes <em>X</em> = 1 if <em>a</em> is the empty string (<em>&epsilon;</em>), or <em>X</em> =  <em>&lambda;</em> otherwise.</li>
<li>For each nonterminal <em>X</em>, all <em>n</em> rules of the form <em>X</em> &rarr;<sub><em>p</em><sub><em>i</em></sub></sub> (<em>a</em><sub><em>i</em></sub>, <em>Y</em><sub><em>i</em></sub>) become the equation <em>X</em> = <em>p</em><sub>1</sub>*<em>&lambda;</em><sub>1</sub>*<em>Y</em><sub>1</sub> + <em>p</em><sub>2</sub>*<em>&lambda;</em><sub>2</sub>*<em>Y</em><sub>2</sub> + ... + <em>p</em><sub><em>n</em></sub>*<em>&lambda;</em><sub><em>n</em></sub>*<em>Y</em><sub><em>n</em></sub>, where <em>&lambda;</em><sub><em>i</em></sub> is either 1 if <em>a</em><sub><em>i</em></sub> is <em>&epsilon;</em>, or <em>&lambda;</em> otherwise.</li>
<li><em>X</em> &rarr; (<em>Y</em>, <em>Z</em>) becomes <em>X</em> = <em>Y</em>*<em>Z</em>.</li>
</ul>

<p>Solving this system for the grammar&#39;s starting nonterminal, and applying Proposition 4, leads to the <em>probability generating function</em> for the grammar&#39;s word distribution.  (See also Flajolet et al. 2010[^14], Icard 2020[^31].) &#x25a1;</p>

<blockquote>
<p><strong>Example:</strong> The stochastic context-free grammar&mdash;<br><em>X</em> &rarr;<sub>1/2</sub> (<em>a</em>, <em>X1</em>),<br><em>X1</em> &rarr; (<em>X</em>, <em>X2</em>),<br><em>X2</em> &rarr; (<em>X</em>, <em>X</em>),<br><em>X</em> &rarr;<sub>1/2</sub> (<em>a</em>, <em>X3</em>),<br><em>X3</em> &rarr; <em>&epsilon;</em>,<br>which encodes ternary trees (Flajolet et al. 2010)[^14], corresponds to the equation <em>X</em> = (1/2) * <em>&lambda;</em>*<em>X</em>*<em>X</em>*<em>X</em> + (1/2)*<em>&lambda;</em>*1, and solving this equation for <em>X</em> leads to the probability generating function for such trees, which is a complicated expression.</p>

<p><strong>Notes:</strong></p>

<ol>
<li><p>A stochastic context-free grammar in which all the probabilities are 1/2 is called a <em>binary stochastic grammar</em> (Flajolet et al. 2010[^14]).  If every probability is a multiple of 1/<em>n</em>, then the grammar can be called an &quot;<em>n</em>-ary stochastic grammar&quot;.  It is even possible for a nonterminal to have two rules of probability <em>&lambda;</em> and (1&minus; <em>&lambda;</em>), which are used when the input coin returns 1 (HEADS) or 0 (TAILS), respectively.</p></li>
<li><p>If a pushdown automaton simulates the function <em>f</em>(<em>&lambda;</em>), then <em>f</em> corresponds to a special system of equations, built as follows (Mossel and Peres 2005)[^15]; see also (Esparza et al. 2004)[^34].  For each state of the automaton (call the state <em>en</em>), include the following equations in the system based on the automaton&#39;s transition rules:</p>

<ul>
<li>(<em>st</em>, <em>p</em>, <em>sy</em>) &rarr; (<em>s2</em>, {}) becomes either <em>&alpha;</em><sub><em>st</em>,<em>sy</em>,<em>en</em></sub> = <em>p</em> if <em>s2</em> is <em>en</em>, or <em>&alpha;</em><sub><em>st</em>,<em>sy</em>,<em>en</em></sub> = 0 otherwise.</li>
<li>(<em>st</em>, <em>p</em>, <em>sy</em>) &rarr; (<em>s2</em>, {<em>sy1</em>}) becomes <em>&alpha;</em><sub><em>st</em>,<em>sy</em>,<em>en</em></sub> = <em>p</em> * <em>&alpha;</em><sub><em>s2</em>,<em>sy1</em>,<em>en</em></sub>.</li>
<li>(<em>st</em>, <em>p</em>, <em>sy</em>) &rarr; (<em>s2</em>, {<em>sy1</em>, <em>sy2</em>}) becomes <em>&alpha;</em><sub><em>st</em>,<em>sy</em>,<em>en</em></sub> = <em>p</em>*<em>&alpha;</em><sub><em>s2</em>,<em>sy2</em>,<em>&sigma;[1]</em></sub>*<em>&alpha;</em><sub><em>&sigma;[1]</em>,<em>sy1</em>,<em>en</em></sub> + ... + <em>p</em>*<em>&alpha;</em><sub><em>s2</em>,<em>sy2</em>,<em>&sigma;[n]</em></sub>*<em>&alpha;</em><sub><em>&sigma;[n]</em>,<em>sy1</em>,<em>en</em></sub>, where <em>&sigma;[i]</em> is one of the machine&#39;s <em>n</em> states.</li>
</ul>

<p>(Here, <em>p</em> is the probability of using the given transition rule; the special value HEADS becomes <em>&lambda;</em>, and the special value TAILS becomes 1&minus;<em>&lambda;</em>.)  Now, each time multiple equations have the same left-hand side, combine them into one equation with the same left-hand side, but with the sum of their right-hand sides.  Then, for every variable of the form <em>&alpha;</em><sub><em>a</em>,<em>b</em>,<em>c</em></sub> not yet present in the system, include the equation <em>&alpha;</em><sub><em>a</em>,<em>b</em>,<em>c</em></sub> = 0.  Then, for each final state <em>fs</em> that returns 1, solve the system for the variable <em>&alpha;</em><sub>START,EMPTY,<em>fs</em></sub> (where START is the automaton&#39;s starting state) to get a solution (a function) that maps (0, 1) to itself. (Each solve can produce multiple solutions, but only one of them will map (0, 1) to itself assuming every <em>p</em> is either HEADS or TAILS.) Finally, add all the solutions to get <em>f</em>(<em>&lambda;</em>).</p></li>
<li><p>Assume there is a pushdown automaton (<em>F</em>) that follows Definition 1 except it uses a set of <em>N</em> input letters (and not simply HEADS or TAILS), accepts an input word if the stack is empty, and rejects the word if the machine reaches a configuration without a transition rule.  Then a pushdown automaton in the full sense of Definition 1 (<em>G</em>) can be built.  In essence:</p>

<ol>
<li>Add a new FAILURE state, which when reached, pops all symbols from the stack.</li>
<li>For each pair (<em>state</em>, <em>stacksymbol</em>) for <em>F</em>, add a set of rules that generate one of the input letters (each letter <em>i</em> generated with probability <em>f</em><sub> <em>i</em></sub>(<em>&lambda;</em>), which must be a function in <strong>PDA</strong>), then use the generated letter to perform the transition stated in the corresponding rule for <em>F</em>.  If there is no such transition, transition to the FAILURE state instead.</li>
<li>When the stack is empty, output 0 if <em>G</em> is in the FAILURE state, or 1 otherwise.</li>
</ol>

<p>Then <em>G</em> returns 1 with the same probability as <em>F</em> accepts an input word with letters randomly generated as in the second step.  Also, one of the <em>N</em> letters can be a so-called &quot;end-of-string&quot; symbol, so that a pushdown automaton can be built that accepts &quot;empty strings&quot;; an example is (Elder et al. 2015)[^35].</p></li>
</ol>
</blockquote>

<p><strong>Proposition 6:</strong> <em>If a full-domain pushdown automaton can generate a distribution of words with the same letter, there is a full-domain pushdown automaton that can generate a distribution of such words conditioned on&mdash;</em></p>

<ol>
<li><em>a finite set of word lengths, or</em></li>
<li><em>a periodic infinite set of word lengths.</em></li>
</ol>

<p>One example of a finite set of word lengths is {1, 3, 5, 6}, where only words of length 1, 3, 5, or 6 are allowed.  A <em>periodic infinite set</em> is defined by a finite set of integers such as {1}, as well as an integer modulus such as 2, so that in this example, all integers congruent to 1 modulo 2 (that is, all odd integers) are allowed word lengths and belong to the set.</p>

<p><em>Proof Sketch:</em></p>

<ol>
<li><p>As in Lemma 1A, assume that the automaton stops when it pops EMPTY from the stack.  Let <em>S</em> be the finite set (for example, {1, 3, 5, 6}), and let <em>M</em> be the maximum value in the finite set.  For each integer <em>i</em> in [0, <em>M</em>], make a copy of the automaton and append the integer <em>i</em> to the name of each of its states.  Combine the copies into a new automaton <em>F</em>, and let its start state be the start state for copy 0.  Now, whenever <em>F</em> generates a letter, instead of transitioning to the next state after the letter-generating operation (see Proposition 4), transition to the corresponding state for the next copy (for example, if the operation would transition to copy 2&#39;s version of &quot;XYZ&quot;, namely &quot;2_XYZ&quot;, transition to &quot;3_XYZ&quot; instead), or if the last copy is reached, transition to the last copy&#39;s FAILURE state.  If <em>F</em> would transition to a failure state corresponding to a copy not in <em>S</em> (for example, &quot;0_FAILURE&quot;, &quot;2_FAILURE&quot;, &quot;3_FAILURE&quot; in this example), first all symbols other than EMPTY are popped from the stack and then <em>F</em> transitions to its start state (this is a so-called &quot;rejection&quot; operation).  Now, all the final states (except FAILURE states) for the copies corresponding to the values in <em>S</em> (for example, copies 1, 3, 5, 6 in the example) are treated as returning 1, and all other states are treated as returning 0.</p></li>
<li><p>Follow (1), except as follows: (A) <em>M</em> is equal to the integer modulus minus 1.  (B) For the last copy of the automaton, instead of transitioning to the next state after the letter-generating operation (see Proposition 4), transition to the corresponding state for copy 0 of the automaton.  &#x25a1;</p></li>
</ol>

<p><strong>Proposition 7:</strong> <em>Every constant function equal to a quadratic irrational number between 0 and 1 is in class <strong>PDA</strong>.</em></p>

<p>A <em>continued fraction</em> is one way to write a real number.  For purposes of the following proof, every real number greater than 0 and less than 1 has the following <em>continued fraction expansion</em>: 0 + 1 / (<em>a</em>[1] + 1 / (<em>a</em>[2] + 1 / (<em>a</em>[3] + ... ))), where each <em>a</em>[<em>i</em>], a <em>partial denominator</em>, is an integer greater than 0.  A <em>quadratic irrational number</em> is an irrational number that can be written as (<em>b</em>+sqrt(<em>c</em>))/<em>d</em>, where <em>b</em>, <em>c</em>, and <em>d</em> are rational numbers.</p>

<p><em>Proof:</em>  By Lagrange&#39;s continued fraction theorem, every quadratic irrational number has a continued fraction expansion that is eventually periodic; the expansion can be described using a finite number of partial denominators, the last &quot;few&quot; of which repeat forever.  The following example describes a periodic continued fraction expansion: [0; 1, 2, (5, 4, 3)], which is the same as [0; 1, 2, 5, 4, 3, 5, 4, 3, 5, 4, 3, ...].  In this example, the partial denominators are the numbers after the semicolon; the size of the period (<code>(5, 4, 3)</code>) is 3; and the size of the non-period (<code>1, 2</code>) is 2.</p>

<p>Given a periodic expansion, and with the aid of an algorithm for simulating <a href="https://peteroupc.github.io/bernoulli.html#Continued_Fractions"><strong>continued fractions</strong></a>, a recursive Markov chain for the expansion (Etessami and Yannakakis 2009)[^32] can be described as follows.  The chain&#39;s components are all built on the following template.  The template component has one entry E, one inner node N, one box, and two exits X0 and X1.  The box has one <em>call port</em> as well as two <em>return ports</em> B0 and B1.</p>

<ul>
<li>From E: Go to N with probability <em>x</em>, or to the box&#39;s call port with probability 1 &minus; <em>x</em>.</li>
<li>From N: Go to X1 with probability <em>y</em>, or to X0 with probability 1 &minus; <em>y</em>.</li>
<li>From B0: Go to E with probability 1.</li>
<li>From B1: Go to X0 with probability 1.</li>
</ul>

<p>Let <em>p</em> be the period size, and let <em>n</em> be the non-period size.  Now the recursive Markov chain to be built has <em>n</em>+<em>p</em> components:</p>

<ul>
<li>For each <em>i</em> in [1, <em>n</em>+1], there is a component labeled <em>i</em>.  It is the same as the template component, except <em>x</em> = <em>a</em>[<em>i</em>]/(1 + <em>a</em>[<em>i</em>]), and <em>y</em> = 1/<em>a</em>[<em>i</em>].  The component&#39;s single box goes to the component labeled <em>i</em>+1, <em>except</em> that for component <em>n</em>+<em>p</em>, the component&#39;s single box goes to the component labeled <em>n</em>+1.</li>
</ul>

<p>According to Etessami and Yannakakis (2009)[^32], the recursive Markov chain can be translated to a pushdown automaton of the kind used in this section. Now all that&#39;s left is to argue that the recursive Markov chain terminates with probability 1.  For every component in the chain, it goes from its entry to its box with probability 1/2 or less (because each partial numerator must be 1 or greater).  Thus, the component recurses with no greater probability than not, and there are otherwise no probability-1 loops in each component, so the overall chain terminates with probability 1. &#x25a1;</p>

<p><strong>Lemma 1:</strong> <em>The square root function sqrt(&lambda;) is in class <strong>PDA</strong>.</em></p>

<p><em>Proof:</em> See (Mossel and Peres 2005)[^15]. &#x25a1;</p>

<p><strong>Corollary 1:</strong> <em>The function f(&lambda;) = &lambda;<sup>m/(2<sup>n</sup>)</sup>, where n &ge; 1 is an integer and where m &ge; 1 is an integer, is in class <strong>PDA</strong>.</em></p>

<p><em>Proof:</em> Start with the case <em>m</em>=1.  If <em>n</em> is 1, write <em>f</em> as sqrt(<em>&lambda;</em>); if <em>n</em> is 2, write <em>f</em> as sqrt&#x2218;sqrt(<em>&lambda;</em>); and for general <em>n</em>, write <em>f</em> as sqrt&#x2218;sqrt&#x2218;...&#x2218;sqrt(<em>&lambda;</em>), with <em>n</em> instances of sqrt.  Because this is a composition and sqrt can be simulated by a full-domain pushdown automaton, so can <em>f</em>.</p>

<p>For general <em>m</em> and <em>n</em>, write <em>f</em> as (sqrt&#x2218;sqrt&#x2218;...&#x2218;sqrt(<em>&lambda;</em>))<sup><em>m</em></sup>, with <em>n</em> instances of sqrt.  This involves doing <em>m</em> multiplications of sqrt&#x2218;sqrt&#x2218;...&#x2218;sqrt, and because this is an integer power of a function that can be simulated by a full-domain pushdown automaton, so can <em>f</em>.</p>

<p>Moreover, <em>f</em> is in class <strong>PDA</strong> by Theorem 1.2 of (Mossel and Peres 2005)[^15] because the machine is a full-domain pushdown automaton. &#x25a1;</p>

<p><a id=Finite_State_and_Pushdown_Generators></a></p>

<h4>Finite-State and Pushdown Generators</h4>

<p>Another interesting class of machines (called <em>pushdown generators</em> here) are similar to pushdown automata (see above), with the following exceptions:</p>

<ol>
<li>Each transition rule can also, optionally, output a base-<em>N</em> digit in its right-hand side.  An example is: (<em>state</em>, <em>flip</em>, <em>sy</em>) &rarr; (<em>digit</em>, <em>state2</em>, {<em>sy2</em>}).</li>
<li>The machine must output infinitely many digits if allowed to run forever.</li>
<li>Rules that would pop the last symbol from the stack are not allowed.</li>
</ol>

<p>The &quot;output&quot; of the machine is now a real number <em>X</em> in the form of the base-<em>N</em> digit expansion <code>0.dddddd...</code>, where <code>dddddd...</code> are the digits produced by the machine from left to right.  In the rest of this section:</p>

<ul>
<li><code>CDF(z)</code> is the cumulative distribution function of <em>X</em>, or the probability that <em>X</em> is <em>z</em> or less.</li>
<li><code>PDF(z)</code> is the probability density function of <em>X</em>, or the &quot;slope&quot; function of <code>CDF(z)</code>, or the relative probability of choosing a number &quot;close&quot; to <em>z</em> at random.</li>
</ul>

<p>A <em>finite-state generator</em> (Knuth and Yao 1976)[^6] is the special case where the probability of heads is 1/2, each digit is either 0 or 1, rules can&#39;t push stack symbols, and only one stack symbol is used.  Then if <code>PDF(z)</code> has infinitely many &quot;slope&quot; functions on the open interval (0, 1), it must be a polynomial with rational coefficients and not equal 0 at any irrational point on (0, 1) (Vatan 2001)[^36], (Kindler and Romik 2004)[^37], and it can be shown that the mean of <em>X</em> must be a rational number.  [^38]</p>

<p><strong>Proposition 8.</strong> <em>Suppose a finite-state generator can generate a probability distribution that takes on finitely many values.  Then:</em></p>

<ol>
<li><em>Each value occurs with a rational probability.</em></li>
<li><em>Each value is either rational or transcendental.</em></li>
</ol>

<p>A real number is <em>transcendental</em> if it can&#39;t be a root of a nonzero polynomial with integer coefficients.  Thus, part 2 means, for example, that irrational, non-transcendental numbers such as 1/sqrt(2) and the golden ratio minus 1 can&#39;t be generated exactly.</p>

<p>Proving this proposition involves the following lemma, which shows that a finite-state generator is related to a machine with a one-way read-only input and a one-way write-only output:</p>

<p><strong>Lemma 2.</strong> <em>A finite-state generator can fit the model of a one-way transducer-like k-machine (as defined in Adamczewski et al. (2020)[^39] section 5.3), for some k equal to 2 or greater.</em></p>

<p><em>Proof Sketch:</em> There are two cases.</p>

<p>Case 1: If every transition rule of the generator outputs a digit, then <em>k</em> is the number of unique inputs among the generator&#39;s transition rules (usually, there are two unique inputs, namely HEADS and TAILS), and the model of a finite-state generator is modified as follows:</p>

<ol>
<li>A <em>configuration</em> of the finite-state generator consists of its current state together with either the last coin flip result or, if the coin wasn&#39;t flipped yet, the empty string.</li>
<li>The <em>output function</em> takes a configuration described above and returns a digit.  If the coin wasn&#39;t flipped yet, the function returns an arbitrary digit (which is not used in proposition 4.6 of the Adamczewski paper).</li>
</ol>

<p>Case 2: If at least one transition rule does not output a digit, then the finite-state generator can be transformed to a machine where HEADS/TAILS is replaced with 50% probabilities, then transformed to an equivalent machine whose rules always output one or more digits, as claimed in Lemma 5.2 of Vatan (2001)[^36].  In case the resulting generator has rules that output more than one digit, additional states and rules can be added so that the generator&#39;s rules output only one digit as desired.  Now at this point the generator&#39;s probabilities will be rational numbers. Now transform the generator from probabilities to inputs of size <em>k</em>, where <em>k</em> is the product of those probabilities, by adding additional rules as desired.  &#x25a1;</p>

<p><em>Proof of Proposition 8:</em> Let <em>n</em> be an integer greater than 0. Take a finite-state generator that starts at state START and branches to one of <em>n</em> finite-state generators (sub-generators) with some probability, which must be rational because the overall generator is a finite-state machine (Icard 2020, Proposition 13)[^31].  The branching process outputs no digit, and part 3 of the proposition follows from Corollary 9 of Icard (2020)[^31].  The <em>n</em> sub-generators are special; each of them generates the binary expansion of a single real number in [0, 1] with probability 1.</p>

<p>To prove part 2 of the proposition, translate an arbitrary finite-state generator to a machine described in Lemma 2.  Once that is done, all that must be shown is that there are two different non-empty sequences of coin flips that end up at the same configuration. This is easy using the pigeonhole principle, since the finite-state generator has a finite number of configurations. Thus, by propositions 5.11, 4.6, and AB of Adamczewski et al. (2020)[^39], the generator can generate a real number&#39;s binary expansion only if that number is rational or transcendental (see also Cobham (1968)[^40]; Adamczewski and Bugeaud (2007)[^41]).</s>  &#x25a1;</p>

<p><strong>Proposition 9.</strong> <em>If the distribution function generated by a finite-state generator is continuous and algebraic on the open interval (0, 1), then that function is a piecewise polynomial function on that interval.</em></p>

<p>The proof follows from combining Kindler and Romik (2004, Theorem 2)[^37] and Knuth and Yao (1976)[^6] with Richman (2012)[^42], who proved that a continuous algebraic function on an open interval is piecewise analytic (&quot;analytic&quot; is a stronger statement than having infinitely many &quot;slope&quot; functions).</p>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>

<div class="noprint">
<p>
<a href="//twitter.com/intent/tweet">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
</script>
</body></html>
