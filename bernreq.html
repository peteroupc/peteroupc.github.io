<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Open Questions on the Bernoulli Factory Problem</title><meta name="citation_title" content="Open Questions on the Bernoulli Factory Problem"><meta name="citation_pdf_url" content="https://peteroupc.github.io/bernreq.pdf"><meta name="citation_url" content="https://peteroupc.github.io/bernreq.html"><meta name="citation_date" content="2023/05/19"><meta name="citation_online_date" content="2023/05/19"><meta name="og:title" content="Open Questions on the Bernoulli Factory Problem"><meta name="og:type" content="article"><meta name="og:url" content="https://peteroupc.github.io/bernreq.html"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="Open Questions on the Bernoulli Factory Problem"><meta name="author" content="Peter Occil"/><meta name="citation_author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css">
            <script type="text/x-mathjax-config"> MathJax.Hub.Config({"HTML-CSS": { availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, preferredFont: "TeX" },
                    tex2jax: { displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ], processEscapes: true } });
            </script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"></script></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>Open Questions on the Bernoulli Factory Problem</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><a id=Background></a></p>

<h2>Background</h2>

<p>Suppose there is a coin that shows heads with an unknown probability, $\lambda$. The goal is to use that coin (and possibly also a fair coin) to build a &quot;new&quot; coin that shows heads with a probability that depends on $\lambda$, call it $f(\lambda)$. This is the <em>Bernoulli factory problem</em>, and it can be solved only for certain functions $f$. (For example, flipping the coin twice and taking heads only if exactly one coin shows heads, the probability $2\lambda(1-\lambda)$ can be simulated.)</p>

<p>Specifically, the only functions that can be simulated this way <strong>are continuous and polynomially bounded on their domain, and map $[0, 1]$ or a subset thereof to $[0, 1]$</strong>, as well as $f=0$ and $f=1$. These functions are called <em>factory functions</em> in this page. (A function $f(x)$ is <em>polynomially bounded</em> if both $f$ and $1-f$ are greater than or equal to min($x^n$, $(1-x)^n$) for some integer $n$ (Keane and O&#39;Brien 1994). This implies that $f$ admits no roots on (0, 1) and can&#39;t take on the value 0 or 1 except possibly at 0, 1, or both.)</p>

<p>This page contains several questions about the <a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli factory</strong></a> problem.  Answers to them will greatly improve my pages on this site about Bernoulli factories.  If you can answer any of them, post an issue in the <a href="https://github.com/peteroupc/peteroupc.github.io/issues"><strong>GitHub issues page</strong></a>.</p>

<p><a id=Contents></a></p>

<h2>Contents</h2>

<ul>
<li><a href="#Background"><strong>Background</strong></a></li>
<li><a href="#Contents"><strong>Contents</strong></a></li>
<li><a href="#Key_Problems"><strong>Key Problems</strong></a></li>
<li><a href="#Polynomials_that_approach_a_factory_function_fast"><strong>Polynomials that approach a factory function &quot;fast&quot;</strong></a>

<ul>
<li><a href="#Main_Question"><strong>Main Question</strong></a></li>
<li><a href="#Solving_the_Bernoulli_factory_problem_with_polynomials"><strong>Solving the Bernoulli factory problem with polynomials</strong></a></li>
<li><a href="#A_Matter_of_Efficiency"><strong>A Matter of Efficiency</strong></a></li>
<li><a href="#A_Conjecture_on_Polynomial_Approximation"><strong>A Conjecture on Polynomial Approximation</strong></a></li>
<li><a href="#Strategies"><strong>Strategies</strong></a></li>
</ul></li>
<li><a href="#Tossing_Heads_According_to_a_Concave_Function"><strong>Tossing Heads According to a Concave Function</strong></a>

<ul>
<li><a href="#Special_Cases"><strong>Special Cases</strong></a></li>
</ul></li>
<li><a href="#New_coins_from_old_smoothly"><strong>New coins from old, smoothly</strong></a>

<ul>
<li><a href="#Questions"><strong>Questions</strong></a></li>
</ul></li>
<li><a href="#Simulable_and_strongly_simulable_functions"><strong>Simulable and strongly simulable functions</strong></a></li>
<li><a href="#Multiple_Output_Bernoulli_Factories"><strong>Multiple-Output Bernoulli Factories</strong></a>

<ul>
<li><a href="#Questions_2"><strong>Questions</strong></a></li>
<li><a href="#Functions_with_Optimal_Factories"><strong>Functions with Optimal Factories</strong></a></li>
</ul></li>
<li><a href="#From_coin_flips_to_algebraic_functions_via_pushdown_automata"><strong>From coin flips to algebraic functions via pushdown automata</strong></a>

<ul>
<li><a href="#Pushdown_Automata"><strong>Pushdown Automata</strong></a></li>
<li><a href="#Algebraic_Functions"><strong>Algebraic Functions</strong></a></li>
<li><a href="#Questions_3"><strong>Questions</strong></a></li>
</ul></li>
<li><a href="#Reverse_time_martingales"><strong>Reverse-time martingales</strong></a></li>
<li><a href="#Other_Questions"><strong>Other Questions</strong></a></li>
<li><a href="#End_Notes"><strong>End Notes</strong></a></li>
<li><a href="#References"><strong>References</strong></a></li>
</ul>

<p><a id=Key_Problems></a></p>

<h2>Key Problems</h2>

<p>The following summarizes most of the problems raised by these open questions.</p>

<ol>
<li><p><strong>Suppose $f:[0,1]\to [0,1]$ is continuous and belongs to a large class of functions (e.g., the $k$-th derivative, $k\ge 0$, is continuous, Lipschitz, concave, strictly increasing, bounded variation, or Zygmund, or $f$ is real analytic).</strong></p>

<ul>
<li><em>Exact Bernoulli factory</em>: <strong>Assuming $0\lt f(\lambda)\lt 1$, compute the Bernstein coefficients of a sequence of polynomials ($g_n$) of degree 2, 4, 8, ..., $2^i$, ... that converge to $f$ from below and satisfy: $(g_{2n}-g_{n})$ is a polynomial with non-negative Bernstein coefficients once it&#39;s rewritten to a polynomial in Bernstein form of degree exactly $2n$.</strong></li>
<li><em>Approximate Bernoulli factory</em>: <strong>Given $\epsilon &gt; 0$, compute the Bernstein coefficients of a polynomial or rational function (of some degree $n$) that is within $\epsilon$ of $f$.</strong></li>
<li><em>Series expansion of simple functions</em>: <strong>Find a random variable $X$ and a non-trivial series $f(\lambda)=\sum_{a\ge 0}\gamma_a(\lambda)$ such that $\gamma_a(\lambda)/\mathbb{P}(X=a)$ is a polynomial or rational function with Bernstein coefficients lying in [0, 1].</strong></li>
</ul>

<p><strong>The convergence rate must be $O(1/n^{r/2})$ if the class has only functions with Lipschitz-continuous $(r-1)$-th derivative.  The method may not introduce transcendental or trigonometric functions (as with Chebyshev interpolants).</strong></p></li>
<li><p><strong>Characterize the following three classes of factory functions $f(\lambda)$:</strong></p>

<ul>
<li><strong>Can be simulated using nothing but the biased coin, when the biased coin can show heads every time, tails every time, or both.</strong></li>
<li><strong>Have a Bernoulli factory that can come arbitrarily close to the entropy limit if it produces multiple $f$-coin flips at a time, rather than just one.</strong></li>
<li><strong>Are algebraic and can be simulated by a finite-state machine with an unbounded stack.</strong></li>
</ul></li>
</ol>

<p><a id=Polynomials_that_approach_a_factory_function_fast></a></p>

<h2>Polynomials that approach a factory function &quot;fast&quot;</h2>

<p><a href="https://math.stackexchange.com/questions/3904732/what-are-ways-to-compute-polynomials-that-converge-from-above-and-below-to-a-con"><strong>https://math.stackexchange.com/questions/3904732/what-are-ways-to-compute-polynomials-that-converge-from-above-and-below-to-a-con</strong></a></p>

<p><a href="https://mathoverflow.net/questions/442057/explicit-and-fast-error-bounds-for-approximating-continuous-functions"><strong>https://mathoverflow.net/questions/442057/explicit-and-fast-error-bounds-for-approximating-continuous-functions</strong></a></p>

<p><a href="https://mathoverflow.net/questions/427595/a-conjecture-on-consistent-monotone-sequences-of-polynomials-in-bernstein-form"><strong>https://mathoverflow.net/questions/427595/a-conjecture-on-consistent-monotone-sequences-of-polynomials-in-bernstein-form</strong></a></p>

<p><a href="https://mathoverflow.net/questions/429037/bounds-on-the-expectation-of-a-function-of-a-hypergeometric-random-variable"><strong>https://mathoverflow.net/questions/429037/bounds-on-the-expectation-of-a-function-of-a-hypergeometric-random-variable</strong></a></p>

<p>This question involves solving the Bernoulli factory problem with polynomials.</p>

<p>In this question, a polynomial $P(x)$ is written in <em>Bernstein form of degree $n$</em> if it is written as&mdash; $$P(x)=\sum_{k=0}^n a_k {n \choose k} x^k (1-x)^{n-k},$$ where $a_0, ..., a_n$ are the polynomial&#39;s <em>Bernstein coefficients</em>.</p>

<p>The degree-$n$ <em>Bernstein polynomial</em> of an arbitrary function $f(x)$ has Bernstein coefficients $a_k = f(k/n)$.  In general, this Bernstein polynomial differs from $f$ even if $f$ is a polynomial.</p>

<p><a id=Main_Question></a></p>

<h3>Main Question</h3>

<p>Suppose $f:[0,1]\to [0,1]$ is continuous and belongs to a large class of functions (for example, the $k$-th derivative, $k\ge 0$, is continuous, Lipschitz continuous, concave, strictly increasing, bounded variation, or in the Zygmund class, or $f$ is real analytic) (<strong>see note 4 in &quot;<a href="#End_Notes"><strong>End Notes</strong></a>&quot;</strong>).</p>

<ol>
<li>(<em>Exact Bernoulli factory</em>): Compute the Bernstein coefficients of a sequence of polynomials ($g_n$) of degree 2, 4, 8, ..., $2^i$, ... that converge to $f$ from below and satisfy: $(g_{2n}-g_{n})$ is a polynomial with non-negative Bernstein coefficients once it&#39;s rewritten to a polynomial in Bernstein form of degree exactly $2n$. (<strong>See note 5 in &quot;<a href="#End_Notes"><strong>End Notes</strong></a>&quot;.</strong>)  Assume $0\lt f(\lambda)\lt 1$ or $f$ is polynomially bounded.</li>
<li>(<em>Approximate Bernoulli factory</em>): Given $\epsilon &gt; 0$, compute the Bernstein coefficients of a polynomial or rational function (of some degree $n$) that is within $\epsilon$ of $f$.</li>
</ol>

<p>The convergence rate must be $O(1/n^{r/2})$ if the class has only functions with Lipschitz-continuous $(r-1)$-th derivative.  The method may not introduce transcendental or trigonometric functions (as with Chebyshev interpolants).</p>

<p><a id=Solving_the_Bernoulli_factory_problem_with_polynomials></a></p>

<h3>Solving the Bernoulli factory problem with polynomials</h3>

<p>An <a href="https://peteroupc.github.io/bernoulli.html#General_Factory_Functions"><strong>algorithm</strong></a> simulates a factory function $f(\lambda)$ via two sequences of polynomials that converge from above and below to that function. Roughly speaking, the algorithm works as follows:</p>

<ol>
<li>Generate U, a uniform random variate in $[0, 1]$.</li>
<li>Flip the input coin (with a probability of heads of $\lambda$), then build an upper and lower bound for $f(\lambda)$, based on the outcomes of the flips so far. In this case, these bounds come from two degree-$n$ polynomials that approach $f$ as $n$ gets large, where $n$ is the number of coin flips so far in the algorithm.</li>
<li>If U is less than or equal to the lower bound, return 1. If U is greater than the upper bound, return 0. Otherwise, go to step 2.</li>
</ol>

<p>The result of the algorithm is 1 with probability <em>exactly</em> equal to $f(\lambda)$, or 0 otherwise.</p>

<p>However, the algorithm requires the polynomial sequences to meet certain requirements; among them, the sequences must be of Bernstein-form polynomials that converge from above and below to a factory function.  Specifically:</p>

<p><em>For $f(\lambda)$ there must be a sequence of polynomials</em> ($g_n$) <em>in Bernstein form of degree 1, 2, 3, ... that converge to $f$ from below and satisfy:</em> $(g_{n+1}-g_{n})$ <em>is a polynomial with non-negative Bernstein coefficients once it&#39;s rewritten to a polynomial in Bernstein form of degree exactly $n+1$ (<strong>see note 5 in &quot;<a href="#End_Notes"><strong>End Notes</strong></a>&quot;</strong>; Nacu and Peres 2005; Holtz et al. 2011).  For $f(\lambda)=1-f(\lambda)$ there must likewise be a sequence of this kind.</em></p>

<p><a id=A_Matter_of_Efficiency></a></p>

<h3>A Matter of Efficiency</h3>

<p>However, ordinary Bernstein polynomials converge to a function at the rate $\Omega(1/n)$ in general, a result known since Voronovskaya (1932) and a rate that will lead to an <strong>infinite expected number of coin flips in general</strong>.  (See also my <a href="https://peteroupc.github.io/bernsupp.html"><strong>supplemental notes</strong></a>.)</p>

<p>But Lorentz (1966) showed that if the function is positive and has a continuous $k$-th derivative, there are polynomials with nonnegative Bernstein coefficients that converge at the rate $O(1/n^{k/2})$ (and thus can enable a <strong>finite expected number of coin flips</strong> if the function is &quot;smooth&quot; enough).</p>

<p>Thus, people have developed alternatives, including linear combinations and iterated Boolean sums of Bernstein polynomials, to improve the convergence rate. These include Micchelli (1973), Guan (2009), Güntürk and Li (2021a, 2021b), the &quot;Lorentz operator&quot; in Holtz et al. (2011) (see also &quot;<a href="#New_coins_from_old_smoothly"><strong>New coins from old, smoothly</strong></a>&quot;), Draganov (2014), and Tachev (2022).</p>

<p>These alternative polynomials usually include results where the error bound is the desired $O(1/n^{k/2})$, but most of those results (e.g., Theorem 4.4 in Micchelli; Theorem 5 in Güntürk and Li) have hidden constants with no upper bounds given, making them unimplementable (that is, it can&#39;t be known beforehand whether a given polynomial will come close to the target function within a user-specified error tolerance).</p>

<p><a id=A_Conjecture_on_Polynomial_Approximation></a></p>

<h3>A Conjecture on Polynomial Approximation</h3>

<p>The following is a <a href="https://peteroupc.github.io/bernsupp.html#A_Conjecture_on_Polynomial_Approximation"><strong>conjecture</strong></a> that could help reduce this problem to the problem of finding explicit error bounds when approximating a function by polynomials.</p>

<p>Let $f(\lambda):[0,1]\to(0,1)$ have $r\ge 1$ continuous derivatives, let $M$ be the maximum of the absolute value of $f$ and its derivatives up to the $r$-th derivative, and denote the Bernstein polynomial of degree $n$ of a function $g$ as $B_n(g)$. Let $W_{2^0}(\lambda), W_{2^1}(\lambda), ..., W_{2^i}(\lambda),...$ be a sequence of functions on [0, 1] that converge uniformly to $f$.</p>

<p>For each integer $n\ge 1$ that&#39;s a power of 2, suppose that there is $D&gt;0$ such that&mdash; $$|f(\lambda)-B_n(W_n(\lambda))| \le DM/n^{r/2},$$ whenever $0\le \lambda\le 1$.  Then there is $C_0\ge D$ such that for every $C\ge C_0$, the polynomials $(g_n)$ in Bernstein form of degree 2, 4, 8, ..., $2^i$, ..., defined as $g_n=B_n(W_n(\lambda) - CM/n^{r/2})$, converge from below to $f$ and satisfy: $(g_{2n}-g_{n})$ is a polynomial with non-negative Bernstein coefficients once it&#39;s rewritten to a polynomial in Bernstein form of degree exactly $2n$. (<strong>See note 5 in &quot;<a href="#End_Notes"><strong>End Notes</strong></a>&quot;.</strong>)</p>

<p>Equivalently (see also Nacu and Peres 2005), there is $C_1&gt;0$ such that the inequality $(PB)$ (see below) holds true for each integer $n\ge 1$ that&#39;s a power of 2 (see &quot;Strategies&quot;, below).</p>

<p>My goal is to see not just whether this conjecture is true, but also which value of $C_0$ (or $C_1$) suffices for the conjecture, especially for any combination of the special cases mentioned at the end of &quot;<a href="#Main_Question"><strong>Main Question</strong></a>&quot;, above.</p>

<p><a id=Strategies></a></p>

<h3>Strategies</h3>

<p>The following are some strategies for answering these questions:</p>

<ul>
<li>For iterated Boolean sums (linear combinations of iterates) of Bernstein polynomials ($U_{n,k}$ in <a href="https://www.sciencedirect.com/science/article/pii/0021904573900282"><strong>Micchelli 1973</strong></a>; see also <a href="https://arxiv.org/abs/2112.09181"><strong>Güntürk and Li</strong></a>), find an explicit bound, with no hidden constants, on the approximation error for functions with continuous $r$-th derivative, or verify my <a href="https://peteroupc.github.io/bernsupp.html#Results_Used_in_Approximate_Bernoulli_Factories"><strong>proofs of these bounds in Propositions B10C and B10D</strong></a>.</li>
<li>For linear combinations of Bernstein polynomials (Butzer 1953, <a href="https://doi.org/10.3934/mfc.2022061"><strong>Tachev 2022</strong></a>), verify my proof of those error bounds in <a href="https://peteroupc.github.io/bernsupp.html#Results_Used_in_Approximate_Bernoulli_Factories"><strong>my Proposition B10</strong></a>.</li>
<li>For the &quot;<a href="https://link.springer.com/article/10.1007/s00365-010-9108-5"><strong>Lorentz operator</strong></a>&quot;, find an explicit bound, with no hidden constants, on the approximation error for the operator $Q_{n,r}$ and for the polynomials $(f_n)$ and $(g_n)$ formed with it, and find the hidden constants $\theta_\alpha$, $s$, and $D$ as well as those in Lemmas 15, 17 to 22, 24, and 25 in the paper.  Or verify my proof of the order-2 operator&#39;s error bounds in <a href="https://peteroupc.github.io/bernsupp.html#Results_Used_in_Approximate_Bernoulli_Factories"><strong>my Proposition B10A</strong></a>.</li>
<li>Let $f:[-1,1]\to [0,1]$ be continuous.  Find explicit bounds, with no hidden constants, on the error in approximating $f$ with the following polynomials: The polynomials are similar to Chebyshev interpolants, but evaluate $f$ at <em>rational</em> values of $\lambda$ that converge to Chebyshev points (that is, converging to $\cos(j\pi/n)$ with increasing $n$). The error bounds must be close to those of Chebyshev interpolants (see, e.g., chapters 7, 8, and 12 of Trefethen, <a href="https://www.chebfun.org/ATAP/"><strong><em>Approximation Theory and Approximation Practice</em></strong></a>, 2013).</li>
<li>Find other polynomial operators meeting the requirements of the main question (see &quot;Main Question&quot;, above) and having explicit error bounds, with no hidden constants, especially operators that preserve polynomials of a higher degree than linear functions.</li>
<li>Find a sequence of functions $(W_n(f))$ and an explicit and tight upper bound on $C_1&gt;0$ such that, for each integer $n\ge 1$ that&#39;s a power of 2&mdash; $$\left|\left(\sum_{i=0}^k W_n\left(\frac{i}{n}\right)\sigma_{n,k,i}\right)-W_{2n}\left(\frac{k}{2n}\right)\right|=|\mathbb{E}[W_n(X_k/n)] - W_{2n}(\mathbb{E}[X_k/n])|\le \frac{C_1 M}{n^{r/2}},\tag{PB}$$ whenever $0\le k\le 2n$, where $M = \max(L, \max|f^{(0)}|, ...,\max|f^{(r-1)}|)$, $L$ is $\max|f^{(r)}|$ or the Lipschitz constant of $f^{(r-1)}$, $X_k$ is a hypergeometric($2n$, $k$, $n$) random variable, and $\sigma_{n,k,i} = {n\choose i}{n\choose {k-i}}/{2n \choose k}=\mathbb{P}(X_k=i)$ is the probability that $X_k$ equals $i$. (<strong>See notes 5 and 6 in &quot;<a href="#End_Notes"><strong>End Notes</strong></a>&quot; as well as &quot;<a href="https://peteroupc.github.io/bernsupp.html#Proofs_for_Polynomial_Building_Schemes"><strong>Proofs for Polynomial-Building Schemes</strong></a>.</strong>)</li>
</ul>

<p><a id=Tossing_Heads_According_to_a_Concave_Function></a></p>

<h2>Tossing Heads According to a Concave Function</h2>

<p><a href="https://mathoverflow.net/questions/409174/concave-functions-series-representation-and-converging-polynomials"><strong>https://mathoverflow.net/questions/409174/concave-functions-series-representation-and-converging-polynomials</strong></a></p>

<p>Suppose $f:[0,1]\to[0,1]$ is continuous, polynomially bounded, and belongs to a large class of functions (for example, the $k$-th derivative, $k\ge 0$, is continuous, Lipschitz continuous, concave, strictly increasing, bounded variation, or in the Zygmund class, or $f$ is real analytic).</p>

<p>Then find a non-negative random variable $X$ and a non-trivial series $f(\lambda)=\sum_{a\ge 0}\gamma_a(\lambda)$ such that $\gamma_a(\lambda)/\mathbb{P}(X=a)$ (letting 0/0 equal 0) has a simple <a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli factory algorithm</strong></a> (and is preferably a polynomial or rational function with rational Bernstein coefficients lying in $[0, 1]$).</p>

<ul>
<li>An example of $X$ is $\mathbb{P}(X=a) = p (1-p)^a$ where $0 &lt; p &lt; 1$ is a known rational.  That is, the probability of getting $a$ is $p (1-p)^a$.</li>
<li>The convergence rate must be $O(1/n^{r/2})$ if the class has only functions with Lipschitz-continuous $(r-1)$-th derivative.  The method may not introduce transcendental or trigonometric functions (as with Chebyshev interpolants).</li>
</ul>

<p><strong>See also Note 1 in &quot;<a href="#End_Notes"><strong>End Notes</strong></a>&quot;.</strong></p>

<p><a id=Special_Cases></a></p>

<h3>Special Cases</h3>

<p>One special case of the question above is if&mdash;</p>

<ul>
<li>$f:[0,1]\to [0,1)$ is concave, and</li>
<li>$\mathbb{P}(X=a)=p (1-p)^a$, where $0 &lt; p &lt; 1$ is rational, and</li>
<li>$\gamma_a(\lambda) = B_{n_{a}}(f)(\lambda) - B_{n_{a-1}}(f)(\lambda)$ ($\gamma_a(0)=B_{n_{a}}(f)(\lambda)$), where $B_n(f)$ is the degree-$n$ Bernstein polynomial of $f$, and</li>
<li>$(n_a)$ is an increasing sequence of positive integers, with $n_{-1} := 0$, and</li>
</ul>

<p>However, using this technique for a given concave $f$ requires finding the appropriate sequence for $n_a$ (such as $2^{a+s}$ for some $s\ge 0$) and the appropriate value of $p$ so that the series expansion can be formed.  Here is an example for $\min(\lambda, 1-\lambda)$ which <em>appears</em> to be correct, but finding it was far from rigorous:  $n_a = 2^{a+1}$, $p = 0.27$.</p>

<p>Once the appropriate series and $X$ are found, an algorithm to toss heads with probability equal to $f$ would be:</p>

<ol>
<li>Flip a coin that shows heads with probability $p$ until that coin shows heads.  Set $a$ to the number of tails.</li>
<li>Write $\frac{\gamma_a(\lambda)}{\mathbb{P}(X=a)}$ (letting 0/0=0) as a polynomial in Bernstein form of degree $n_{a}$ (or a higher degree such that the Bernstein coefficients are all in [0, 1]). Flip the biased coin (with probability of heads $\lambda$) $n$ times, where $n$ is the polynomial&#39;s degree, and let $j$ be the number of heads.</li>
<li>Return 1 with probability equal to the polynomial&#39;s $j$th Bernstein coefficient ($j$ starts at 0), or 0 otherwise (see also Goyal and Sigman 2012 for an algorithm to simulate polynomials).</li>
</ol>

<blockquote>
<p><strong>Note:</strong> There is no general solution for all concave $f:[0,1]\to [0,1]$, not all of which are polynomially bounded (note the codomain is $[0,1]$, not $[0,1)$).  Indeed, there are several counterexamples: $g(\lambda)=\lim_{t\to\lambda} (1-\exp(-2/t))$ (which is smooth), or $h(\lambda)$ formed by taking $g(\lambda)$ at 0 and at all points of the form $1/n$, where $n\ge 1$ is an integer, and connecting them with linear functions (so that $h$ is not even differentiable).</p>

<p><strong>Note:</strong> Another problem is to write $\gamma_a(\lambda)/\mathbb{P}(X=a)$ as a polynomial in Bernstein form with only 0 and 1 as coefficients.  However, this can be reduced to rewriting the expression to polynomials with dyadic rational coefficients, or even with coefficients whose binary expansion is easy to calculate.  In fact, the proof in Keane and O&#39;Brien (1994) rewrites $f$ as: $f(\lambda)=\sum_{a\ge 1}\mathbb{P}(X=a) Q_a(\lambda)$, where $X$ is an integer-valued random variable 1 or greater and where each $Q_a(\lambda)$ is a polynomial in Bernstein form of degree $k_a$ with only 0 and 1 as coefficients.</p>
</blockquote>

<p><a id=New_coins_from_old_smoothly></a></p>

<h2>New coins from old, smoothly</h2>

<p><a href="https://mathoverflow.net/questions/407179/using-the-holtz-method-to-build-polynomials-that-converge-to-a-continuous-functi"><strong>https://mathoverflow.net/questions/407179/using-the-holtz-method-to-build-polynomials-that-converge-to-a-continuous-functi</strong></a></p>

<p>Let $B_n(f)$ be the degree-$n$ Bernstein polynomial of $f$.</p>

<p><a href="https://link.springer.com/content/pdf/10.1007/s00365-010-9108-5.pdf"><strong>Holtz et al. 2011</strong></a>, in the paper &quot;New coins from old, smoothly&quot;, studied a family of polynomials $(Q_{n,r} f)$ (which they call the <em>Lorentz operators</em>) that approximate a continuous function $f$.</p>

<p>They used the Lorentz operators to build a family of polynomials $(g_n)$ that converge from below to $f$ and satisfy the following: $(g_{2n}−g_{n})$ is a polynomial with non-negative Bernstein coefficients, once it&#39;s rewritten to a polynomial in Bernstein form of degree exactly $2n$.</p>

<p>They proved, among other results, the following.  A function $f(\lambda):[0,1]\to(0,1)$ admits a family $(g_n)$ described above that converges at the rate&mdash;</p>

<ul>
<li>$O((\Delta_n(\lambda))^\beta)$ if and only if $f$ is $\lfloor\beta\rfloor$ times differentiable and has a ($\beta-\lfloor\beta\rfloor$)-Hölder continuous $\lfloor\beta\rfloor$-th derivative, where $\beta&gt;0$ is a non-integer and $\Delta_n(\lambda) = \max((\lambda(1-\lambda)/n)^{1/2}, 1/n)$.  (Roughly speaking, the rate is $O((1/n)^{\beta})$ when $\lambda$ is close to 0 or 1, and $O((1/n)^{\beta/2})$ elsewhere.)</li>
<li>$O((\Delta_n(\lambda))^{r+1})$ only if the $r$th derivative of $f$ is in the Zygmund class, where $r\ge 0$ is an integer.</li>
</ul>

<p>The scheme is as follows:</p>

<p>Let $f:[0,1]\to (0,1)$ have a $\beta$-Hölder continuous $r$-th derivative, where $\beta$ is in (0, 1).  Let $\alpha = r+\beta$; $b = 2^s$; $s\gt 0$ be an integer.  Let $Q_{n, r}f$ be a degree $n+r$ approximating polynomial called a <em>Lorentz operator</em> as described in Holtz et al. 2011.  Let $n_0$ be the smallest $n$, divisible by $b$, such that $Q_{n_0, r}f$ has coefficients within [0, 1]. Define the following for every integer $n \ge n_0$ divisible by $b$:</p>

<ul>
<li>$f_{n_0} = Q_{n_0, r}f$.</li>
<li>$f_{n} = f_{n/b} + Q_{n, r}(f-f_{n/b})$ for each integer $n &gt; n_0$.</li>
<li>$\phi(n, \alpha, \lambda) = \frac{\theta_{\alpha}}{n^{\alpha}}+(\frac{\lambda(1-\lambda)}{n})^{\alpha/2}$.</li>
<li>$BP(\lambda)$ is a polynomial defined as follows: Find the degree-$n$ Bernstein polynomial of $\phi(n, r+\beta, \lambda)$, then rewrite it as a degree-$n+r$ polynomial in Bernstein form.</li>
<li>$g(n, r,\lambda) = f_{n}(\lambda) - D \cdot BP(\lambda).$</li>
</ul>

<p>Thus, $\theta_\alpha$, $s$, and $D$ are hidden constants with no upper bounds given, making the Holtz method unimplementable.  The same is true for the constants in Lemmas 15, 17 to 22, and 24 in the paper.</p>

<p><a id=Questions></a></p>

<h3>Questions</h3>

<p>Let $f(\lambda):[0,1]\to (0,1)$ have a $\beta-\lfloor\beta\rfloor$)-Hölder continuous $\lfloor\beta\rfloor$-th derivative, where $\beta&gt;0$ is a non-integer.</p>

<ol>
<li>What is an explicit upper bound (with no hidden constants) on the error in approximating $f$ with the Lorentz operators $(Q_{n,r} f)$, described above, of the form $C\cdot M\cdot\max((\lambda(1-\lambda)/n)^{1/2}, 1/n)^r$, where $C=C(r)$ and $M=M(f,r)$ are constants?</li>
<li>Same question, but for the polynomial family $(g_n)$ given in (1), above.</li>
<li>Same questions as 1 and 2, but $f$&#39;s $(r-1)$-th derivative is in the Zygmund class. (Note that the method of Holtz et al.&#39;s paper as written doesn&#39;t apply to integer $\beta$; see also Conjecture 34 of that paper.)</li>
</ol>

<p><a id=Simulable_and_strongly_simulable_functions></a></p>

<h2>Simulable and strongly simulable functions</h2>

<p><a href="https://mathoverflow.net/questions/404961/from-biased-coins-and-nothing-else-to-biased-coins"><strong>https://mathoverflow.net/questions/404961/from-biased-coins-and-nothing-else-to-biased-coins</strong></a></p>

<p>There are two kinds of Bernoulli factory functions:</p>

<ul>
<li>A function $f(\lambda)$ is <em>simulable</em> if an algorithm exists to toss heads with probability $f(\lambda)$ given a coin with probability of heads $\lambda$ (the &quot;biased coin&quot;) as well as a fair coin.</li>
<li>A function $f(\lambda)$ is <em>strongly simulable</em> if an algorithm exists to toss heads with probability $f(\lambda)$ given <strong>only</strong> a coin with probability of heads $\lambda$.</li>
</ul>

<p>Every strongly simulable function is simulable, but not vice versa.</p>

<p>In fact, Keane and O&#39;Brien (1994) showed already that $f(\lambda)$ is strongly simulable if $f$ is simulable and neither 0 nor 1 is in $f$&#39;s domain (that is, if the biased coin doesn&#39;t show heads every time or tails every time).  And it&#39;s also easy to show that if $f$ is strongly simulable, then $f(0)$ must be 0 or 1 if 0 is in $f$&#39;s domain and $f(1)$ must be 0 or 1 whenever 1 is in $f$&#39;s domain.</p>

<p>However, it&#39;s not so trivial to find the exact class of strongly simulable functions when $f$&#39;s domain includes 0, 1, or both.</p>

<p>As one illustration of this, the proof of Keane and O&#39;Brien relies on generating a geometric random variate and using that variate to control which &quot;part&quot; of the target function $f(\lambda)$ to simulate.   This obviously works on all of [0, 1] if the algorithm uses both the biased coin and a separate fair coin.  However, if only the biased coin is used in the algorithm, the geometric random variate is generated using fair bits via the von Neumann method, which however will never terminate if $\lambda$ is either 0 or 1.  In addition, a <a href="https://peteroupc.github.io/bernsupp.html#Which_functions_don_t_require_outside_randomness_to_simulate"><strong>result I found</strong></a> gives sufficient conditions for being strongly simulable when $f$&#39;s domain includes 0, 1, or both.  Its proof proceeds by showing, among other things, that the Bernoulli factory for $f$ must flip the input coin and get 0 and 1 before it simulates any fair coin flips via the von Neumann trick.</p>

<p>Question: <strong>Prove or disprove:</strong> Let $f:(D\subseteq [0, 1])\to [0,1]$.  Given a coin that shows heads with probability $\lambda$ (which can be 0 or 1), it is possible to toss heads with probability $f(\lambda)$ using the coin and no other sources of randomness (and, thus, $f$ is <em>strongly simulable</em>) <strong>if and only if</strong>&mdash;</p>

<ul>
<li>$f$ is constant on its domain, or is continuous and polynomially bounded on its domain (<em>polynomially bounded</em> means, both $f$ and $1-f$ are bounded below by min($x^n$, $(1-x)^n$) for some integer $n$ [Keane and O&#39;Brien 1994]), and</li>
<li>$f(0)$ is 0 or 1 if 0 is in $f$&#39;s domain and $f(1)$ is 0 or 1 whenever 1 is in $f$&#39;s domain, and</li>
<li>if $f(0) = 0$ or $f(1) = 0$ or both, then there is a polynomial $g(x):[0,1]\to [0,1]$ with computable coefficients, such that $g(0) = f(0)$ and $g(1) = f(1)$ whenever 0 or 1, respectively, is in the domain of f, and such that $g(x)\gt f(x)$ for every $x$ in the domain of $f$, except at 0 and 1, and</li>
<li>if $f(0) = 1$ or $f(1) = 1$ or both, then there is a polynomial $h(x):[0,1]\to [0,1]$ with computable coefficients, such that $h(0) = f(0)$ and $h(1) = f(1)$ whenever 0 or 1, respectively, is in the domain of $f$, and such that $g(x)\lt f(x)$ for every $x$ in the domain of f, except at 0 and 1.</li>
</ul>

<p>A condition such as &quot;0 is not in the domain of $f$, or $f$ can be extended to a Lipschitz continuous function on $[0, \epsilon)$ for some $\epsilon&gt;0$&quot; does not work.  A counterexample is $f(x)=(\sin(1/x)/4+1/2)\cdot(1-(1-x)^n)$ for $n\ge 1$ ($f(0)=0$), which is strongly simulable at 0 despite not being Lipschitz at 0.  ($(1-x)^n$ is the probability of the biased coin showing zero $n$ times in a row.)</p>

<p><a id=Multiple_Output_Bernoulli_Factories></a></p>

<h2>Multiple-Output Bernoulli Factories</h2>

<p><a href="https://mathoverflow.net/questions/412772/from-biased-coins-to-biased-coins-as-efficiently-as-possible"><strong>https://mathoverflow.net/questions/412772/from-biased-coins-to-biased-coins-as-efficiently-as-possible</strong></a></p>

<p>Let $J$ be a closed interval on $(0, 1)$, and let $f(\lambda):J \to (0, 1)$ be continuous.</p>

<p>Then by Keane and O&#39;Brien, $f$ admits an algorithm that solves the Bernoulli factory problem for $f$ (using only the biased coin, in fact). A related problem is a Bernoulli factory that takes a coin with unknown probability of heads $\lambda \in J$ and produces <em>one or more</em> samples, at a time, of the probability $f(\lambda)$. This question calls it a <em>multiple-output Bernoulli factory</em>.</p>

<p>Obviously, any single-output Bernoulli factory can produce multiple outputs by running itself multiple times. But for some functions $f$, it may be that producing multiple outputs at a time may use fewer coin flips than producing one output multiple times.</p>

<p>Define the entropy bound as&mdash; $$h(f(\lambda))/h(\lambda),$$ where&mdash; $$h(x)=-x \ln(x)-(1-x) \ln(1-x),$$ is related to the Shannon entropy function.</p>

<p><a id=Questions_2></a></p>

<h3>Questions</h3>

<ol>
<li>Given that a function $f(\lambda)$ is continuous and maps a closed interval in (0, 1) to (0, 1), is there a multiple-output Bernoulli factory algorithm for $f$ with an expected number of coin flips per sample that is arbitrarily close to the entropy bound, uniformly for every $\lambda$ in $f$&#39;s domain? Call such a Bernoulli factory an <em>optimal factory</em>.  (See Nacu and Peres 2005, Question 1.)</li>
<li>Does the answer to question 1 change if the algorithm can also use a fair coin in addition to the biased coin?</li>
</ol>

<p><a id=Functions_with_Optimal_Factories></a></p>

<h3>Functions with Optimal Factories</h3>

<p>So far, the following functions do admit an optimal factory:</p>

<ul>
<li>The functions $\lambda$ and $1-\lambda$.</li>
<li>Constants in [0, 1]. As Nacu and Peres (2005) already showed, any such constant $c$ admits an optimal factory: generate unbiased random bits using Peres&#39;s iterated von Neumann extractor (Peres 1992), then build a binary tree that generates 1 with probability $c$ and 0 otherwise (Knuth and Yao 1976).</li>
</ul>

<p>It is easy to see that if an optimal factory exists for $f(\lambda)$, then one also exists for $1-f(\lambda)$: simply change all ones returned by the $f(\lambda)$ factory into zeros and vice versa.</p>

<p>Also, as Yuval Peres (Jun. 24, 2021) told me, there is an efficient multiple-output Bernoulli factory for $f(\lambda) = \lambda/2$: the key is to flip the input coin enough times to produce unbiased random bits using his extractor (Peres 1992), then multiply each unbiased bit with another input coin flip to get a sample from $\lambda/2$. Given that the sample is equal to 0, there are three possibilities that can &quot;be extracted to produce more fair bits&quot;: either the unbiased bit is 0, or the coin flip is 0, or both are 0.  This algorithm, though, might not count as an <em>optimal factory</em>, and Peres described this algorithm only incompletely.  Indeed, the correctness might depend on how the three possibilities are &quot;extracted to produce more fair bits&quot;; after all, the number of coin flips per sample, for every $\lambda$, must not surpass the entropy bound.</p>

<p>In any case, I believe that not all factory functions admit an optimal factory described here; especially because&mdash;</p>

<ul>
<li>the question may depend on $f$&#39;s range, and</li>
<li>the efficiency of even a <em>single-output</em> Bernoulli factory depends on $f$&#39;s smoothness (e.g., $O(1/n^{(r+\alpha)/2})$ only if $f$&#39;s $r$th derivative is Hölder continuous with Hölder exponent $\alpha$; Holtz et al. 2011).</li>
</ul>

<p>See an <a href="https://peteroupc.github.io/bernsupp.html#Multiple_Output_Bernoulli_Factory"><strong>appendix in one of my articles</strong></a> for more information on my progress on the problem.</p>

<p><a id=From_coin_flips_to_algebraic_functions_via_pushdown_automata></a></p>

<h2>From coin flips to algebraic functions via pushdown automata</h2>

<p><a href="https://cstheory.stackexchange.com/questions/50853/from-coin-flips-to-algebraic-functions-via-pushdown-automata"><strong>https://cstheory.stackexchange.com/questions/50853/from-coin-flips-to-algebraic-functions-via-pushdown-automata</strong></a></p>

<p>This section is about solving the Bernoulli factory problem on a restricted computing model, namely the model of <em>pushdown automata</em> (finite-state machines with a stack) that are driven by flips of a coin and produce new probabilities.</p>

<p><a id=Pushdown_Automata></a></p>

<h3>Pushdown Automata</h3>

<p>A <em>pushdown automaton</em> has a finite set of <em>states</em> and a finite set of <em>stack symbols</em>, one of which is called EMPTY and takes a biased coin with an unknown probability of heads. It starts with a given state and its stack starts with EMPTY. On each iteration:</p>

<ul>
<li>The automaton flips the coin.</li>
<li>Based on the coin flip (HEADS or TAILS), the current state, and the top stack symbol, it moves to a new state (or keeps it unchanged) and replaces the top stack symbol with zero, one, or two symbols. Thus, there are three kinds of <em>transition rules</em>:

<ul>
<li>(<em>state</em>, <em>flip</em>, <em>symbol</em>) &rarr; (<em>state2</em>, {<em>symbol2</em>}): move to <em>state2</em>, replace top stack symbol with same or different one.</li>
<li>(<em>state</em>, <em>flip</em>, <em>symbol</em>) &rarr; (<em>state2</em>, {<em>symbol2</em>, <em>new</em>}): move to <em>state2</em>, replace top stack symbol with <em>symbol2</em>, then <em>push</em> a new symbol (<em>new</em>) onto the stack.</li>
<li>(<em>state</em>, <em>flip</em>, <em>symbol</em>) &rarr; (<em>state2</em>, {}): move to <em>state2</em>, <em>pop</em> the top symbol from the stack.</li>
</ul></li>
</ul>

<p>When the stack is empty, the machine stops and returns either 0 or 1 depending on the state it ends up at. (For the questions below, let <em>flip</em> be HEADS, TAILS, or a rational number in [0, 1]; this likewise reduces to the definition above.  The rest of this question assumes the pushdown automaton terminates with probability 1.)</p>

<p><a id=Algebraic_Functions></a></p>

<h3>Algebraic Functions</h3>

<p>Let $f: (0, 1) \to (0, 1)$ be continuous.  Mossel and Peres (2005) showed that a pushdown automaton can simulate $f$ only if $f$ is <em>algebraic over the rational numbers</em> (there is a nonzero polynomial $P(x, y)$ in two variables and whose coefficients are rational numbers, such that $P(x, f(x)) = 0$ for every $x$ in the domain of $f$).  The algebraic function generated by pushdown automata corresponds to a system of polynomial equations, as described by Mossel and Peres (2005) and Esparza et al. 2004.</p>

<p>Let $\mathcal{C}$ be the class of continuous functions that map (0, 1) to (0, 1) and are algebraic over rationals.  The constants 0 and 1 are also in $\mathcal{C}$.</p>

<p>Let $\mathcal{D} \subseteq \mathcal{C}$ be the class of functions that a pushdown automaton can simulate.</p>

<p>I don&#39;t yet know whether $\mathcal{D}=\mathcal{C}$ (and that was also a question of Mossel and Peres).</p>

<p>The following section of my open-source page, <a href="https://peteroupc.github.io/bernsupp.html#Pushdown_Automata_and_Algebraic_Functions"><strong>Pushdown Automata and Algebraic Functions</strong></a>, contains information on the question. That section sets forth the following results about the class $\mathcal{D}$:</p>

<ul>
<li>$\sqrt{\lambda}$ is in $\mathcal{D}$, and so is every rational function in $\mathcal{C}$.</li>
<li>If $f(\lambda)$ and $g(\lambda)$ are in $\mathcal{D}$, then so are their product and composition.</li>
<li>If $f(\lambda)$ is in $\mathcal{D}$, then so is every Bernstein-form polynomial in the variable $f(\lambda)$ with coefficients in $\mathcal{D}$.</li>
<li>If a pushdown automaton can generate a discrete distribution of <em>n</em>-letter words, then that distribution&#39;s probability generating function is in $\mathcal{D}$ (cf. Dughmi et al. 2021).</li>
<li>If a pushdown automaton can generate a discrete distribution of <em>n</em>-letter words of the same letter, it can generate that distribution conditioned on a finite set of word lengths, or a periodic infinite set of word lengths (e.g., odd word lengths only).</li>
<li>Every quadratic irrational in (0, 1) is in $\mathcal{D}$.</li>
</ul>

<p><a id=Questions_3></a></p>

<h3>Questions</h3>

<ol>
<li>For every function in class $\mathcal{C}$, is there a pushdown automaton that can simulate that function? (In other words, is $\mathcal{D}=\mathcal{C}$?).</li>
<li>In particular, is min($\lambda$, $1-\lambda$) in class $\mathcal{D}$? What about $\lambda^{1/p}$ for some prime $p\ge 3$?</li>
</ol>

<p><strong>See also Notes 2 and 3.</strong></p>

<p><a id=Reverse_time_martingales></a></p>

<h2>Reverse-time martingales</h2>

<p>This section is withdrawn. For the Bernoulli factory problem, rational functions are probably not much better than polynomials when approximating functions with low smoothness (e.g., those with only three continuous derivatives).  This follows from Borwein (1979, theorem 29) and Holtz et al. (2011) (which disproved a theorem of Lorentz relied on by Borwein but maintained it with an extra assumption used in the Bernoulli factory setting).</p>

<p><a id=Other_Questions></a></p>

<h2>Other Questions</h2>

<ul>
<li>Given integer <em>m</em>&ge;0, rational number 0&lt;<em>k</em>&le;exp(1), and unknown heads probability 0&le;<em>&lambda;</em>&le;1, find a <a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli factory</strong></a> for&mdash; $$f(\lambda)=\exp(-(\exp(m+\lambda)-(k(m+\lambda)))) = \frac{\exp(-\exp(m+\lambda))}{\exp(-(k(m+\lambda)))},\tag{PD}$$ that, as much as possible, avoids calculating $h(\lambda) = \exp(m+\lambda)-k(m+\lambda)$; in this sense, the more implicitly the Bernoulli factory works with irrational or transcendental functions, the better.  A solution is sought especially when <em>k</em> is 1 or 2.   Note that the right-hand side of (PD) can be implemented by <a href="https://peteroupc.github.io/bernoulli.html#ExpMinus_exp_minus__z"><strong>ExpMinus</strong></a> and division Bernoulli factories, but is inefficient and heavyweight due to the need to calculate $\epsilon$ for the division factory.  In addition there is a Bernoulli factory that first calculates $h(\lambda)$ and $floor(h(\lambda))$ using constructive reals and then runs <strong>ExpMinus</strong>, but this is likewise far from lightweight.  (Calculating exp(.) with floating-point operations is not acceptable for this question.)</li>
<li>Special case of &quot;<a href="#Tossing_Heads_According_to_a_Concave_Function"><strong>Tossing Heads According to a Concave Function</strong></a>&quot;: Let $f(\lambda):[0,1]\to [0,1]$ be writable as $f(\lambda)=\sum_{n\ge 0} a_n \lambda^n,$ where $a_n\ge 0$ is rational, $a_n$ is nonzero infinitely often, and $f(1)$ is irrational.  Then what are simple criteria to determine whether there is $0\lt p\lt 1$ such that $0\le a_n\le p(1-p)^n$ and, if so, to find such $p$?  Obviously, if $(a_n)$ is nowhere increasing then $1\gt p\ge a_0$.</li>
<li><p><a href="https://stats.stackexchange.com/questions/541402/what-are-relatively-simple-simulations-that-succeed-with-an-irrational-probabili"><strong>Simple simulation algorithms</strong></a>: What simulations exist that are &quot;relatively simple&quot; and succeed with an irrational probability between 0 and 1? What about &quot;relatively simple&quot; Bernoulli factory algorithms for factory functions?  Here, &quot;relatively simple&quot; means that the algorithm:</p>

<ul>
<li>Should use only uniform random integers (or bits) and integer arithmetic.</li>
<li>Does not use floating-point arithmetic, make direct use of irrational or transcendental functions or constants, or calculate the <em>p</em>-adic digit expansion of an irrational or transcendental function, for any real <em>p</em>.</li>
<li>Should not use rational arithmetic or increasingly complex approximations, except as a last resort.</li>
</ul>

<p>See also Flajolet et al., &quot;On Buffon machines and numbers&quot;, 2010.  There are many ways to describe the irrational probability or factory function. References are sought to papers or books that describe irrational constants or factory functions in any of the following ways:</p>

<ul>
<li>For irrational constants:

<ul>
<li>Simple <a href="https://peteroupc.github.io/bernoulli.html#Continued_Fractions"><strong>continued fraction</strong></a> expansions.</li>
<li>Closed shapes inside the unit square whose area is an irrational number.  (Includes algorithms that tell whether a box lies inside, outside, or partly inside or outside the shape.)    <a href="https://peteroupc.github.io/bernoulli.html#pi___4"><strong>Example.</strong></a></li>
<li>Generate a uniform (<em>x</em>, <em>y</em>) point inside a closed shape, then return 1 with probability <em>x</em>.  For what shapes is the expected value of <em>x</em> an irrational number?  <a href="https://peteroupc.github.io/bernsupp.html#4_3___pi"><strong>Example.</strong></a></li>
<li>Functions that map [0, 1] to [0, 1] whose integral is an irrational number.</li>
</ul></li>
<li>Bernoulli factory functions with any of the following series expansions, using rational arithmetic only:

<ul>
<li>Alternating power series (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Power_Series"><strong>Certain Power Series</strong></a>&quot;).</li>
<li>Series with nonnegative terms and bounds on the truncation error (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Converging_Series"><strong>Certain Converging Series</strong></a>&quot;).</li>
</ul></li>
</ul></li>
</ul>

<p>Prove or disprove:</p>

<ul>
<li>Given that $f:[0,1]\to (0,1]$ is convex, the polynomials $(g_n) = (B_n(f) - \max_{0\le\lambda\le 1}|B_n(f)(\lambda)-f(\lambda)|)$ (where $n\ge 1$ is an integer power of 2) are in Bernstein form of degree $n$, converge to $f$ from below, and satisfy: $(g_{2n}-g_{n})$ is a polynomial with non-negative Bernstein coefficients once it&#39;s rewritten to a polynomial in Bernstein form of degree exactly $2n$. The same is true for the polynomials $(g_n) = (B_n(f) - |B_n(f)(1/2)-f(1/2)|)$, if $f$ is also symmetric about 1/2.</li>
</ul>

<p><a id=End_Notes></a></p>

<h2>End Notes</h2>

<p><strong>Note 1</strong>: Besides the questions on concave functions given above, there is also the question of whether the solution terminates with a finite expected running time.  In this sense, Nacu &amp; Peres showed that a finite expected time is possible only if $f$ is Lipschitz continuous, and I strongly suspect it&#39;s not possible either unless $f$ has a Hölder continuous fourth derivative, in view of the results by Holtz given in the section &quot;New coins from old&quot;, smoothly.</p>

<p><strong>Note 2</strong>: On pushdown automata: Etessami and Yannakakis (2009) showed that pushdown automata with rational probabilities are equivalent to recursive Markov chains (with rational transition probabilities), and that for every recursive Markov chain, the system of polynomial equations has nonnegative coefficients. But this paper doesn&#39;t deal with the case of recursive Markov chains where the transition probabilities cannot just be rational, but can also be $\lambda$ and $1-\lambda$ where $\lambda$ is an unknown rational or irrational probability of heads.</p>

<p><strong>Note 3</strong>: On pushdown automata: Banderier and Drmota (2014) showed the asymptotic behavior of power series solutions $f(\lambda)$ of a polynomial system, where both the series and the system have nonnegative real coefficients. Notably, functions of the form $\lambda^{1/p}$ where $p\ge 3$ is not a power of 2, are not possible solutions, because their so-called &quot;critical exponent&quot; is not dyadic. But the result seems not to apply to <em>piecewise</em> power series such as $\min(\lambda,1-\lambda)$, which are likewise algebraic functions.</p>

<p><strong>Note 4</strong>: $g(\lambda)$ is in the Zygmund class if there is $D&gt;0$ such that $|g(x-h) + g(x+h) - 2g(x)|\le Dh$ wherever the left-hand side is defined and $0\lt h\le\epsilon$.</p>

<p><strong>Note 5</strong>: This condition is also known as a &quot;consistency requirement&quot;; it ensures that not only the polynomials &quot;increase&quot; to $f(\lambda)$, but also their Bernstein coefficients do as well.  This condition is equivalent in practice to the following statement (Nacu &amp; Peres 2005). For every integer $n\ge 1$ that&#39;s a power of 2, $a(2n, k)\ge\mathbb{E}[a(n, X_{n,k})]= \left(\sum_{i=0}^k a(n,i) {n\choose i}{n\choose {k-i}}/{2n\choose k}\right)$, where $a(n,k)$ is the degree-$n$ polynomial&#39;s $k$-th Bernstein coefficient, where $0\le k\le 2n$ is an integer, and where $X_{n,k}$ is a hypergeometric($2n$, $k$, $n$) random variable.  A hypergeometric($2n$, $k$, $n$) random variable is the number of &quot;good&quot; balls out of $n$ balls taken uniformly at random, all at once, from a bag containing $2n$ balls, $k$ of which are &quot;good&quot;.  See also my <a href="https://mathoverflow.net/questions/429037/bounds-on-the-expectation-of-a-function-of-a-hypergeometric-random-variable"><strong>MathOverflow question</strong></a> on finding bounds for hypergeometric variables.</p>

<p><strong>Note 6</strong>: If $W_n(0)=f(0)$ and $W_n(1)=f(1)$ for every $n$, then the inequality $(PB)$ is automatically true when $k=0$ and $k=2n$, so that the statement has to be checked only for $0\lt k\lt 2n$.  If, in addition, $W_n$ is symmetric about 1/2, so that $W_n(\lambda)=W_n(1-\lambda)$ whenever $0\le \lambda\le 1$, then the statement has to be checked only for $0\lt k\le n$ (since the values $\sigma_{n,k,i} = {n\choose i}{n\choose {k-i}}/{2n \choose k}$ are symmetric in that they satisfy $\sigma_{n,k,i}=\sigma_{n,k,k-i}$).<br>This question is a problem of finding the <em>Jensen gap</em> of $W_n$ for certain kinds of hypergeometric random variables (<strong>see Note 5</strong>).  Lee et al. (2021) deal with a problem very similar to this one and find results that take advantage of $f$&#39;s (here, $W_n$&#39;s) smoothness, but unfortunately assume the variable is supported on an <em>open</em> interval, rather than a <em>closed</em> one (namely $[0,1]$) as in this question.</p>

<p><a id=References></a></p>

<h2>References</h2>

<ul>
<li>E. Voronovskaya, &quot;Détermination de la forme asymptotique d&#39;approximation des fonctions par les polynômes de M. Bernstein&quot;, 1932.</li>
<li>Łatuszyński, K., Kosmidis, I., Papaspiliopoulos, O., Roberts, G.O., &quot;<a href="https://arxiv.org/abs/0907.4018v2"><strong>Simulating events of unknown probabilities via reverse time martingales</strong></a>&quot;, arXiv:0907.4018v2 [stat.CO], 2009/2011.</li>
<li>Keane, M. S., and O&#39;Brien, G. L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</li>
<li>Holtz, O., Nazarov, F., Peres, Y., &quot;<a href="https://link.springer.com/article/10.1007/s00365-010-9108-5"><strong>New Coins from Old, Smoothly</strong></a>&quot;, Constructive Approximation 33 (2011).</li>
<li>Nacu, Şerban, and Yuval Peres. &quot;Fast simulation of new coins from old&quot;, The Annals of Applied Probability 15, no. 1A (2005): 93-115.</li>
<li>Knuth, Donald E. and Andrew Chi-Chih Yao. &quot;The complexity of nonuniform random number generation&quot;, in <em>Algorithms and Complexity: New Directions and Recent Results</em>, 1976.</li>
<li>Peres, Y., &quot;<a href="https://projecteuclid.org/euclid.aos/1176348543"><strong>Iterating von Neumann&#39;s procedure for extracting random bits</strong></a>&quot;, Annals of Statistics 1992,20,1, p. 590-597.</li>
<li>Mossel, Elchanan, and Yuval Peres. New coins from old: computing with unknown bias. Combinatorica, 25(6), pp.707-724, 2005.</li>
<li>Icard, Thomas F., &quot;Calibrating generative models: The probabilistic Chomsky–Schützenberger hierarchy.&quot; Journal of Mathematical Psychology 95 (2020): 102308.</li>
<li>Dughmi, Shaddin, Jason Hartline, Robert D. Kleinberg, and Rad Niazadeh. &quot;Bernoulli Factories and Black-box Reductions in Mechanism Design.&quot; Journal of the ACM (JACM) 68, no. 2 (2021): 1-30.</li>
<li>Etessami, K. And Yannakakis, M., &quot;Recursive Markov chains, stochastic grammars, and monotone systems of nonlinear equations&quot;, Journal of the ACM 56(1), pp.1-66, 2009.</li>
<li>Banderier, C. And Drmota, M., 2015. Formulae and asymptotics for coefficients of algebraic functions. Combinatorics, Probability and Computing, 24(1), pp.1-53.</li>
<li>Esparza, J., Kučera, A. and Mayr, R., 2004, July. Model checking probabilistic pushdown automata. In Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, 2004. (pp. 12-21). IEEE.</li>
<li>Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560v2"><strong>On Buffon machines and numbers</strong></a>&quot;, arXiv:0906.5560v2 [math.PR], 2010.</li>
<li>von Neumann, J., &quot;Various techniques used in connection with random digits&quot;, 1951.</li>
<li>G.G. Lorentz, &quot;The degree of approximation by polynomials with positive coefficients&quot;, 1966.</li>
<li>Micchelli, C. (1973). The saturation class and iterates of the Bernstein polynomials. Journal of Approximation Theory, 8(1), 1-18.</li>
<li>Butzer, P.L., &quot;Linear combinations of Bernstein polynomials&quot;, Canadian Journal of Mathematics 15 (1953).</li>
<li>Guan, Zhong. &quot;<a href="https://arxiv.org/pdf/0909.0684"><strong>Iterated Bernstein polynomial approximations</strong></a>.&quot; arXiv preprint arXiv:0909.0684 (2009).</li>
<li>Güntürk, C. Sinan, and Weilin Li. &quot;<a href="https://arxiv.org/pdf/2112.09183"><strong>Approximation with one-bit polynomials in Bernstein form</strong></a>&quot;, arXiv:2112.09183 (2021); Constructive Approximation, pp.1-30 (2022).</li>
<li>Güntürk, C. Sinan, and Weilin Li. &quot;<a href="https://arxiv.org/abs/2112.09181"><strong>Approximation of functions with one-bit neural networks</strong></a>&quot;, arXiv:2112.09181 (2021).</li>
<li>Draganov, Borislav R. &quot;On simultaneous approximation by iterated Boolean sums of Bernstein operators.&quot; Results in Mathematics 66, no. 1 (2014): 21-41.</li>
<li>Kawamura, Akitoshi, Norbert Müller, Carsten Rösnick, and Martin Ziegler. &quot;<a href="https://doi.org/10.1016/j.jco.2015.05.001"><strong>Computational benefit of smoothness: Parameterized bit-complexity of numerical operators on analytic functions and Gevrey’s hierarchy</strong></a>.&quot; Journal of Complexity 31, no. 5 (2015): 689-714.</li>
<li>Borwein, P.B., &quot;Restricted Uniform Rational Approximations&quot;, dissertation, University of British Columbia, 1979.</li>
<li>Tachev, Gancho. &quot;<a href="https://doi.org/10.3934/mfc.2022061"><strong>Linear combinations of two Bernstein polynomials</strong></a>&quot;, <em>Mathematical Foundations of Computing</em>, 2022.</li>
<li>Lee, Sang Kyu, Jae Ho Chang, and Hyoung-Moon Kim. &quot;Further sharpening of Jensen&#39;s inequality.&quot; Statistics 55, no. 5 (2021): 1154-1168.</li>
<li>Bustamante, J., &quot;Estimates of positive linear operators in terms of second order moduli&quot;, J. Math. Anal. Appl. 345 (2008).</li>
<li>S.N. Bernstein, &quot;The asymptotic behavior of the approximation of functions by their Bernstein polynomials&quot;, 1932.</li>
<li>X. Han, &quot;<a href="https://www.sciencedirect.com/science/article/pii/S0021904503001485"><strong>Multi-node higher order expansions of a function</strong></a>&quot;, Journal of Approximation Theory, October 2003.</li>
</ul>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>

<div class="noprint">
<p>
<a href="//twitter.com/intent/tweet">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
<p style='font-size:120%;font-weight:bold'><a href='https://peteroupc.github.io/bernreq.pdf'>Download a PDF of this page</a></p></nav></body></html>
